Started main
Parser created:  ArgumentParser(prog='DualPrompt training and evaluation configs', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)
Getting config
Reached here
Reached here
Not using distributed mode
Train transforms:  Compose(
    RandomResizedCrop(size=(224, 224), scale=(0.05, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=warn)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
)
Test transforms:  Compose(
    Resize(size=256, interpolation=bicubic, max_size=None, antialias=warn)
    CenterCrop(size=(224, 224))
    ToTensor()
)
Downloading from https://data.deepai.org/CUB200(2011).zip
Downloading https://data.deepai.org/CUB200(2011).zip to /local_datasets/CUB200(2011).zip
100%|██████████████████████| 1187408162/1187408162 [04:28<00:00, 4416026.06it/s]
NB CLasses:  200
Creating model: vit_base_patch16_224_in21k
Using multihead:  True
Num Tasks:  10 pool_size:  50 kernel_size:  17 top_k:  1
Nb classes:  20
Namespace(subparser_name='cub_convprompt', batch_size=64, epochs=60, model='vit_base_patch16_224_in21k', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, use_transform=False, use_clip_grad=True, SLCA=False, logit_norm=0.1, ca_epochs=5, opt='adam', opt_eps=1e-08, clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='cosine', lr=0.001, lr_orig=0.01, lr_cls=0.01, lr_rps=0.0001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='/local_datasets/', dataset='Split-CUB200', shuffle=False, output_dir='./output', device='cuda', seed=1996, eval=False, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=10, train_mask=True, task_inc=False, num_prompts_per_task=5, variable_num_prompts=True, use_g_prompt=False, g_prompt_length=5, g_prompt_layer_idx=[], use_prefix_tune_for_g_prompt=True, use_e_prompt=True, e_prompt_layer_idx=[0, 1, 2, 3, 4, 5, 6], use_prefix_tune_for_e_prompt=True, kernel_size=17, prompt_pool=True, size=10, length=20, top_k=1, initializer='uniform', prompt_key=True, prompt_key_init='uniform', use_prompt_mask=True, mask_first_epoch=False, shared_prompt_pool=False, shared_prompt_key=False, batchwise_prompt=False, embedding_key='cls', predefined_key='', pull_constraint=True, pull_constraint_coeff=1.0, same_key_value=False, global_pool='token', head_type='token', freeze=['blocks', 'patch_embed', 'cls_token', 'pos_embed'], print_freq=10, distributed=False, nb_classes=200)
number of params: 3353972
Start training for 60 epochs
Using adam optimizer
Reinitialising optimizer
Old Num K:  0 New Num K:  5
Task number:  0
Train: Epoch[ 1/60]  [ 0/10]  eta: 0:00:55  Lr: 0.000250  Loss: 2.9750  Acc@1: 6.2500 (6.2500)  Acc@5: 31.2500 (31.2500)  time: 5.5090  data: 0.7851  max mem: 6661
Train: Epoch[ 1/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000250  Loss: 2.7089  Acc@1: 12.5000 (13.8333)  Acc@5: 45.3125 (44.5000)  time: 2.0927  data: 0.0789  max mem: 6674
Train: Epoch[ 1/60] Total time: 0:00:20 (2.0977 s / it)
Averaged stats: Lr: 0.000250  Loss: 2.7089  Acc@1: 12.5000 (13.8333)  Acc@5: 45.3125 (44.5000)
Train: Epoch[ 2/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000250  Loss: 2.5463  Acc@1: 26.5625 (26.5625)  Acc@5: 70.3125 (70.3125)  time: 2.9391  data: 0.8671  max mem: 6674
Train: Epoch[ 2/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000250  Loss: 1.8958  Acc@1: 42.1875 (41.5000)  Acc@5: 82.8125 (82.8333)  time: 1.7826  data: 0.0869  max mem: 6674
Train: Epoch[ 2/60] Total time: 0:00:17 (1.7900 s / it)
Averaged stats: Lr: 0.000250  Loss: 1.8958  Acc@1: 42.1875 (41.5000)  Acc@5: 82.8125 (82.8333)
Train: Epoch[ 3/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000249  Loss: 1.9870  Acc@1: 53.1250 (53.1250)  Acc@5: 93.7500 (93.7500)  time: 2.9444  data: 0.8984  max mem: 6674
Train: Epoch[ 3/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000249  Loss: 1.5036  Acc@1: 67.1875 (65.6667)  Acc@5: 95.3125 (95.1667)  time: 1.8061  data: 0.0900  max mem: 6674
Train: Epoch[ 3/60] Total time: 0:00:18 (1.8125 s / it)
Averaged stats: Lr: 0.000249  Loss: 1.5036  Acc@1: 67.1875 (65.6667)  Acc@5: 95.3125 (95.1667)
Train: Epoch[ 4/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000248  Loss: 1.6188  Acc@1: 68.7500 (68.7500)  Acc@5: 96.8750 (96.8750)  time: 2.8539  data: 0.7272  max mem: 6674
Train: Epoch[ 4/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000248  Loss: 1.2933  Acc@1: 75.0000 (75.5000)  Acc@5: 96.8750 (97.5000)  time: 1.7772  data: 0.0729  max mem: 6674
Train: Epoch[ 4/60] Total time: 0:00:17 (1.7842 s / it)
Averaged stats: Lr: 0.000248  Loss: 1.2933  Acc@1: 75.0000 (75.5000)  Acc@5: 96.8750 (97.5000)
Train: Epoch[ 5/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000247  Loss: 1.0855  Acc@1: 89.0625 (89.0625)  Acc@5: 100.0000 (100.0000)  time: 2.9058  data: 0.8509  max mem: 6674
Train: Epoch[ 5/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000247  Loss: 0.7686  Acc@1: 82.8125 (81.8333)  Acc@5: 96.8750 (97.1667)  time: 1.7791  data: 0.0852  max mem: 6674
Train: Epoch[ 5/60] Total time: 0:00:17 (1.7856 s / it)
Averaged stats: Lr: 0.000247  Loss: 0.7686  Acc@1: 82.8125 (81.8333)  Acc@5: 96.8750 (97.1667)
Train: Epoch[ 6/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000246  Loss: 0.8529  Acc@1: 90.6250 (90.6250)  Acc@5: 98.4375 (98.4375)  time: 2.8302  data: 0.8145  max mem: 6674
Train: Epoch[ 6/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000246  Loss: 0.7967  Acc@1: 84.3750 (85.5000)  Acc@5: 98.4375 (98.3333)  time: 1.7890  data: 0.0816  max mem: 6674
Train: Epoch[ 6/60] Total time: 0:00:17 (1.7958 s / it)
Averaged stats: Lr: 0.000246  Loss: 0.7967  Acc@1: 84.3750 (85.5000)  Acc@5: 98.4375 (98.3333)
Train: Epoch[ 7/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000244  Loss: 0.8536  Acc@1: 81.2500 (81.2500)  Acc@5: 96.8750 (96.8750)  time: 2.8039  data: 0.8307  max mem: 6674
Train: Epoch[ 7/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000244  Loss: 0.6072  Acc@1: 85.9375 (87.8333)  Acc@5: 96.8750 (98.0000)  time: 1.7632  data: 0.0832  max mem: 6674
Train: Epoch[ 7/60] Total time: 0:00:17 (1.7696 s / it)
Averaged stats: Lr: 0.000244  Loss: 0.6072  Acc@1: 85.9375 (87.8333)  Acc@5: 96.8750 (98.0000)
Train: Epoch[ 8/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000242  Loss: 0.6685  Acc@1: 85.9375 (85.9375)  Acc@5: 96.8750 (96.8750)  time: 2.8563  data: 0.7701  max mem: 6674
Train: Epoch[ 8/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000242  Loss: 0.3541  Acc@1: 89.0625 (88.1667)  Acc@5: 96.8750 (97.6667)  time: 1.7857  data: 0.0772  max mem: 6674
Train: Epoch[ 8/60] Total time: 0:00:17 (1.7931 s / it)
Averaged stats: Lr: 0.000242  Loss: 0.3541  Acc@1: 89.0625 (88.1667)  Acc@5: 96.8750 (97.6667)
Train: Epoch[ 9/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000239  Loss: 0.5967  Acc@1: 84.3750 (84.3750)  Acc@5: 95.3125 (95.3125)  time: 2.7778  data: 0.7470  max mem: 6674
Train: Epoch[ 9/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000239  Loss: 0.6638  Acc@1: 87.5000 (88.8333)  Acc@5: 98.4375 (98.3333)  time: 1.7576  data: 0.0748  max mem: 6674
Train: Epoch[ 9/60] Total time: 0:00:17 (1.7636 s / it)
Averaged stats: Lr: 0.000239  Loss: 0.6638  Acc@1: 87.5000 (88.8333)  Acc@5: 98.4375 (98.3333)
Train: Epoch[10/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000236  Loss: 0.5269  Acc@1: 90.6250 (90.6250)  Acc@5: 98.4375 (98.4375)  time: 2.7270  data: 0.6642  max mem: 6674
Train: Epoch[10/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000236  Loss: 0.5237  Acc@1: 89.0625 (89.3333)  Acc@5: 98.4375 (98.1667)  time: 1.7549  data: 0.0666  max mem: 6674
Train: Epoch[10/60] Total time: 0:00:17 (1.7613 s / it)
Averaged stats: Lr: 0.000236  Loss: 0.5237  Acc@1: 89.0625 (89.3333)  Acc@5: 98.4375 (98.1667)
Train: Epoch[11/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000233  Loss: 0.6152  Acc@1: 87.5000 (87.5000)  Acc@5: 95.3125 (95.3125)  time: 2.7987  data: 0.7945  max mem: 6674
Train: Epoch[11/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000233  Loss: 0.3515  Acc@1: 87.5000 (90.0000)  Acc@5: 98.4375 (98.6667)  time: 1.7815  data: 0.0796  max mem: 6674
Train: Epoch[11/60] Total time: 0:00:17 (1.7879 s / it)
Averaged stats: Lr: 0.000233  Loss: 0.3515  Acc@1: 87.5000 (90.0000)  Acc@5: 98.4375 (98.6667)
Train: Epoch[12/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000230  Loss: 0.3136  Acc@1: 95.3125 (95.3125)  Acc@5: 98.4375 (98.4375)  time: 2.7734  data: 0.6914  max mem: 6674
Train: Epoch[12/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000230  Loss: 0.4573  Acc@1: 91.6667 (91.8333)  Acc@5: 100.0000 (99.0000)  time: 1.7573  data: 0.0693  max mem: 6674
Train: Epoch[12/60] Total time: 0:00:17 (1.7647 s / it)
Averaged stats: Lr: 0.000230  Loss: 0.4573  Acc@1: 91.6667 (91.8333)  Acc@5: 100.0000 (99.0000)
Train: Epoch[13/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000226  Loss: 0.5222  Acc@1: 85.9375 (85.9375)  Acc@5: 95.3125 (95.3125)  time: 2.8312  data: 0.8322  max mem: 6674
Train: Epoch[13/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000226  Loss: 0.6980  Acc@1: 87.5000 (89.5000)  Acc@5: 98.4375 (98.1667)  time: 1.7640  data: 0.0834  max mem: 6674
Train: Epoch[13/60] Total time: 0:00:17 (1.7704 s / it)
Averaged stats: Lr: 0.000226  Loss: 0.6980  Acc@1: 87.5000 (89.5000)  Acc@5: 98.4375 (98.1667)
Train: Epoch[14/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000222  Loss: 0.3880  Acc@1: 89.0625 (89.0625)  Acc@5: 98.4375 (98.4375)  time: 2.7443  data: 0.6806  max mem: 6674
Train: Epoch[14/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000222  Loss: 0.4435  Acc@1: 92.1875 (92.6667)  Acc@5: 98.4375 (98.8333)  time: 1.7763  data: 0.0682  max mem: 6674
Train: Epoch[14/60] Total time: 0:00:17 (1.7829 s / it)
Averaged stats: Lr: 0.000222  Loss: 0.4435  Acc@1: 92.1875 (92.6667)  Acc@5: 98.4375 (98.8333)
Train: Epoch[15/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000218  Loss: 0.3019  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 2.9102  data: 0.9659  max mem: 6674
Train: Epoch[15/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000218  Loss: 0.3411  Acc@1: 93.7500 (92.6667)  Acc@5: 98.4375 (98.6667)  time: 1.7767  data: 0.0967  max mem: 6674
Train: Epoch[15/60] Total time: 0:00:17 (1.7829 s / it)
Averaged stats: Lr: 0.000218  Loss: 0.3411  Acc@1: 93.7500 (92.6667)  Acc@5: 98.4375 (98.6667)
Train: Epoch[16/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000213  Loss: 0.3794  Acc@1: 90.6250 (90.6250)  Acc@5: 98.4375 (98.4375)  time: 2.8098  data: 0.7218  max mem: 6674
Train: Epoch[16/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000213  Loss: 0.1389  Acc@1: 95.3125 (94.3333)  Acc@5: 98.4375 (98.6667)  time: 1.7633  data: 0.0723  max mem: 6674
Train: Epoch[16/60] Total time: 0:00:17 (1.7710 s / it)
Averaged stats: Lr: 0.000213  Loss: 0.1389  Acc@1: 95.3125 (94.3333)  Acc@5: 98.4375 (98.6667)
Train: Epoch[17/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000209  Loss: 0.1743  Acc@1: 96.8750 (96.8750)  Acc@5: 100.0000 (100.0000)  time: 2.8309  data: 0.8409  max mem: 6674
Train: Epoch[17/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000209  Loss: 0.3560  Acc@1: 92.1875 (92.3333)  Acc@5: 98.4375 (98.0000)  time: 1.7889  data: 0.0842  max mem: 6674
Train: Epoch[17/60] Total time: 0:00:17 (1.7957 s / it)
Averaged stats: Lr: 0.000209  Loss: 0.3560  Acc@1: 92.1875 (92.3333)  Acc@5: 98.4375 (98.0000)
Train: Epoch[18/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000204  Loss: 0.2742  Acc@1: 95.3125 (95.3125)  Acc@5: 100.0000 (100.0000)  time: 2.8111  data: 0.8600  max mem: 6674
Train: Epoch[18/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000204  Loss: 0.3199  Acc@1: 92.1875 (93.1667)  Acc@5: 98.4375 (99.0000)  time: 1.7701  data: 0.0861  max mem: 6674
Train: Epoch[18/60] Total time: 0:00:17 (1.7770 s / it)
Averaged stats: Lr: 0.000204  Loss: 0.3199  Acc@1: 92.1875 (93.1667)  Acc@5: 98.4375 (99.0000)
Train: Epoch[19/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000198  Loss: 0.3186  Acc@1: 93.7500 (93.7500)  Acc@5: 98.4375 (98.4375)  time: 2.7740  data: 0.7006  max mem: 6674
Train: Epoch[19/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000198  Loss: 0.1231  Acc@1: 93.7500 (93.8333)  Acc@5: 98.4375 (99.0000)  time: 1.7613  data: 0.0702  max mem: 6674
Train: Epoch[19/60] Total time: 0:00:17 (1.7675 s / it)
Averaged stats: Lr: 0.000198  Loss: 0.1231  Acc@1: 93.7500 (93.8333)  Acc@5: 98.4375 (99.0000)
Train: Epoch[20/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000193  Loss: 0.2412  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)  time: 2.9505  data: 0.7974  max mem: 6674
Train: Epoch[20/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000193  Loss: 0.4692  Acc@1: 93.7500 (94.1667)  Acc@5: 98.4375 (99.1667)  time: 1.7983  data: 0.0799  max mem: 6674
Train: Epoch[20/60] Total time: 0:00:18 (1.8072 s / it)
Averaged stats: Lr: 0.000193  Loss: 0.4692  Acc@1: 93.7500 (94.1667)  Acc@5: 98.4375 (99.1667)
Train: Epoch[21/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000188  Loss: 0.3121  Acc@1: 92.1875 (92.1875)  Acc@5: 98.4375 (98.4375)  time: 2.8377  data: 0.7220  max mem: 6674
Train: Epoch[21/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000188  Loss: 0.1336  Acc@1: 93.7500 (93.8333)  Acc@5: 100.0000 (99.1667)  time: 1.7700  data: 0.0723  max mem: 6674
Train: Epoch[21/60] Total time: 0:00:17 (1.7762 s / it)
Averaged stats: Lr: 0.000188  Loss: 0.1336  Acc@1: 93.7500 (93.8333)  Acc@5: 100.0000 (99.1667)
Train: Epoch[22/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000182  Loss: 0.2524  Acc@1: 93.7500 (93.7500)  Acc@5: 98.4375 (98.4375)  time: 2.7967  data: 0.6864  max mem: 6674
Train: Epoch[22/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000182  Loss: 0.1297  Acc@1: 93.7500 (94.5000)  Acc@5: 100.0000 (99.3333)  time: 1.7868  data: 0.0688  max mem: 6674
Train: Epoch[22/60] Total time: 0:00:17 (1.7940 s / it)
Averaged stats: Lr: 0.000182  Loss: 0.1297  Acc@1: 93.7500 (94.5000)  Acc@5: 100.0000 (99.3333)
Train: Epoch[23/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000176  Loss: 0.1904  Acc@1: 98.4375 (98.4375)  Acc@5: 98.4375 (98.4375)  time: 2.8332  data: 0.7936  max mem: 6674
Train: Epoch[23/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000176  Loss: 0.1237  Acc@1: 93.7500 (93.5000)  Acc@5: 100.0000 (98.6667)  time: 1.7721  data: 0.0795  max mem: 6674
Train: Epoch[23/60] Total time: 0:00:17 (1.7785 s / it)
Averaged stats: Lr: 0.000176  Loss: 0.1237  Acc@1: 93.7500 (93.5000)  Acc@5: 100.0000 (98.6667)
Train: Epoch[24/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000170  Loss: 0.2447  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)  time: 2.8010  data: 0.7926  max mem: 6674
Train: Epoch[24/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000170  Loss: 0.4277  Acc@1: 90.6250 (93.0000)  Acc@5: 100.0000 (99.0000)  time: 1.7652  data: 0.0794  max mem: 6674
Train: Epoch[24/60] Total time: 0:00:17 (1.7730 s / it)
Averaged stats: Lr: 0.000170  Loss: 0.4277  Acc@1: 90.6250 (93.0000)  Acc@5: 100.0000 (99.0000)
Train: Epoch[25/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000164  Loss: 0.3223  Acc@1: 90.6250 (90.6250)  Acc@5: 98.4375 (98.4375)  time: 2.7530  data: 0.7035  max mem: 6674
Train: Epoch[25/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000164  Loss: 0.1822  Acc@1: 95.3125 (94.5000)  Acc@5: 98.4375 (98.6667)  time: 1.7773  data: 0.0705  max mem: 6674
Train: Epoch[25/60] Total time: 0:00:17 (1.7839 s / it)
Averaged stats: Lr: 0.000164  Loss: 0.1822  Acc@1: 95.3125 (94.5000)  Acc@5: 98.4375 (98.6667)
Train: Epoch[26/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000157  Loss: 0.1638  Acc@1: 98.4375 (98.4375)  Acc@5: 100.0000 (100.0000)  time: 2.7340  data: 0.6706  max mem: 6674
Train: Epoch[26/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000157  Loss: 0.3837  Acc@1: 95.3125 (95.8333)  Acc@5: 100.0000 (99.3333)  time: 1.7544  data: 0.0672  max mem: 6674
Train: Epoch[26/60] Total time: 0:00:17 (1.7621 s / it)
Averaged stats: Lr: 0.000157  Loss: 0.3837  Acc@1: 95.3125 (95.8333)  Acc@5: 100.0000 (99.3333)
Train: Epoch[27/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000151  Loss: 0.1824  Acc@1: 96.8750 (96.8750)  Acc@5: 100.0000 (100.0000)  time: 2.7649  data: 0.6780  max mem: 6674
Train: Epoch[27/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000151  Loss: 0.1847  Acc@1: 93.7500 (93.5000)  Acc@5: 98.4375 (98.5000)  time: 1.7555  data: 0.0679  max mem: 6674
Train: Epoch[27/60] Total time: 0:00:17 (1.7616 s / it)
Averaged stats: Lr: 0.000151  Loss: 0.1847  Acc@1: 93.7500 (93.5000)  Acc@5: 98.4375 (98.5000)
Train: Epoch[28/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000145  Loss: 0.2933  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)  time: 2.7615  data: 0.8079  max mem: 6674
Train: Epoch[28/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000145  Loss: 0.1440  Acc@1: 93.7500 (94.6667)  Acc@5: 98.4375 (98.5000)  time: 1.7709  data: 0.0809  max mem: 6674
Train: Epoch[28/60] Total time: 0:00:17 (1.7776 s / it)
Averaged stats: Lr: 0.000145  Loss: 0.1440  Acc@1: 93.7500 (94.6667)  Acc@5: 98.4375 (98.5000)
Train: Epoch[29/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000138  Loss: 0.2702  Acc@1: 93.7500 (93.7500)  Acc@5: 98.4375 (98.4375)  time: 2.7870  data: 0.8519  max mem: 6674
Train: Epoch[29/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000138  Loss: 0.1369  Acc@1: 95.3125 (95.0000)  Acc@5: 98.4375 (99.1667)  time: 1.7650  data: 0.0853  max mem: 6674
Train: Epoch[29/60] Total time: 0:00:17 (1.7713 s / it)
Averaged stats: Lr: 0.000138  Loss: 0.1369  Acc@1: 95.3125 (95.0000)  Acc@5: 98.4375 (99.1667)
Train: Epoch[30/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000132  Loss: 0.2011  Acc@1: 93.7500 (93.7500)  Acc@5: 98.4375 (98.4375)  time: 2.8066  data: 0.6998  max mem: 6674
Train: Epoch[30/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000132  Loss: 0.0274  Acc@1: 93.7500 (92.8333)  Acc@5: 98.4375 (98.8333)  time: 1.7646  data: 0.0701  max mem: 6674
Train: Epoch[30/60] Total time: 0:00:17 (1.7716 s / it)
Averaged stats: Lr: 0.000132  Loss: 0.0274  Acc@1: 93.7500 (92.8333)  Acc@5: 98.4375 (98.8333)
Train: Epoch[31/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000125  Loss: 0.1697  Acc@1: 96.8750 (96.8750)  Acc@5: 100.0000 (100.0000)  time: 2.8333  data: 0.8697  max mem: 6674
Train: Epoch[31/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000125  Loss: 0.1341  Acc@1: 95.3125 (94.8333)  Acc@5: 100.0000 (99.5000)  time: 1.7869  data: 0.0871  max mem: 6674
Train: Epoch[31/60] Total time: 0:00:17 (1.7938 s / it)
Averaged stats: Lr: 0.000125  Loss: 0.1341  Acc@1: 95.3125 (94.8333)  Acc@5: 100.0000 (99.5000)
Train: Epoch[32/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000118  Loss: 0.1265  Acc@1: 98.4375 (98.4375)  Acc@5: 98.4375 (98.4375)  time: 2.7785  data: 0.6938  max mem: 6674
Train: Epoch[32/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000118  Loss: 0.2854  Acc@1: 95.3125 (95.1667)  Acc@5: 98.4375 (99.1667)  time: 1.7665  data: 0.0695  max mem: 6674
Train: Epoch[32/60] Total time: 0:00:17 (1.7732 s / it)
Averaged stats: Lr: 0.000118  Loss: 0.2854  Acc@1: 95.3125 (95.1667)  Acc@5: 98.4375 (99.1667)
Train: Epoch[33/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000112  Loss: 0.2174  Acc@1: 95.3125 (95.3125)  Acc@5: 98.4375 (98.4375)  time: 2.7821  data: 0.7277  max mem: 6674
Train: Epoch[33/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000112  Loss: 0.2669  Acc@1: 95.3125 (95.0000)  Acc@5: 98.4375 (98.6667)  time: 1.7637  data: 0.0729  max mem: 6674
Train: Epoch[33/60] Total time: 0:00:17 (1.7697 s / it)
Averaged stats: Lr: 0.000112  Loss: 0.2669  Acc@1: 95.3125 (95.0000)  Acc@5: 98.4375 (98.6667)
Train: Epoch[34/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000105  Loss: 0.3069  Acc@1: 89.0625 (89.0625)  Acc@5: 98.4375 (98.4375)  time: 2.9441  data: 0.8369  max mem: 6674
Train: Epoch[34/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000105  Loss: 0.3491  Acc@1: 95.3125 (94.5000)  Acc@5: 98.4375 (99.1667)  time: 1.8007  data: 0.0838  max mem: 6674
Train: Epoch[34/60] Total time: 0:00:18 (1.8090 s / it)
Averaged stats: Lr: 0.000105  Loss: 0.3491  Acc@1: 95.3125 (94.5000)  Acc@5: 98.4375 (99.1667)
Train: Epoch[35/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000099  Loss: 0.0677  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 2.8962  data: 0.8604  max mem: 6674
Train: Epoch[35/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000099  Loss: 0.1157  Acc@1: 96.8750 (96.8333)  Acc@5: 100.0000 (99.6667)  time: 1.7786  data: 0.0862  max mem: 6674
Train: Epoch[35/60] Total time: 0:00:17 (1.7850 s / it)
Averaged stats: Lr: 0.000099  Loss: 0.1157  Acc@1: 96.8750 (96.8333)  Acc@5: 100.0000 (99.6667)
Train: Epoch[36/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000093  Loss: 0.2130  Acc@1: 93.7500 (93.7500)  Acc@5: 98.4375 (98.4375)  time: 2.7513  data: 0.7081  max mem: 6674
Train: Epoch[36/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000093  Loss: 0.0630  Acc@1: 93.7500 (94.6667)  Acc@5: 98.4375 (98.6667)  time: 1.7841  data: 0.0710  max mem: 6674
Train: Epoch[36/60] Total time: 0:00:17 (1.7924 s / it)
Averaged stats: Lr: 0.000093  Loss: 0.0630  Acc@1: 93.7500 (94.6667)  Acc@5: 98.4375 (98.6667)
Train: Epoch[37/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000086  Loss: 0.2545  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 2.8643  data: 0.9068  max mem: 6674
Train: Epoch[37/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000086  Loss: 0.3565  Acc@1: 95.3125 (95.5000)  Acc@5: 100.0000 (99.6667)  time: 1.7745  data: 0.0908  max mem: 6674
Train: Epoch[37/60] Total time: 0:00:17 (1.7809 s / it)
Averaged stats: Lr: 0.000086  Loss: 0.3565  Acc@1: 95.3125 (95.5000)  Acc@5: 100.0000 (99.6667)
Train: Epoch[38/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000080  Loss: 0.2018  Acc@1: 95.3125 (95.3125)  Acc@5: 100.0000 (100.0000)  time: 2.7670  data: 0.7700  max mem: 6674
Train: Epoch[38/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000080  Loss: 0.2975  Acc@1: 95.3125 (95.0000)  Acc@5: 100.0000 (99.5000)  time: 1.7586  data: 0.0772  max mem: 6674
Train: Epoch[38/60] Total time: 0:00:17 (1.7656 s / it)
Averaged stats: Lr: 0.000080  Loss: 0.2975  Acc@1: 95.3125 (95.0000)  Acc@5: 100.0000 (99.5000)
Train: Epoch[39/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000074  Loss: 0.2275  Acc@1: 96.8750 (96.8750)  Acc@5: 96.8750 (96.8750)  time: 2.7482  data: 0.7014  max mem: 6674
Train: Epoch[39/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000074  Loss: 0.2853  Acc@1: 93.7500 (94.3333)  Acc@5: 98.4375 (98.6667)  time: 1.7800  data: 0.0703  max mem: 6674
Train: Epoch[39/60] Total time: 0:00:17 (1.7867 s / it)
Averaged stats: Lr: 0.000074  Loss: 0.2853  Acc@1: 93.7500 (94.3333)  Acc@5: 98.4375 (98.6667)
Train: Epoch[40/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000068  Loss: 0.1257  Acc@1: 96.8750 (96.8750)  Acc@5: 100.0000 (100.0000)  time: 2.7705  data: 0.7812  max mem: 6674
Train: Epoch[40/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000068  Loss: 0.2001  Acc@1: 95.3125 (94.6667)  Acc@5: 100.0000 (99.5000)  time: 1.7610  data: 0.0783  max mem: 6674
Train: Epoch[40/60] Total time: 0:00:17 (1.7682 s / it)
Averaged stats: Lr: 0.000068  Loss: 0.2001  Acc@1: 95.3125 (94.6667)  Acc@5: 100.0000 (99.5000)
Train: Epoch[41/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000063  Loss: 0.2102  Acc@1: 95.3125 (95.3125)  Acc@5: 100.0000 (100.0000)  time: 2.7799  data: 0.8259  max mem: 6674
Train: Epoch[41/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000063  Loss: 0.1635  Acc@1: 96.8750 (96.3333)  Acc@5: 100.0000 (99.6667)  time: 1.7636  data: 0.0827  max mem: 6674
Train: Epoch[41/60] Total time: 0:00:17 (1.7697 s / it)
Averaged stats: Lr: 0.000063  Loss: 0.1635  Acc@1: 96.8750 (96.3333)  Acc@5: 100.0000 (99.6667)
Train: Epoch[42/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000057  Loss: 0.1878  Acc@1: 95.3125 (95.3125)  Acc@5: 98.4375 (98.4375)  time: 2.7757  data: 0.7579  max mem: 6674
Train: Epoch[42/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000057  Loss: 0.1717  Acc@1: 95.3125 (96.0000)  Acc@5: 98.4375 (99.1667)  time: 1.7834  data: 0.0759  max mem: 6674
Train: Epoch[42/60] Total time: 0:00:17 (1.7922 s / it)
Averaged stats: Lr: 0.000057  Loss: 0.1717  Acc@1: 95.3125 (96.0000)  Acc@5: 98.4375 (99.1667)
Train: Epoch[43/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000052  Loss: 0.2452  Acc@1: 95.3125 (95.3125)  Acc@5: 100.0000 (100.0000)  time: 2.7959  data: 0.7222  max mem: 6674
Train: Epoch[43/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000052  Loss: 0.1670  Acc@1: 95.3125 (96.0000)  Acc@5: 100.0000 (99.6667)  time: 1.7695  data: 0.0724  max mem: 6674
Train: Epoch[43/60] Total time: 0:00:17 (1.7755 s / it)
Averaged stats: Lr: 0.000052  Loss: 0.1670  Acc@1: 95.3125 (96.0000)  Acc@5: 100.0000 (99.6667)
Train: Epoch[44/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000046  Loss: 0.1507  Acc@1: 95.3125 (95.3125)  Acc@5: 100.0000 (100.0000)  time: 2.7814  data: 0.8076  max mem: 6674
Train: Epoch[44/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000046  Loss: 0.0781  Acc@1: 95.3125 (95.5000)  Acc@5: 100.0000 (100.0000)  time: 1.7637  data: 0.0809  max mem: 6674
Train: Epoch[44/60] Total time: 0:00:17 (1.7707 s / it)
Averaged stats: Lr: 0.000046  Loss: 0.0781  Acc@1: 95.3125 (95.5000)  Acc@5: 100.0000 (100.0000)
Train: Epoch[45/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000041  Loss: 0.1823  Acc@1: 95.3125 (95.3125)  Acc@5: 100.0000 (100.0000)  time: 2.8283  data: 0.7633  max mem: 6674
Train: Epoch[45/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000041  Loss: 0.3431  Acc@1: 93.7500 (94.8333)  Acc@5: 100.0000 (99.1667)  time: 1.7865  data: 0.0765  max mem: 6674
Train: Epoch[45/60] Total time: 0:00:17 (1.7930 s / it)
Averaged stats: Lr: 0.000041  Loss: 0.3431  Acc@1: 93.7500 (94.8333)  Acc@5: 100.0000 (99.1667)
Train: Epoch[46/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000037  Loss: 0.1873  Acc@1: 96.8750 (96.8750)  Acc@5: 98.4375 (98.4375)  time: 2.7590  data: 0.6795  max mem: 6674
Train: Epoch[46/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000037  Loss: 0.1075  Acc@1: 96.8750 (96.5000)  Acc@5: 100.0000 (99.3333)  time: 1.7630  data: 0.0681  max mem: 6674
Train: Epoch[46/60] Total time: 0:00:17 (1.7702 s / it)
Averaged stats: Lr: 0.000037  Loss: 0.1075  Acc@1: 96.8750 (96.5000)  Acc@5: 100.0000 (99.3333)
Train: Epoch[47/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000032  Loss: 0.1671  Acc@1: 95.3125 (95.3125)  Acc@5: 100.0000 (100.0000)  time: 2.8019  data: 0.7928  max mem: 6674
Train: Epoch[47/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000032  Loss: 0.0246  Acc@1: 93.7500 (94.3333)  Acc@5: 100.0000 (99.3333)  time: 1.7649  data: 0.0794  max mem: 6674
Train: Epoch[47/60] Total time: 0:00:17 (1.7715 s / it)
Averaged stats: Lr: 0.000032  Loss: 0.0246  Acc@1: 93.7500 (94.3333)  Acc@5: 100.0000 (99.3333)
Train: Epoch[48/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000028  Loss: 0.1426  Acc@1: 96.8750 (96.8750)  Acc@5: 100.0000 (100.0000)  time: 2.8272  data: 0.7827  max mem: 6674
Train: Epoch[48/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000028  Loss: 0.1062  Acc@1: 95.3125 (95.5000)  Acc@5: 100.0000 (99.6667)  time: 1.7856  data: 0.0784  max mem: 6674
Train: Epoch[48/60] Total time: 0:00:17 (1.7931 s / it)
Averaged stats: Lr: 0.000028  Loss: 0.1062  Acc@1: 95.3125 (95.5000)  Acc@5: 100.0000 (99.6667)
Train: Epoch[49/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000024  Loss: 0.2461  Acc@1: 95.3125 (95.3125)  Acc@5: 100.0000 (100.0000)  time: 2.8063  data: 0.7947  max mem: 6674
Train: Epoch[49/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000024  Loss: 0.3388  Acc@1: 93.7500 (94.5000)  Acc@5: 100.0000 (99.5000)  time: 1.7685  data: 0.0796  max mem: 6674
Train: Epoch[49/60] Total time: 0:00:17 (1.7747 s / it)
Averaged stats: Lr: 0.000024  Loss: 0.3388  Acc@1: 93.7500 (94.5000)  Acc@5: 100.0000 (99.5000)
Train: Epoch[50/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000020  Loss: 0.1556  Acc@1: 95.3125 (95.3125)  Acc@5: 98.4375 (98.4375)  time: 2.7728  data: 0.6884  max mem: 6674
Train: Epoch[50/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000020  Loss: 0.0905  Acc@1: 95.3125 (96.0000)  Acc@5: 98.4375 (99.1667)  time: 1.7844  data: 0.0690  max mem: 6674
Train: Epoch[50/60] Total time: 0:00:17 (1.7913 s / it)
Averaged stats: Lr: 0.000020  Loss: 0.0905  Acc@1: 95.3125 (96.0000)  Acc@5: 98.4375 (99.1667)
Train: Epoch[51/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000017  Loss: 0.2720  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)  time: 2.7705  data: 0.7462  max mem: 6674
Train: Epoch[51/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000017  Loss: 0.1459  Acc@1: 95.8333 (94.8333)  Acc@5: 98.4375 (98.8333)  time: 1.7643  data: 0.0748  max mem: 6674
Train: Epoch[51/60] Total time: 0:00:17 (1.7710 s / it)
Averaged stats: Lr: 0.000017  Loss: 0.1459  Acc@1: 95.8333 (94.8333)  Acc@5: 98.4375 (98.8333)
Train: Epoch[52/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000014  Loss: 0.2399  Acc@1: 95.3125 (95.3125)  Acc@5: 98.4375 (98.4375)  time: 2.8731  data: 0.8586  max mem: 6674
Train: Epoch[52/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000014  Loss: 0.0370  Acc@1: 95.3125 (95.5000)  Acc@5: 100.0000 (99.3333)  time: 1.7651  data: 0.0860  max mem: 6674
Train: Epoch[52/60] Total time: 0:00:17 (1.7715 s / it)
Averaged stats: Lr: 0.000014  Loss: 0.0370  Acc@1: 95.3125 (95.5000)  Acc@5: 100.0000 (99.3333)
Train: Epoch[53/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000011  Loss: 0.1210  Acc@1: 98.4375 (98.4375)  Acc@5: 100.0000 (100.0000)  time: 2.8384  data: 0.8143  max mem: 6674
Train: Epoch[53/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000011  Loss: 0.0717  Acc@1: 96.8750 (97.0000)  Acc@5: 100.0000 (99.3333)  time: 1.7818  data: 0.0816  max mem: 6674
Train: Epoch[53/60] Total time: 0:00:17 (1.7886 s / it)
Averaged stats: Lr: 0.000011  Loss: 0.0717  Acc@1: 96.8750 (97.0000)  Acc@5: 100.0000 (99.3333)
Train: Epoch[54/60]  [ 0/10]  eta: 0:00:26  Lr: 0.000008  Loss: 0.2626  Acc@1: 93.7500 (93.7500)  Acc@5: 98.4375 (98.4375)  time: 2.6163  data: 0.6460  max mem: 6674
Train: Epoch[54/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000008  Loss: 0.2606  Acc@1: 93.7500 (94.3333)  Acc@5: 100.0000 (99.1667)  time: 1.7440  data: 0.0648  max mem: 6674
Train: Epoch[54/60] Total time: 0:00:17 (1.7522 s / it)
Averaged stats: Lr: 0.000008  Loss: 0.2606  Acc@1: 93.7500 (94.3333)  Acc@5: 100.0000 (99.1667)
Train: Epoch[55/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000006  Loss: 0.1517  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 2.7603  data: 0.6998  max mem: 6674
Train: Epoch[55/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000006  Loss: 0.2217  Acc@1: 93.7500 (94.3333)  Acc@5: 100.0000 (99.5000)  time: 1.7520  data: 0.0701  max mem: 6674
Train: Epoch[55/60] Total time: 0:00:17 (1.7582 s / it)
Averaged stats: Lr: 0.000006  Loss: 0.2217  Acc@1: 93.7500 (94.3333)  Acc@5: 100.0000 (99.5000)
Train: Epoch[56/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000004  Loss: 0.1321  Acc@1: 96.8750 (96.8750)  Acc@5: 100.0000 (100.0000)  time: 2.7503  data: 0.7559  max mem: 6674
Train: Epoch[56/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000004  Loss: 0.2239  Acc@1: 95.3125 (94.5000)  Acc@5: 98.4375 (98.8333)  time: 1.7725  data: 0.0757  max mem: 6674
Train: Epoch[56/60] Total time: 0:00:17 (1.7796 s / it)
Averaged stats: Lr: 0.000004  Loss: 0.2239  Acc@1: 95.3125 (94.5000)  Acc@5: 98.4375 (98.8333)
Train: Epoch[57/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000003  Loss: 0.2514  Acc@1: 95.3125 (95.3125)  Acc@5: 98.4375 (98.4375)  time: 2.8383  data: 0.8048  max mem: 6674
Train: Epoch[57/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000003  Loss: 0.4824  Acc@1: 95.3125 (95.5000)  Acc@5: 100.0000 (99.3333)  time: 1.7628  data: 0.0806  max mem: 6674
Train: Epoch[57/60] Total time: 0:00:17 (1.7689 s / it)
Averaged stats: Lr: 0.000003  Loss: 0.4824  Acc@1: 95.3125 (95.5000)  Acc@5: 100.0000 (99.3333)
Train: Epoch[58/60]  [ 0/10]  eta: 0:00:26  Lr: 0.000002  Loss: 0.1270  Acc@1: 98.4375 (98.4375)  Acc@5: 98.4375 (98.4375)  time: 2.6811  data: 0.6902  max mem: 6674
Train: Epoch[58/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000002  Loss: 0.2875  Acc@1: 93.7500 (94.8333)  Acc@5: 100.0000 (99.5000)  time: 1.7467  data: 0.0692  max mem: 6674
Train: Epoch[58/60] Total time: 0:00:17 (1.7544 s / it)
Averaged stats: Lr: 0.000002  Loss: 0.2875  Acc@1: 93.7500 (94.8333)  Acc@5: 100.0000 (99.5000)
Train: Epoch[59/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000001  Loss: 0.2234  Acc@1: 96.8750 (96.8750)  Acc@5: 100.0000 (100.0000)  time: 2.7381  data: 0.7158  max mem: 6674
Train: Epoch[59/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000001  Loss: 0.6294  Acc@1: 95.3125 (95.5000)  Acc@5: 100.0000 (99.5000)  time: 1.7698  data: 0.0717  max mem: 6674
Train: Epoch[59/60] Total time: 0:00:17 (1.7766 s / it)
Averaged stats: Lr: 0.000001  Loss: 0.6294  Acc@1: 95.3125 (95.5000)  Acc@5: 100.0000 (99.5000)
Train: Epoch[60/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000000  Loss: 0.2337  Acc@1: 96.8750 (96.8750)  Acc@5: 100.0000 (100.0000)  time: 2.7630  data: 0.6810  max mem: 6674
Train: Epoch[60/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000000  Loss: 0.2849  Acc@1: 96.8750 (96.6667)  Acc@5: 100.0000 (99.6667)  time: 1.7583  data: 0.0682  max mem: 6674
Train: Epoch[60/60] Total time: 0:00:17 (1.7652 s / it)
Averaged stats: Lr: 0.000000  Loss: 0.2849  Acc@1: 96.8750 (96.6667)  Acc@5: 100.0000 (99.6667)
Test: [Task 1]  [0/9]  eta: 0:00:13  Loss: 0.2193 (0.2193)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)  time: 1.5300  data: 0.8858  max mem: 6674
Test: [Task 1]  [8/9]  eta: 0:00:00  Loss: 0.0714 (0.1170)  Acc@1: 98.4375 (96.1165)  Acc@5: 100.0000 (100.0000)  time: 0.6230  data: 0.0986  max mem: 6674
Test: [Task 1] Total time: 0:00:05 (0.6302 s / it)
* Acc@1 96.117 Acc@5 100.000 loss 0.117
Batchwise eval time for task 1 = 0.6302753289540609
[Average accuracy till task1]	Acc@1: 96.1165	Acc@5: 100.0000	Loss: 0.1170
Eval time for task 1 = 5.706938743591309
Using adam optimizer
Reinitialising optimizer
modules.json: 100%|█████████████████████████████| 229/229 [00:00<00:00, 121kB/s]
config_sentence_transformers.json: 100%|███████| 116/116 [00:00<00:00, 64.6kB/s]
README.md: 5.41kB [00:00, 15.2MB/s]
sentence_bert_config.json: 100%|█████████████| 52.0/52.0 [00:00<00:00, 30.5kB/s]
/kaggle/working/venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
config.json: 100%|██████████████████████████████| 670/670 [00:00<00:00, 372kB/s]
pytorch_model.bin: 100%|██████████████████████| 438M/438M [00:02<00:00, 185MB/s]
/kaggle/working/venv/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
tokenizer_config.json: 100%|████████████████████| 632/632 [00:00<00:00, 374kB/s]
vocab.txt: 232kB [00:00, 13.3MB/s]
tokenizer.json: 466kB [00:00, 21.2MB/s]
special_tokens_map.json: 100%|█████████████████| 112/112 [00:00<00:00, 60.1kB/s]
config.json: 100%|█████████████████████████████| 190/190 [00:00<00:00, 23.9kB/s]
Similarity:  tensor(0.9186)  Task:  1
Old Num K:  5 New Num K:  6
Task number:  1
Train: Epoch[ 1/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000250  Loss: 3.0878  Acc@1: 0.0000 (0.0000)  Acc@5: 3.1250 (3.1250)  time: 2.8538  data: 0.7508  max mem: 6729
Train: Epoch[ 1/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000250  Loss: 3.1474  Acc@1: 0.0000 (0.3333)  Acc@5: 7.8125 (10.6667)  time: 1.6753  data: 0.0752  max mem: 6739
Train: Epoch[ 1/60] Total time: 0:00:16 (1.6850 s / it)
Averaged stats: Lr: 0.000250  Loss: 3.1474  Acc@1: 0.0000 (0.3333)  Acc@5: 7.8125 (10.6667)
Train: Epoch[ 2/60]  [ 0/10]  eta: 0:00:26  Lr: 0.000250  Loss: 2.7747  Acc@1: 0.0000 (0.0000)  Acc@5: 31.2500 (31.2500)  time: 2.6599  data: 0.8242  max mem: 6740
Train: Epoch[ 2/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000250  Loss: 2.2504  Acc@1: 3.1250 (4.8333)  Acc@5: 46.8750 (45.6667)  time: 1.6571  data: 0.0826  max mem: 6740
Train: Epoch[ 2/60] Total time: 0:00:16 (1.6651 s / it)
Averaged stats: Lr: 0.000250  Loss: 2.2504  Acc@1: 3.1250 (4.8333)  Acc@5: 46.8750 (45.6667)
Train: Epoch[ 3/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000249  Loss: 2.1986  Acc@1: 20.3125 (20.3125)  Acc@5: 70.3125 (70.3125)  time: 2.7372  data: 0.8711  max mem: 6740
Train: Epoch[ 3/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000249  Loss: 1.9167  Acc@1: 18.7500 (19.5000)  Acc@5: 70.3125 (71.3333)  time: 1.6641  data: 0.0872  max mem: 6740
Train: Epoch[ 3/60] Total time: 0:00:16 (1.6731 s / it)
Averaged stats: Lr: 0.000249  Loss: 1.9167  Acc@1: 18.7500 (19.5000)  Acc@5: 70.3125 (71.3333)
Train: Epoch[ 4/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000248  Loss: 1.8037  Acc@1: 21.8750 (21.8750)  Acc@5: 79.6875 (79.6875)  time: 2.7658  data: 0.8270  max mem: 6740
Train: Epoch[ 4/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000248  Loss: 1.4009  Acc@1: 25.0000 (28.0000)  Acc@5: 79.6875 (80.1667)  time: 1.6709  data: 0.0828  max mem: 6740
Train: Epoch[ 4/60] Total time: 0:00:16 (1.6790 s / it)
Averaged stats: Lr: 0.000248  Loss: 1.4009  Acc@1: 25.0000 (28.0000)  Acc@5: 79.6875 (80.1667)
Train: Epoch[ 5/60]  [ 0/10]  eta: 0:00:26  Lr: 0.000247  Loss: 1.5294  Acc@1: 31.2500 (31.2500)  Acc@5: 85.9375 (85.9375)  time: 2.6959  data: 0.8822  max mem: 6740
Train: Epoch[ 5/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000247  Loss: 1.4324  Acc@1: 29.6875 (32.8333)  Acc@5: 87.5000 (87.1667)  time: 1.6584  data: 0.0883  max mem: 6740
Train: Epoch[ 5/60] Total time: 0:00:16 (1.6677 s / it)
Averaged stats: Lr: 0.000247  Loss: 1.4324  Acc@1: 29.6875 (32.8333)  Acc@5: 87.5000 (87.1667)
Train: Epoch[ 6/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000246  Loss: 1.3744  Acc@1: 28.1250 (28.1250)  Acc@5: 85.9375 (85.9375)  time: 2.7804  data: 0.9110  max mem: 6740
Train: Epoch[ 6/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000246  Loss: 1.3276  Acc@1: 37.5000 (39.0000)  Acc@5: 89.0625 (89.1667)  time: 1.6707  data: 0.0913  max mem: 6740
Train: Epoch[ 6/60] Total time: 0:00:16 (1.6787 s / it)
Averaged stats: Lr: 0.000246  Loss: 1.3276  Acc@1: 37.5000 (39.0000)  Acc@5: 89.0625 (89.1667)
Train: Epoch[ 7/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000244  Loss: 1.3558  Acc@1: 37.5000 (37.5000)  Acc@5: 76.5625 (76.5625)  time: 2.7018  data: 0.7290  max mem: 6740
Train: Epoch[ 7/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000244  Loss: 1.1284  Acc@1: 46.8750 (46.0000)  Acc@5: 90.6250 (89.0000)  time: 1.6700  data: 0.0730  max mem: 6740
Train: Epoch[ 7/60] Total time: 0:00:16 (1.6794 s / it)
Averaged stats: Lr: 0.000244  Loss: 1.1284  Acc@1: 46.8750 (46.0000)  Acc@5: 90.6250 (89.0000)
Train: Epoch[ 8/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000242  Loss: 1.0430  Acc@1: 51.5625 (51.5625)  Acc@5: 92.1875 (92.1875)  time: 2.7676  data: 0.8199  max mem: 6740
Train: Epoch[ 8/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000242  Loss: 1.1707  Acc@1: 51.5625 (52.5000)  Acc@5: 92.1875 (92.6667)  time: 1.6753  data: 0.0821  max mem: 6740
Train: Epoch[ 8/60] Total time: 0:00:16 (1.6840 s / it)
Averaged stats: Lr: 0.000242  Loss: 1.1707  Acc@1: 51.5625 (52.5000)  Acc@5: 92.1875 (92.6667)
Train: Epoch[ 9/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000239  Loss: 0.9151  Acc@1: 50.0000 (50.0000)  Acc@5: 95.3125 (95.3125)  time: 3.1235  data: 0.9672  max mem: 6740
Train: Epoch[ 9/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000239  Loss: 1.0077  Acc@1: 54.6875 (56.3333)  Acc@5: 93.7500 (92.5000)  time: 1.7252  data: 0.0969  max mem: 6740
Train: Epoch[ 9/60] Total time: 0:00:17 (1.7356 s / it)
Averaged stats: Lr: 0.000239  Loss: 1.0077  Acc@1: 54.6875 (56.3333)  Acc@5: 93.7500 (92.5000)
Train: Epoch[10/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000236  Loss: 0.8931  Acc@1: 59.3750 (59.3750)  Acc@5: 95.3125 (95.3125)  time: 2.8902  data: 0.7685  max mem: 6740
Train: Epoch[10/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000236  Loss: 0.8381  Acc@1: 59.3750 (60.8333)  Acc@5: 93.7500 (93.6667)  time: 1.6856  data: 0.0771  max mem: 6740
Train: Epoch[10/60] Total time: 0:00:16 (1.6934 s / it)
Averaged stats: Lr: 0.000236  Loss: 0.8381  Acc@1: 59.3750 (60.8333)  Acc@5: 93.7500 (93.6667)
Train: Epoch[11/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000233  Loss: 0.9357  Acc@1: 54.6875 (54.6875)  Acc@5: 96.8750 (96.8750)  time: 2.7730  data: 0.8127  max mem: 6740
Train: Epoch[11/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000233  Loss: 1.1301  Acc@1: 59.3750 (61.8333)  Acc@5: 93.7500 (94.0000)  time: 1.6759  data: 0.0814  max mem: 6740
Train: Epoch[11/60] Total time: 0:00:16 (1.6855 s / it)
Averaged stats: Lr: 0.000233  Loss: 1.1301  Acc@1: 59.3750 (61.8333)  Acc@5: 93.7500 (94.0000)
Train: Epoch[12/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000230  Loss: 0.8068  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (93.7500)  time: 2.7157  data: 0.7249  max mem: 6740
Train: Epoch[12/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000230  Loss: 0.9121  Acc@1: 64.0625 (63.0000)  Acc@5: 93.7500 (95.0000)  time: 1.6657  data: 0.0726  max mem: 6740
Train: Epoch[12/60] Total time: 0:00:16 (1.6738 s / it)
Averaged stats: Lr: 0.000230  Loss: 0.9121  Acc@1: 64.0625 (63.0000)  Acc@5: 93.7500 (95.0000)
Train: Epoch[13/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000226  Loss: 0.8321  Acc@1: 59.3750 (59.3750)  Acc@5: 95.3125 (95.3125)  time: 2.7515  data: 0.8560  max mem: 6740
Train: Epoch[13/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000226  Loss: 0.8647  Acc@1: 64.0625 (64.6667)  Acc@5: 95.3125 (96.0000)  time: 1.6711  data: 0.0857  max mem: 6740
Train: Epoch[13/60] Total time: 0:00:16 (1.6801 s / it)
Averaged stats: Lr: 0.000226  Loss: 0.8647  Acc@1: 64.0625 (64.6667)  Acc@5: 95.3125 (96.0000)
Train: Epoch[14/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000222  Loss: 0.7227  Acc@1: 71.8750 (71.8750)  Acc@5: 96.8750 (96.8750)  time: 2.7181  data: 0.7696  max mem: 6740
Train: Epoch[14/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000222  Loss: 0.8472  Acc@1: 70.3125 (69.3333)  Acc@5: 93.7500 (94.6667)  time: 1.6690  data: 0.0771  max mem: 6740
Train: Epoch[14/60] Total time: 0:00:16 (1.6771 s / it)
Averaged stats: Lr: 0.000222  Loss: 0.8472  Acc@1: 70.3125 (69.3333)  Acc@5: 93.7500 (94.6667)
Train: Epoch[15/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000218  Loss: 0.9477  Acc@1: 60.9375 (60.9375)  Acc@5: 89.0625 (89.0625)  time: 2.7463  data: 0.8020  max mem: 6740
Train: Epoch[15/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000218  Loss: 0.4870  Acc@1: 65.6250 (69.0000)  Acc@5: 95.3125 (95.1667)  time: 1.6721  data: 0.0803  max mem: 6740
Train: Epoch[15/60] Total time: 0:00:16 (1.6818 s / it)
Averaged stats: Lr: 0.000218  Loss: 0.4870  Acc@1: 65.6250 (69.0000)  Acc@5: 95.3125 (95.1667)
Train: Epoch[16/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000213  Loss: 0.6622  Acc@1: 79.6875 (79.6875)  Acc@5: 96.8750 (96.8750)  time: 2.7839  data: 0.9300  max mem: 6740
Train: Epoch[16/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000213  Loss: 0.7270  Acc@1: 71.8750 (71.3333)  Acc@5: 96.8750 (95.8333)  time: 1.6715  data: 0.0931  max mem: 6740
Train: Epoch[16/60] Total time: 0:00:16 (1.6794 s / it)
Averaged stats: Lr: 0.000213  Loss: 0.7270  Acc@1: 71.8750 (71.3333)  Acc@5: 96.8750 (95.8333)
Train: Epoch[17/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000209  Loss: 0.6634  Acc@1: 71.8750 (71.8750)  Acc@5: 96.8750 (96.8750)  time: 2.7362  data: 0.8769  max mem: 6740
Train: Epoch[17/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000209  Loss: 0.7926  Acc@1: 71.8750 (74.3333)  Acc@5: 95.8333 (95.0000)  time: 1.6673  data: 0.0878  max mem: 6740
Train: Epoch[17/60] Total time: 0:00:16 (1.6766 s / it)
Averaged stats: Lr: 0.000209  Loss: 0.7926  Acc@1: 71.8750 (74.3333)  Acc@5: 95.8333 (95.0000)
Train: Epoch[18/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000204  Loss: 0.7538  Acc@1: 75.0000 (75.0000)  Acc@5: 95.3125 (95.3125)  time: 2.8036  data: 0.8497  max mem: 6740
Train: Epoch[18/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000204  Loss: 0.6961  Acc@1: 73.4375 (73.1667)  Acc@5: 95.3125 (95.6667)  time: 1.6774  data: 0.0851  max mem: 6740
Train: Epoch[18/60] Total time: 0:00:16 (1.6854 s / it)
Averaged stats: Lr: 0.000204  Loss: 0.6961  Acc@1: 73.4375 (73.1667)  Acc@5: 95.3125 (95.6667)
Train: Epoch[19/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000198  Loss: 0.5502  Acc@1: 76.5625 (76.5625)  Acc@5: 100.0000 (100.0000)  time: 2.8729  data: 0.9731  max mem: 6740
Train: Epoch[19/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000198  Loss: 0.6158  Acc@1: 76.5625 (75.3333)  Acc@5: 96.8750 (97.3333)  time: 1.6892  data: 0.0974  max mem: 6740
Train: Epoch[19/60] Total time: 0:00:16 (1.6979 s / it)
Averaged stats: Lr: 0.000198  Loss: 0.6158  Acc@1: 76.5625 (75.3333)  Acc@5: 96.8750 (97.3333)
Train: Epoch[20/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000193  Loss: 0.6682  Acc@1: 78.1250 (78.1250)  Acc@5: 95.3125 (95.3125)  time: 2.8907  data: 0.8713  max mem: 6740
Train: Epoch[20/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000193  Loss: 0.7786  Acc@1: 76.5625 (74.8333)  Acc@5: 95.8333 (96.5000)  time: 1.7073  data: 0.0873  max mem: 6740
Train: Epoch[20/60] Total time: 0:00:17 (1.7155 s / it)
Averaged stats: Lr: 0.000193  Loss: 0.7786  Acc@1: 76.5625 (74.8333)  Acc@5: 95.8333 (96.5000)
Train: Epoch[21/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000188  Loss: 0.5926  Acc@1: 84.3750 (84.3750)  Acc@5: 98.4375 (98.4375)  time: 2.7631  data: 0.7806  max mem: 6740
Train: Epoch[21/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000188  Loss: 0.8084  Acc@1: 71.8750 (73.8333)  Acc@5: 95.3125 (96.3333)  time: 1.6722  data: 0.0782  max mem: 6740
Train: Epoch[21/60] Total time: 0:00:16 (1.6821 s / it)
Averaged stats: Lr: 0.000188  Loss: 0.8084  Acc@1: 71.8750 (73.8333)  Acc@5: 95.3125 (96.3333)
Train: Epoch[22/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000182  Loss: 0.5931  Acc@1: 78.1250 (78.1250)  Acc@5: 98.4375 (98.4375)  time: 2.8188  data: 0.8674  max mem: 6740
Train: Epoch[22/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000182  Loss: 0.4940  Acc@1: 78.1250 (78.1667)  Acc@5: 96.8750 (96.6667)  time: 1.6763  data: 0.0869  max mem: 6740
Train: Epoch[22/60] Total time: 0:00:16 (1.6848 s / it)
Averaged stats: Lr: 0.000182  Loss: 0.4940  Acc@1: 78.1250 (78.1667)  Acc@5: 96.8750 (96.6667)
Train: Epoch[23/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000176  Loss: 0.6163  Acc@1: 82.8125 (82.8125)  Acc@5: 95.3125 (95.3125)  time: 2.8152  data: 0.7705  max mem: 6740
Train: Epoch[23/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000176  Loss: 0.6949  Acc@1: 76.5625 (78.0000)  Acc@5: 96.8750 (97.1667)  time: 1.6743  data: 0.0772  max mem: 6740
Train: Epoch[23/60] Total time: 0:00:16 (1.6849 s / it)
Averaged stats: Lr: 0.000176  Loss: 0.6949  Acc@1: 76.5625 (78.0000)  Acc@5: 96.8750 (97.1667)
Train: Epoch[24/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000170  Loss: 0.5541  Acc@1: 79.6875 (79.6875)  Acc@5: 96.8750 (96.8750)  time: 2.7999  data: 0.8502  max mem: 6740
Train: Epoch[24/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000170  Loss: 0.4566  Acc@1: 79.6875 (77.3333)  Acc@5: 96.8750 (96.3333)  time: 1.6740  data: 0.0852  max mem: 6740
Train: Epoch[24/60] Total time: 0:00:16 (1.6820 s / it)
Averaged stats: Lr: 0.000170  Loss: 0.4566  Acc@1: 79.6875 (77.3333)  Acc@5: 96.8750 (96.3333)
Train: Epoch[25/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000164  Loss: 0.5524  Acc@1: 76.5625 (76.5625)  Acc@5: 98.4375 (98.4375)  time: 2.8616  data: 0.9027  max mem: 6740
Train: Epoch[25/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000164  Loss: 0.6130  Acc@1: 75.0000 (75.3333)  Acc@5: 95.8333 (96.6667)  time: 1.6823  data: 0.0904  max mem: 6740
Train: Epoch[25/60] Total time: 0:00:16 (1.6925 s / it)
Averaged stats: Lr: 0.000164  Loss: 0.6130  Acc@1: 75.0000 (75.3333)  Acc@5: 95.8333 (96.6667)
Train: Epoch[26/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000157  Loss: 0.6214  Acc@1: 73.4375 (73.4375)  Acc@5: 98.4375 (98.4375)  time: 2.7512  data: 0.7796  max mem: 6740
Train: Epoch[26/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000157  Loss: 0.4835  Acc@1: 76.5625 (76.1667)  Acc@5: 95.8333 (96.5000)  time: 1.6699  data: 0.0781  max mem: 6740
Train: Epoch[26/60] Total time: 0:00:16 (1.6780 s / it)
Averaged stats: Lr: 0.000157  Loss: 0.4835  Acc@1: 76.5625 (76.1667)  Acc@5: 95.8333 (96.5000)
Train: Epoch[27/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000151  Loss: 0.5319  Acc@1: 76.5625 (76.5625)  Acc@5: 98.4375 (98.4375)  time: 2.7639  data: 0.7847  max mem: 6740
Train: Epoch[27/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000151  Loss: 0.5863  Acc@1: 78.1250 (78.3333)  Acc@5: 96.8750 (97.1667)  time: 1.6690  data: 0.0786  max mem: 6740
Train: Epoch[27/60] Total time: 0:00:16 (1.6774 s / it)
Averaged stats: Lr: 0.000151  Loss: 0.5863  Acc@1: 78.1250 (78.3333)  Acc@5: 96.8750 (97.1667)
Train: Epoch[28/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000145  Loss: 0.3959  Acc@1: 85.9375 (85.9375)  Acc@5: 98.4375 (98.4375)  time: 2.7209  data: 0.8936  max mem: 6740
Train: Epoch[28/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000145  Loss: 0.6552  Acc@1: 76.5625 (78.3333)  Acc@5: 96.8750 (96.6667)  time: 1.6660  data: 0.0895  max mem: 6740
Train: Epoch[28/60] Total time: 0:00:16 (1.6741 s / it)
Averaged stats: Lr: 0.000145  Loss: 0.6552  Acc@1: 76.5625 (78.3333)  Acc@5: 96.8750 (96.6667)
Train: Epoch[29/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000138  Loss: 0.5152  Acc@1: 71.8750 (71.8750)  Acc@5: 98.4375 (98.4375)  time: 2.7477  data: 0.9144  max mem: 6740
Train: Epoch[29/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000138  Loss: 0.4776  Acc@1: 78.1250 (78.5000)  Acc@5: 96.8750 (96.6667)  time: 1.6689  data: 0.0916  max mem: 6740
Train: Epoch[29/60] Total time: 0:00:16 (1.6780 s / it)
Averaged stats: Lr: 0.000138  Loss: 0.4776  Acc@1: 78.1250 (78.5000)  Acc@5: 96.8750 (96.6667)
Train: Epoch[30/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000132  Loss: 0.5500  Acc@1: 79.6875 (79.6875)  Acc@5: 96.8750 (96.8750)  time: 2.7368  data: 0.7586  max mem: 6740
Train: Epoch[30/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000132  Loss: 0.4050  Acc@1: 79.6875 (80.8333)  Acc@5: 96.8750 (96.8333)  time: 1.6650  data: 0.0760  max mem: 6740
Train: Epoch[30/60] Total time: 0:00:16 (1.6731 s / it)
Averaged stats: Lr: 0.000132  Loss: 0.4050  Acc@1: 79.6875 (80.8333)  Acc@5: 96.8750 (96.8333)
Train: Epoch[31/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000125  Loss: 0.5159  Acc@1: 78.1250 (78.1250)  Acc@5: 96.8750 (96.8750)  time: 2.7270  data: 0.8189  max mem: 6740
Train: Epoch[31/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000125  Loss: 0.3927  Acc@1: 81.2500 (81.8333)  Acc@5: 96.8750 (97.1667)  time: 1.6641  data: 0.0820  max mem: 6740
Train: Epoch[31/60] Total time: 0:00:16 (1.6733 s / it)
Averaged stats: Lr: 0.000125  Loss: 0.3927  Acc@1: 81.2500 (81.8333)  Acc@5: 96.8750 (97.1667)
Train: Epoch[32/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000118  Loss: 0.5525  Acc@1: 79.6875 (79.6875)  Acc@5: 96.8750 (96.8750)  time: 2.7815  data: 0.9018  max mem: 6740
Train: Epoch[32/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000118  Loss: 0.3470  Acc@1: 81.2500 (80.6667)  Acc@5: 96.8750 (97.0000)  time: 1.6944  data: 0.0903  max mem: 6740
Train: Epoch[32/60] Total time: 0:00:17 (1.7027 s / it)
Averaged stats: Lr: 0.000118  Loss: 0.3470  Acc@1: 81.2500 (80.6667)  Acc@5: 96.8750 (97.0000)
Train: Epoch[33/60]  [ 0/10]  eta: 0:00:26  Lr: 0.000112  Loss: 0.4249  Acc@1: 87.5000 (87.5000)  Acc@5: 98.4375 (98.4375)  time: 2.6700  data: 0.8159  max mem: 6740
Train: Epoch[33/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000112  Loss: 0.3353  Acc@1: 84.3750 (85.1667)  Acc@5: 100.0000 (98.3333)  time: 1.6607  data: 0.0817  max mem: 6740
Train: Epoch[33/60] Total time: 0:00:16 (1.6697 s / it)
Averaged stats: Lr: 0.000112  Loss: 0.3353  Acc@1: 84.3750 (85.1667)  Acc@5: 100.0000 (98.3333)
Train: Epoch[34/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000105  Loss: 0.5812  Acc@1: 76.5625 (76.5625)  Acc@5: 96.8750 (96.8750)  time: 2.7328  data: 0.8547  max mem: 6740
Train: Epoch[34/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000105  Loss: 0.4759  Acc@1: 79.6875 (80.6667)  Acc@5: 96.8750 (97.3333)  time: 1.6652  data: 0.0856  max mem: 6740
Train: Epoch[34/60] Total time: 0:00:16 (1.6732 s / it)
Averaged stats: Lr: 0.000105  Loss: 0.4759  Acc@1: 79.6875 (80.6667)  Acc@5: 96.8750 (97.3333)
Train: Epoch[35/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000099  Loss: 0.5697  Acc@1: 76.5625 (76.5625)  Acc@5: 93.7500 (93.7500)  time: 2.7077  data: 0.7542  max mem: 6740
Train: Epoch[35/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000099  Loss: 0.4990  Acc@1: 76.5625 (79.1667)  Acc@5: 96.8750 (97.0000)  time: 1.6607  data: 0.0756  max mem: 6740
Train: Epoch[35/60] Total time: 0:00:16 (1.6695 s / it)
Averaged stats: Lr: 0.000099  Loss: 0.4990  Acc@1: 76.5625 (79.1667)  Acc@5: 96.8750 (97.0000)
Train: Epoch[36/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000093  Loss: 0.3576  Acc@1: 84.3750 (84.3750)  Acc@5: 100.0000 (100.0000)  time: 2.7395  data: 0.8137  max mem: 6740
Train: Epoch[36/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000093  Loss: 0.4013  Acc@1: 82.8125 (82.3333)  Acc@5: 98.4375 (98.3333)  time: 1.6684  data: 0.0815  max mem: 6740
Train: Epoch[36/60] Total time: 0:00:16 (1.6768 s / it)
Averaged stats: Lr: 0.000093  Loss: 0.4013  Acc@1: 82.8125 (82.3333)  Acc@5: 98.4375 (98.3333)
Train: Epoch[37/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000086  Loss: 0.4939  Acc@1: 79.6875 (79.6875)  Acc@5: 96.8750 (96.8750)  time: 2.7984  data: 0.8812  max mem: 6740
Train: Epoch[37/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000086  Loss: 0.3022  Acc@1: 83.3333 (83.1667)  Acc@5: 98.4375 (97.6667)  time: 1.6702  data: 0.0883  max mem: 6740
Train: Epoch[37/60] Total time: 0:00:16 (1.6798 s / it)
Averaged stats: Lr: 0.000086  Loss: 0.3022  Acc@1: 83.3333 (83.1667)  Acc@5: 98.4375 (97.6667)
Train: Epoch[38/60]  [ 0/10]  eta: 0:00:26  Lr: 0.000080  Loss: 0.4795  Acc@1: 75.0000 (75.0000)  Acc@5: 96.8750 (96.8750)  time: 2.6897  data: 0.7678  max mem: 6740
Train: Epoch[38/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000080  Loss: 0.7650  Acc@1: 79.6875 (81.5000)  Acc@5: 98.4375 (97.8333)  time: 1.6590  data: 0.0769  max mem: 6740
Train: Epoch[38/60] Total time: 0:00:16 (1.6669 s / it)
Averaged stats: Lr: 0.000080  Loss: 0.7650  Acc@1: 79.6875 (81.5000)  Acc@5: 98.4375 (97.8333)
Train: Epoch[39/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000074  Loss: 0.3974  Acc@1: 85.9375 (85.9375)  Acc@5: 96.8750 (96.8750)  time: 2.7289  data: 0.7499  max mem: 6740
Train: Epoch[39/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000074  Loss: 0.4017  Acc@1: 81.2500 (81.3333)  Acc@5: 96.8750 (96.8333)  time: 1.6641  data: 0.0751  max mem: 6740
Train: Epoch[39/60] Total time: 0:00:16 (1.6743 s / it)
Averaged stats: Lr: 0.000074  Loss: 0.4017  Acc@1: 81.2500 (81.3333)  Acc@5: 96.8750 (96.8333)
Train: Epoch[40/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000068  Loss: 0.4757  Acc@1: 79.6875 (79.6875)  Acc@5: 95.3125 (95.3125)  time: 2.7689  data: 0.8906  max mem: 6740
Train: Epoch[40/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000068  Loss: 0.4059  Acc@1: 79.6875 (81.8333)  Acc@5: 96.8750 (97.5000)  time: 1.6690  data: 0.0892  max mem: 6740
Train: Epoch[40/60] Total time: 0:00:16 (1.6770 s / it)
Averaged stats: Lr: 0.000068  Loss: 0.4059  Acc@1: 79.6875 (81.8333)  Acc@5: 96.8750 (97.5000)
Train: Epoch[41/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000063  Loss: 0.3541  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 2.7432  data: 0.7943  max mem: 6740
Train: Epoch[41/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000063  Loss: 0.4251  Acc@1: 82.8125 (83.1667)  Acc@5: 96.8750 (97.0000)  time: 1.6658  data: 0.0796  max mem: 6740
Train: Epoch[41/60] Total time: 0:00:16 (1.6752 s / it)
Averaged stats: Lr: 0.000063  Loss: 0.4251  Acc@1: 82.8125 (83.1667)  Acc@5: 96.8750 (97.0000)
Train: Epoch[42/60]  [ 0/10]  eta: 0:00:26  Lr: 0.000057  Loss: 0.5832  Acc@1: 78.1250 (78.1250)  Acc@5: 92.1875 (92.1875)  time: 2.6710  data: 0.7442  max mem: 6740
Train: Epoch[42/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000057  Loss: 0.3348  Acc@1: 82.8125 (82.8333)  Acc@5: 98.4375 (97.1667)  time: 1.6581  data: 0.0746  max mem: 6740
Train: Epoch[42/60] Total time: 0:00:16 (1.6660 s / it)
Averaged stats: Lr: 0.000057  Loss: 0.3348  Acc@1: 82.8125 (82.8333)  Acc@5: 98.4375 (97.1667)
Train: Epoch[43/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000052  Loss: 0.5066  Acc@1: 79.6875 (79.6875)  Acc@5: 95.3125 (95.3125)  time: 2.7182  data: 0.8049  max mem: 6740
Train: Epoch[43/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000052  Loss: 0.4860  Acc@1: 79.6875 (81.3333)  Acc@5: 95.3125 (96.8333)  time: 1.6868  data: 0.0806  max mem: 6740
Train: Epoch[43/60] Total time: 0:00:16 (1.6970 s / it)
Averaged stats: Lr: 0.000052  Loss: 0.4860  Acc@1: 79.6875 (81.3333)  Acc@5: 95.3125 (96.8333)
Train: Epoch[44/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000046  Loss: 0.2600  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 2.7355  data: 0.7373  max mem: 6740
Train: Epoch[44/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000046  Loss: 0.4749  Acc@1: 82.8125 (84.1667)  Acc@5: 98.4375 (98.3333)  time: 1.6671  data: 0.0739  max mem: 6740
Train: Epoch[44/60] Total time: 0:00:16 (1.6767 s / it)
Averaged stats: Lr: 0.000046  Loss: 0.4749  Acc@1: 82.8125 (84.1667)  Acc@5: 98.4375 (98.3333)
Train: Epoch[45/60]  [ 0/10]  eta: 0:00:26  Lr: 0.000041  Loss: 0.4754  Acc@1: 82.8125 (82.8125)  Acc@5: 95.3125 (95.3125)  time: 2.6773  data: 0.7602  max mem: 6740
Train: Epoch[45/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000041  Loss: 0.4757  Acc@1: 82.8125 (82.5000)  Acc@5: 95.8333 (96.6667)  time: 1.6604  data: 0.0761  max mem: 6740
Train: Epoch[45/60] Total time: 0:00:16 (1.6700 s / it)
Averaged stats: Lr: 0.000041  Loss: 0.4757  Acc@1: 82.8125 (82.5000)  Acc@5: 95.8333 (96.6667)
Train: Epoch[46/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000037  Loss: 0.3104  Acc@1: 82.8125 (82.8125)  Acc@5: 100.0000 (100.0000)  time: 2.7718  data: 0.8080  max mem: 6740
Train: Epoch[46/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000037  Loss: 0.5582  Acc@1: 82.8125 (83.5000)  Acc@5: 98.4375 (98.0000)  time: 1.6702  data: 0.0809  max mem: 6740
Train: Epoch[46/60] Total time: 0:00:16 (1.6779 s / it)
Averaged stats: Lr: 0.000037  Loss: 0.5582  Acc@1: 82.8125 (83.5000)  Acc@5: 98.4375 (98.0000)
Train: Epoch[47/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000032  Loss: 0.3947  Acc@1: 82.8125 (82.8125)  Acc@5: 95.3125 (95.3125)  time: 2.7622  data: 0.7785  max mem: 6740
Train: Epoch[47/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000032  Loss: 0.3246  Acc@1: 82.8125 (83.5000)  Acc@5: 95.8333 (96.5000)  time: 1.6723  data: 0.0780  max mem: 6740
Train: Epoch[47/60] Total time: 0:00:16 (1.6814 s / it)
Averaged stats: Lr: 0.000032  Loss: 0.3246  Acc@1: 82.8125 (83.5000)  Acc@5: 95.8333 (96.5000)
Train: Epoch[48/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000028  Loss: 0.4769  Acc@1: 82.8125 (82.8125)  Acc@5: 95.3125 (95.3125)  time: 2.7499  data: 0.9190  max mem: 6740
Train: Epoch[48/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000028  Loss: 0.4160  Acc@1: 84.3750 (84.8333)  Acc@5: 98.4375 (98.3333)  time: 1.6683  data: 0.0920  max mem: 6740
Train: Epoch[48/60] Total time: 0:00:16 (1.6761 s / it)
Averaged stats: Lr: 0.000028  Loss: 0.4160  Acc@1: 84.3750 (84.8333)  Acc@5: 98.4375 (98.3333)
Train: Epoch[49/60]  [ 0/10]  eta: 0:00:26  Lr: 0.000024  Loss: 0.3750  Acc@1: 84.3750 (84.3750)  Acc@5: 96.8750 (96.8750)  time: 2.6671  data: 0.7746  max mem: 6740
Train: Epoch[49/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000024  Loss: 0.2677  Acc@1: 82.8125 (82.3333)  Acc@5: 98.4375 (97.6667)  time: 1.6602  data: 0.0776  max mem: 6740
Train: Epoch[49/60] Total time: 0:00:16 (1.6707 s / it)
Averaged stats: Lr: 0.000024  Loss: 0.2677  Acc@1: 82.8125 (82.3333)  Acc@5: 98.4375 (97.6667)
Train: Epoch[50/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000020  Loss: 0.4866  Acc@1: 78.1250 (78.1250)  Acc@5: 96.8750 (96.8750)  time: 2.7164  data: 0.7454  max mem: 6740
Train: Epoch[50/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000020  Loss: 0.4048  Acc@1: 84.3750 (83.5000)  Acc@5: 96.8750 (97.3333)  time: 1.6667  data: 0.0747  max mem: 6740
Train: Epoch[50/60] Total time: 0:00:16 (1.6748 s / it)
Averaged stats: Lr: 0.000020  Loss: 0.4048  Acc@1: 84.3750 (83.5000)  Acc@5: 96.8750 (97.3333)
Train: Epoch[51/60]  [ 0/10]  eta: 0:00:26  Lr: 0.000017  Loss: 0.3994  Acc@1: 82.8125 (82.8125)  Acc@5: 96.8750 (96.8750)  time: 2.6584  data: 0.7677  max mem: 6740
Train: Epoch[51/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000017  Loss: 0.4780  Acc@1: 82.8125 (83.8333)  Acc@5: 96.8750 (98.0000)  time: 1.6550  data: 0.0769  max mem: 6740
Train: Epoch[51/60] Total time: 0:00:16 (1.6641 s / it)
Averaged stats: Lr: 0.000017  Loss: 0.4780  Acc@1: 82.8125 (83.8333)  Acc@5: 96.8750 (98.0000)
Train: Epoch[52/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000014  Loss: 0.3819  Acc@1: 82.8125 (82.8125)  Acc@5: 95.3125 (95.3125)  time: 2.7180  data: 0.7360  max mem: 6740
Train: Epoch[52/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000014  Loss: 0.3285  Acc@1: 82.8125 (82.8333)  Acc@5: 96.8750 (96.8333)  time: 1.6597  data: 0.0737  max mem: 6740
Train: Epoch[52/60] Total time: 0:00:16 (1.6677 s / it)
Averaged stats: Lr: 0.000014  Loss: 0.3285  Acc@1: 82.8125 (82.8333)  Acc@5: 96.8750 (96.8333)
Train: Epoch[53/60]  [ 0/10]  eta: 0:00:26  Lr: 0.000011  Loss: 0.3988  Acc@1: 76.5625 (76.5625)  Acc@5: 98.4375 (98.4375)  time: 2.6426  data: 0.7068  max mem: 6740
Train: Epoch[53/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000011  Loss: 0.2809  Acc@1: 82.8125 (83.0000)  Acc@5: 98.4375 (97.3333)  time: 1.6547  data: 0.0708  max mem: 6740
Train: Epoch[53/60] Total time: 0:00:16 (1.6642 s / it)
Averaged stats: Lr: 0.000011  Loss: 0.2809  Acc@1: 82.8125 (83.0000)  Acc@5: 98.4375 (97.3333)
Train: Epoch[54/60]  [ 0/10]  eta: 0:00:26  Lr: 0.000008  Loss: 0.4229  Acc@1: 82.8125 (82.8125)  Acc@5: 96.8750 (96.8750)  time: 2.6831  data: 0.7344  max mem: 6740
Train: Epoch[54/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000008  Loss: 0.2527  Acc@1: 82.8125 (83.3333)  Acc@5: 96.8750 (97.3333)  time: 1.6841  data: 0.0736  max mem: 6740
Train: Epoch[54/60] Total time: 0:00:16 (1.6927 s / it)
Averaged stats: Lr: 0.000008  Loss: 0.2527  Acc@1: 82.8125 (83.3333)  Acc@5: 96.8750 (97.3333)
Train: Epoch[55/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000006  Loss: 0.2936  Acc@1: 84.3750 (84.3750)  Acc@5: 100.0000 (100.0000)  time: 2.7567  data: 0.7655  max mem: 6740
Train: Epoch[55/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000006  Loss: 0.4165  Acc@1: 84.3750 (84.8333)  Acc@5: 96.8750 (97.3333)  time: 1.6697  data: 0.0767  max mem: 6740
Train: Epoch[55/60] Total time: 0:00:16 (1.6795 s / it)
Averaged stats: Lr: 0.000006  Loss: 0.4165  Acc@1: 84.3750 (84.8333)  Acc@5: 96.8750 (97.3333)
Train: Epoch[56/60]  [ 0/10]  eta: 0:00:26  Lr: 0.000004  Loss: 0.4427  Acc@1: 82.8125 (82.8125)  Acc@5: 96.8750 (96.8750)  time: 2.6601  data: 0.6859  max mem: 6740
Train: Epoch[56/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000004  Loss: 0.2774  Acc@1: 81.2500 (81.5000)  Acc@5: 96.8750 (96.8333)  time: 1.6570  data: 0.0687  max mem: 6740
Train: Epoch[56/60] Total time: 0:00:16 (1.6649 s / it)
Averaged stats: Lr: 0.000004  Loss: 0.2774  Acc@1: 81.2500 (81.5000)  Acc@5: 96.8750 (96.8333)
Train: Epoch[57/60]  [ 0/10]  eta: 0:00:26  Lr: 0.000003  Loss: 0.3114  Acc@1: 85.9375 (85.9375)  Acc@5: 96.8750 (96.8750)  time: 2.6658  data: 0.7895  max mem: 6740
Train: Epoch[57/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000003  Loss: 0.3740  Acc@1: 82.8125 (82.6667)  Acc@5: 96.8750 (97.3333)  time: 1.6616  data: 0.0791  max mem: 6740
Train: Epoch[57/60] Total time: 0:00:16 (1.6713 s / it)
Averaged stats: Lr: 0.000003  Loss: 0.3740  Acc@1: 82.8125 (82.6667)  Acc@5: 96.8750 (97.3333)
Train: Epoch[58/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000002  Loss: 0.3369  Acc@1: 84.3750 (84.3750)  Acc@5: 98.4375 (98.4375)  time: 2.7830  data: 0.9018  max mem: 6740
Train: Epoch[58/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000002  Loss: 0.5939  Acc@1: 83.3333 (83.5000)  Acc@5: 96.8750 (97.8333)  time: 1.6676  data: 0.0903  max mem: 6740
Train: Epoch[58/60] Total time: 0:00:16 (1.6755 s / it)
Averaged stats: Lr: 0.000002  Loss: 0.5939  Acc@1: 83.3333 (83.5000)  Acc@5: 96.8750 (97.8333)
Train: Epoch[59/60]  [ 0/10]  eta: 0:00:26  Lr: 0.000001  Loss: 0.4733  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 2.6878  data: 0.7442  max mem: 6740
Train: Epoch[59/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000001  Loss: 0.3498  Acc@1: 83.3333 (85.0000)  Acc@5: 98.4375 (98.1667)  time: 1.6609  data: 0.0746  max mem: 6740
Train: Epoch[59/60] Total time: 0:00:16 (1.6701 s / it)
Averaged stats: Lr: 0.000001  Loss: 0.3498  Acc@1: 83.3333 (85.0000)  Acc@5: 98.4375 (98.1667)
Train: Epoch[60/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000000  Loss: 0.5032  Acc@1: 81.2500 (81.2500)  Acc@5: 96.8750 (96.8750)  time: 2.7521  data: 0.7573  max mem: 6740
Train: Epoch[60/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000000  Loss: 1.0427  Acc@1: 79.6875 (81.0000)  Acc@5: 96.8750 (97.1667)  time: 1.6710  data: 0.0759  max mem: 6740
Train: Epoch[60/60] Total time: 0:00:16 (1.6788 s / it)
Averaged stats: Lr: 0.000000  Loss: 1.0427  Acc@1: 79.6875 (81.0000)  Acc@5: 96.8750 (97.1667)
Test: [Task 1]  [0/9]  eta: 0:00:13  Loss: 0.2590 (0.2590)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)  time: 1.5185  data: 0.8772  max mem: 6740
Test: [Task 1]  [8/9]  eta: 0:00:00  Loss: 0.1161 (0.1584)  Acc@1: 98.4375 (96.1165)  Acc@5: 100.0000 (99.6117)  time: 0.6128  data: 0.0977  max mem: 6740
Test: [Task 1] Total time: 0:00:05 (0.6217 s / it)
* Acc@1 96.117 Acc@5 99.612 loss 0.158
Batchwise eval time for task 1 = 0.6217700375450982
Test: [Task 2]  [0/9]  eta: 0:00:14  Loss: 0.2073 (0.2073)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 1.6407  data: 1.0021  max mem: 6740
Test: [Task 2]  [8/9]  eta: 0:00:00  Loss: 0.5284 (0.5245)  Acc@1: 81.2500 (82.9565)  Acc@5: 100.0000 (99.4783)  time: 0.7245  data: 0.1116  max mem: 6740
Test: [Task 2] Total time: 0:00:06 (0.7339 s / it)
* Acc@1 82.957 Acc@5 99.478 loss 0.524
Batchwise eval time for task 2 = 0.7339180840386285
[Average accuracy till task2]	Acc@1: 89.1743	Acc@5: 99.5450	Loss: 0.3414	Forgetting: 0.0000	Backward: 0.0000
Eval time for task 2 = 12.286774396896362
Using adam optimizer
Reinitialising optimizer
/kaggle/working/venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Similarity:  tensor(0.9233)  Task:  2
Old Num K:  6 New Num K:  7
Task number:  2
Train: Epoch[ 1/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000250  Loss: 3.1563  Acc@1: 0.0000 (0.0000)  Acc@5: 1.5625 (1.5625)  time: 2.8821  data: 0.8017  max mem: 6778
Train: Epoch[ 1/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000250  Loss: 3.2173  Acc@1: 0.0000 (0.1667)  Acc@5: 1.5625 (2.6667)  time: 1.7878  data: 0.0803  max mem: 6790
Train: Epoch[ 1/60] Total time: 0:00:17 (1.7955 s / it)
Averaged stats: Lr: 0.000250  Loss: 3.2173  Acc@1: 0.0000 (0.1667)  Acc@5: 1.5625 (2.6667)
Train: Epoch[ 2/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000250  Loss: 3.0871  Acc@1: 0.0000 (0.0000)  Acc@5: 10.9375 (10.9375)  time: 2.8087  data: 0.8012  max mem: 6790
Train: Epoch[ 2/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000250  Loss: 2.0648  Acc@1: 0.0000 (0.5000)  Acc@5: 15.6250 (18.8333)  time: 1.7786  data: 0.0802  max mem: 6790
Train: Epoch[ 2/60] Total time: 0:00:17 (1.7868 s / it)
Averaged stats: Lr: 0.000250  Loss: 2.0648  Acc@1: 0.0000 (0.5000)  Acc@5: 15.6250 (18.8333)
Train: Epoch[ 3/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000249  Loss: 2.1781  Acc@1: 4.6875 (4.6875)  Acc@5: 28.1250 (28.1250)  time: 2.8448  data: 0.7271  max mem: 6790
Train: Epoch[ 3/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000249  Loss: 1.7676  Acc@1: 6.2500 (8.0000)  Acc@5: 43.7500 (48.8333)  time: 1.8076  data: 0.0729  max mem: 6790
Train: Epoch[ 3/60] Total time: 0:00:18 (1.8159 s / it)
Averaged stats: Lr: 0.000249  Loss: 1.7676  Acc@1: 6.2500 (8.0000)  Acc@5: 43.7500 (48.8333)
Train: Epoch[ 4/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000248  Loss: 1.7047  Acc@1: 14.0625 (14.0625)  Acc@5: 59.3750 (59.3750)  time: 2.8199  data: 0.7463  max mem: 6790
Train: Epoch[ 4/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000248  Loss: 1.2625  Acc@1: 18.7500 (19.6667)  Acc@5: 78.1250 (73.5000)  time: 1.7777  data: 0.0748  max mem: 6790
Train: Epoch[ 4/60] Total time: 0:00:17 (1.7878 s / it)
Averaged stats: Lr: 0.000248  Loss: 1.2625  Acc@1: 18.7500 (19.6667)  Acc@5: 78.1250 (73.5000)
Train: Epoch[ 5/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000247  Loss: 1.4253  Acc@1: 29.6875 (29.6875)  Acc@5: 75.0000 (75.0000)  time: 2.8405  data: 0.7410  max mem: 6790
Train: Epoch[ 5/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000247  Loss: 0.8944  Acc@1: 31.2500 (34.0000)  Acc@5: 82.8125 (83.6667)  time: 1.7826  data: 0.0742  max mem: 6790
Train: Epoch[ 5/60] Total time: 0:00:17 (1.7904 s / it)
Averaged stats: Lr: 0.000247  Loss: 0.8944  Acc@1: 31.2500 (34.0000)  Acc@5: 82.8125 (83.6667)
Train: Epoch[ 6/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000246  Loss: 1.0681  Acc@1: 29.6875 (29.6875)  Acc@5: 85.9375 (85.9375)  time: 2.8883  data: 0.8203  max mem: 6790
Train: Epoch[ 6/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000246  Loss: 1.0024  Acc@1: 43.7500 (44.1667)  Acc@5: 89.0625 (88.3333)  time: 1.7981  data: 0.0822  max mem: 6790
Train: Epoch[ 6/60] Total time: 0:00:18 (1.8070 s / it)
Averaged stats: Lr: 0.000246  Loss: 1.0024  Acc@1: 43.7500 (44.1667)  Acc@5: 89.0625 (88.3333)
Train: Epoch[ 7/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000244  Loss: 1.0123  Acc@1: 54.6875 (54.6875)  Acc@5: 85.9375 (85.9375)  time: 2.9025  data: 0.8292  max mem: 6790
Train: Epoch[ 7/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000244  Loss: 0.9757  Acc@1: 56.2500 (57.3333)  Acc@5: 92.1875 (92.3333)  time: 1.7925  data: 0.0831  max mem: 6790
Train: Epoch[ 7/60] Total time: 0:00:18 (1.8004 s / it)
Averaged stats: Lr: 0.000244  Loss: 0.9757  Acc@1: 56.2500 (57.3333)  Acc@5: 92.1875 (92.3333)
Train: Epoch[ 8/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000242  Loss: 0.7476  Acc@1: 54.6875 (54.6875)  Acc@5: 92.1875 (92.1875)  time: 2.9063  data: 0.8596  max mem: 6790
Train: Epoch[ 8/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000242  Loss: 0.7451  Acc@1: 60.9375 (60.5000)  Acc@5: 92.1875 (92.1667)  time: 1.7910  data: 0.0861  max mem: 6790
Train: Epoch[ 8/60] Total time: 0:00:18 (1.8010 s / it)
Averaged stats: Lr: 0.000242  Loss: 0.7451  Acc@1: 60.9375 (60.5000)  Acc@5: 92.1875 (92.1667)
Train: Epoch[ 9/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000239  Loss: 0.6919  Acc@1: 57.8125 (57.8125)  Acc@5: 96.8750 (96.8750)  time: 2.8563  data: 0.7725  max mem: 6790
Train: Epoch[ 9/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000239  Loss: 1.0411  Acc@1: 62.5000 (65.5000)  Acc@5: 96.8750 (95.5000)  time: 1.7824  data: 0.0774  max mem: 6790
Train: Epoch[ 9/60] Total time: 0:00:17 (1.7904 s / it)
Averaged stats: Lr: 0.000239  Loss: 1.0411  Acc@1: 62.5000 (65.5000)  Acc@5: 96.8750 (95.5000)
Train: Epoch[10/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000236  Loss: 0.6731  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)  time: 2.9258  data: 0.8752  max mem: 6790
Train: Epoch[10/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000236  Loss: 0.6168  Acc@1: 66.6667 (67.3333)  Acc@5: 92.1875 (92.8333)  time: 1.7899  data: 0.0876  max mem: 6790
Train: Epoch[10/60] Total time: 0:00:18 (1.8005 s / it)
Averaged stats: Lr: 0.000236  Loss: 0.6168  Acc@1: 66.6667 (67.3333)  Acc@5: 92.1875 (92.8333)
Train: Epoch[11/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000233  Loss: 0.6953  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 2.8868  data: 0.8503  max mem: 6790
Train: Epoch[11/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000233  Loss: 0.7594  Acc@1: 68.7500 (69.1667)  Acc@5: 93.7500 (93.8333)  time: 1.7909  data: 0.0852  max mem: 6790
Train: Epoch[11/60] Total time: 0:00:17 (1.7990 s / it)
Averaged stats: Lr: 0.000233  Loss: 0.7594  Acc@1: 68.7500 (69.1667)  Acc@5: 93.7500 (93.8333)
Train: Epoch[12/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000230  Loss: 0.6189  Acc@1: 71.8750 (71.8750)  Acc@5: 96.8750 (96.8750)  time: 2.9417  data: 0.9553  max mem: 6790
Train: Epoch[12/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000230  Loss: 0.7165  Acc@1: 70.3125 (72.1667)  Acc@5: 93.7500 (94.5000)  time: 1.8130  data: 0.0957  max mem: 6790
Train: Epoch[12/60] Total time: 0:00:18 (1.8234 s / it)
Averaged stats: Lr: 0.000230  Loss: 0.7165  Acc@1: 70.3125 (72.1667)  Acc@5: 93.7500 (94.5000)
Train: Epoch[13/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000226  Loss: 0.6394  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)  time: 2.8326  data: 0.7604  max mem: 6790
Train: Epoch[13/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000226  Loss: 0.4390  Acc@1: 73.4375 (72.8333)  Acc@5: 95.3125 (94.8333)  time: 1.7877  data: 0.0762  max mem: 6790
Train: Epoch[13/60] Total time: 0:00:17 (1.7957 s / it)
Averaged stats: Lr: 0.000226  Loss: 0.4390  Acc@1: 73.4375 (72.8333)  Acc@5: 95.3125 (94.8333)
Train: Epoch[14/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000222  Loss: 0.4547  Acc@1: 79.6875 (79.6875)  Acc@5: 100.0000 (100.0000)  time: 2.7532  data: 0.7279  max mem: 6790
Train: Epoch[14/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000222  Loss: 0.3488  Acc@1: 75.0000 (75.3333)  Acc@5: 93.7500 (94.3333)  time: 1.7750  data: 0.0729  max mem: 6790
Train: Epoch[14/60] Total time: 0:00:17 (1.7845 s / it)
Averaged stats: Lr: 0.000222  Loss: 0.3488  Acc@1: 75.0000 (75.3333)  Acc@5: 93.7500 (94.3333)
Train: Epoch[15/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000218  Loss: 0.4136  Acc@1: 89.0625 (89.0625)  Acc@5: 98.4375 (98.4375)  time: 3.0541  data: 1.0078  max mem: 6790
Train: Epoch[15/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000218  Loss: 0.7011  Acc@1: 76.5625 (77.1667)  Acc@5: 95.3125 (95.3333)  time: 1.8069  data: 0.1009  max mem: 6790
Train: Epoch[15/60] Total time: 0:00:18 (1.8148 s / it)
Averaged stats: Lr: 0.000218  Loss: 0.7011  Acc@1: 76.5625 (77.1667)  Acc@5: 95.3125 (95.3333)
Train: Epoch[16/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000213  Loss: 0.4996  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)  time: 2.8270  data: 0.7381  max mem: 6790
Train: Epoch[16/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000213  Loss: 0.3529  Acc@1: 75.0000 (75.8333)  Acc@5: 95.3125 (95.6667)  time: 1.7825  data: 0.0739  max mem: 6790
Train: Epoch[16/60] Total time: 0:00:17 (1.7929 s / it)
Averaged stats: Lr: 0.000213  Loss: 0.3529  Acc@1: 75.0000 (75.8333)  Acc@5: 95.3125 (95.6667)
Train: Epoch[17/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000209  Loss: 0.5306  Acc@1: 71.8750 (71.8750)  Acc@5: 93.7500 (93.7500)  time: 2.8613  data: 0.7572  max mem: 6790
Train: Epoch[17/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000209  Loss: 0.4195  Acc@1: 81.2500 (79.6667)  Acc@5: 96.8750 (97.0000)  time: 1.7851  data: 0.0759  max mem: 6790
Train: Epoch[17/60] Total time: 0:00:17 (1.7932 s / it)
Averaged stats: Lr: 0.000209  Loss: 0.4195  Acc@1: 81.2500 (79.6667)  Acc@5: 96.8750 (97.0000)
Train: Epoch[18/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000204  Loss: 0.4678  Acc@1: 82.8125 (82.8125)  Acc@5: 95.3125 (95.3125)  time: 2.8048  data: 0.8119  max mem: 6790
Train: Epoch[18/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000204  Loss: 0.6747  Acc@1: 79.6875 (78.0000)  Acc@5: 95.3125 (94.8333)  time: 1.7765  data: 0.0813  max mem: 6790
Train: Epoch[18/60] Total time: 0:00:17 (1.7854 s / it)
Averaged stats: Lr: 0.000204  Loss: 0.6747  Acc@1: 79.6875 (78.0000)  Acc@5: 95.3125 (94.8333)
Train: Epoch[19/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000198  Loss: 0.5398  Acc@1: 78.1250 (78.1250)  Acc@5: 92.1875 (92.1875)  time: 2.9580  data: 0.9349  max mem: 6790
Train: Epoch[19/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000198  Loss: 0.4774  Acc@1: 78.1250 (80.6667)  Acc@5: 95.8333 (95.3333)  time: 1.7929  data: 0.0936  max mem: 6790
Train: Epoch[19/60] Total time: 0:00:18 (1.8021 s / it)
Averaged stats: Lr: 0.000198  Loss: 0.4774  Acc@1: 78.1250 (80.6667)  Acc@5: 95.8333 (95.3333)
Train: Epoch[20/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000193  Loss: 0.4683  Acc@1: 89.0625 (89.0625)  Acc@5: 96.8750 (96.8750)  time: 2.8158  data: 0.7339  max mem: 6790
Train: Epoch[20/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000193  Loss: 0.3010  Acc@1: 81.2500 (81.1667)  Acc@5: 96.8750 (95.6667)  time: 1.7976  data: 0.0735  max mem: 6790
Train: Epoch[20/60] Total time: 0:00:18 (1.8089 s / it)
Averaged stats: Lr: 0.000193  Loss: 0.3010  Acc@1: 81.2500 (81.1667)  Acc@5: 96.8750 (95.6667)
Train: Epoch[21/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000188  Loss: 0.4657  Acc@1: 89.0625 (89.0625)  Acc@5: 93.7500 (93.7500)  time: 2.8485  data: 0.7799  max mem: 6790
Train: Epoch[21/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000188  Loss: 0.3717  Acc@1: 82.8125 (84.1667)  Acc@5: 96.8750 (96.3333)  time: 1.7839  data: 0.0781  max mem: 6790
Train: Epoch[21/60] Total time: 0:00:17 (1.7920 s / it)
Averaged stats: Lr: 0.000188  Loss: 0.3717  Acc@1: 82.8125 (84.1667)  Acc@5: 96.8750 (96.3333)
Train: Epoch[22/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000182  Loss: 0.3916  Acc@1: 84.3750 (84.3750)  Acc@5: 96.8750 (96.8750)  time: 2.8565  data: 0.7873  max mem: 6790
Train: Epoch[22/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000182  Loss: 0.4369  Acc@1: 83.3333 (83.3333)  Acc@5: 96.8750 (96.8333)  time: 1.7842  data: 0.0789  max mem: 6790
Train: Epoch[22/60] Total time: 0:00:17 (1.7936 s / it)
Averaged stats: Lr: 0.000182  Loss: 0.4369  Acc@1: 83.3333 (83.3333)  Acc@5: 96.8750 (96.8333)
Train: Epoch[23/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000176  Loss: 0.4963  Acc@1: 81.2500 (81.2500)  Acc@5: 95.3125 (95.3125)  time: 2.8266  data: 0.8053  max mem: 6790
Train: Epoch[23/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000176  Loss: 0.3004  Acc@1: 81.2500 (82.3333)  Acc@5: 95.3125 (96.5000)  time: 1.7840  data: 0.0807  max mem: 6790
Train: Epoch[23/60] Total time: 0:00:17 (1.7918 s / it)
Averaged stats: Lr: 0.000176  Loss: 0.3004  Acc@1: 81.2500 (82.3333)  Acc@5: 95.3125 (96.5000)
Train: Epoch[24/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000170  Loss: 0.3696  Acc@1: 82.8125 (82.8125)  Acc@5: 98.4375 (98.4375)  time: 2.8619  data: 0.8025  max mem: 6790
Train: Epoch[24/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000170  Loss: 0.3768  Acc@1: 83.3333 (84.0000)  Acc@5: 95.3125 (96.1667)  time: 1.7833  data: 0.0804  max mem: 6790
Train: Epoch[24/60] Total time: 0:00:17 (1.7935 s / it)
Averaged stats: Lr: 0.000170  Loss: 0.3768  Acc@1: 83.3333 (84.0000)  Acc@5: 95.3125 (96.1667)
Train: Epoch[25/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000164  Loss: 0.3729  Acc@1: 87.5000 (87.5000)  Acc@5: 98.4375 (98.4375)  time: 2.8574  data: 0.8467  max mem: 6790
Train: Epoch[25/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000164  Loss: 0.4500  Acc@1: 85.9375 (84.5000)  Acc@5: 98.4375 (97.0000)  time: 1.7805  data: 0.0848  max mem: 6790
Train: Epoch[25/60] Total time: 0:00:17 (1.7886 s / it)
Averaged stats: Lr: 0.000164  Loss: 0.4500  Acc@1: 85.9375 (84.5000)  Acc@5: 98.4375 (97.0000)
Train: Epoch[26/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000157  Loss: 0.3921  Acc@1: 87.5000 (87.5000)  Acc@5: 95.3125 (95.3125)  time: 2.8264  data: 0.7815  max mem: 6790
Train: Epoch[26/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000157  Loss: 0.2267  Acc@1: 82.8125 (82.1667)  Acc@5: 93.7500 (94.8333)  time: 1.7807  data: 0.0783  max mem: 6790
Train: Epoch[26/60] Total time: 0:00:17 (1.7901 s / it)
Averaged stats: Lr: 0.000157  Loss: 0.2267  Acc@1: 82.8125 (82.1667)  Acc@5: 93.7500 (94.8333)
Train: Epoch[27/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000151  Loss: 0.3162  Acc@1: 85.9375 (85.9375)  Acc@5: 100.0000 (100.0000)  time: 2.8978  data: 0.8299  max mem: 6790
Train: Epoch[27/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000151  Loss: 0.5812  Acc@1: 81.2500 (83.6667)  Acc@5: 96.8750 (95.6667)  time: 1.7885  data: 0.0831  max mem: 6790
Train: Epoch[27/60] Total time: 0:00:17 (1.7961 s / it)
Averaged stats: Lr: 0.000151  Loss: 0.5812  Acc@1: 81.2500 (83.6667)  Acc@5: 96.8750 (95.6667)
Train: Epoch[28/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000145  Loss: 0.3272  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 2.8863  data: 0.8996  max mem: 6790
Train: Epoch[28/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000145  Loss: 0.4963  Acc@1: 87.5000 (86.8333)  Acc@5: 95.3125 (96.3333)  time: 1.7853  data: 0.0901  max mem: 6790
Train: Epoch[28/60] Total time: 0:00:17 (1.7942 s / it)
Averaged stats: Lr: 0.000145  Loss: 0.4963  Acc@1: 87.5000 (86.8333)  Acc@5: 95.3125 (96.3333)
Train: Epoch[29/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000138  Loss: 0.2731  Acc@1: 89.0625 (89.0625)  Acc@5: 98.4375 (98.4375)  time: 2.8375  data: 0.8042  max mem: 6790
Train: Epoch[29/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000138  Loss: 0.5176  Acc@1: 84.3750 (84.3333)  Acc@5: 95.3125 (95.6667)  time: 1.8044  data: 0.0806  max mem: 6790
Train: Epoch[29/60] Total time: 0:00:18 (1.8127 s / it)
Averaged stats: Lr: 0.000138  Loss: 0.5176  Acc@1: 84.3750 (84.3333)  Acc@5: 95.3125 (95.6667)
Train: Epoch[30/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000132  Loss: 0.3498  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 2.8507  data: 0.8502  max mem: 6790
Train: Epoch[30/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000132  Loss: 0.2183  Acc@1: 85.9375 (86.5000)  Acc@5: 96.8750 (97.0000)  time: 1.7849  data: 0.0852  max mem: 6790
Train: Epoch[30/60] Total time: 0:00:17 (1.7945 s / it)
Averaged stats: Lr: 0.000132  Loss: 0.2183  Acc@1: 85.9375 (86.5000)  Acc@5: 96.8750 (97.0000)
Train: Epoch[31/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000125  Loss: 0.2702  Acc@1: 89.0625 (89.0625)  Acc@5: 100.0000 (100.0000)  time: 2.8698  data: 0.8414  max mem: 6790
Train: Epoch[31/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000125  Loss: 0.3728  Acc@1: 89.0625 (87.5000)  Acc@5: 96.8750 (97.5000)  time: 1.7840  data: 0.0843  max mem: 6790
Train: Epoch[31/60] Total time: 0:00:17 (1.7920 s / it)
Averaged stats: Lr: 0.000125  Loss: 0.3728  Acc@1: 89.0625 (87.5000)  Acc@5: 96.8750 (97.5000)
Train: Epoch[32/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000118  Loss: 0.5649  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  time: 2.8088  data: 0.7019  max mem: 6790
Train: Epoch[32/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000118  Loss: 0.2041  Acc@1: 85.9375 (85.8333)  Acc@5: 96.8750 (96.3333)  time: 1.7781  data: 0.0703  max mem: 6790
Train: Epoch[32/60] Total time: 0:00:17 (1.7876 s / it)
Averaged stats: Lr: 0.000118  Loss: 0.2041  Acc@1: 85.9375 (85.8333)  Acc@5: 96.8750 (96.3333)
Train: Epoch[33/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000112  Loss: 0.3023  Acc@1: 90.6250 (90.6250)  Acc@5: 96.8750 (96.8750)  time: 2.8150  data: 0.7436  max mem: 6790
Train: Epoch[33/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000112  Loss: 0.4105  Acc@1: 84.3750 (84.6667)  Acc@5: 95.3125 (95.6667)  time: 1.7815  data: 0.0745  max mem: 6790
Train: Epoch[33/60] Total time: 0:00:17 (1.7894 s / it)
Averaged stats: Lr: 0.000112  Loss: 0.4105  Acc@1: 84.3750 (84.6667)  Acc@5: 95.3125 (95.6667)
Train: Epoch[34/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000105  Loss: 0.3000  Acc@1: 82.8125 (82.8125)  Acc@5: 96.8750 (96.8750)  time: 2.8653  data: 0.8315  max mem: 6790
Train: Epoch[34/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000105  Loss: 0.4891  Acc@1: 87.5000 (87.6667)  Acc@5: 96.8750 (96.8333)  time: 1.7837  data: 0.0833  max mem: 6790
Train: Epoch[34/60] Total time: 0:00:17 (1.7932 s / it)
Averaged stats: Lr: 0.000105  Loss: 0.4891  Acc@1: 87.5000 (87.6667)  Acc@5: 96.8750 (96.8333)
Train: Epoch[35/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000099  Loss: 0.4318  Acc@1: 87.5000 (87.5000)  Acc@5: 92.1875 (92.1875)  time: 2.9326  data: 0.7834  max mem: 6790
Train: Epoch[35/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000099  Loss: 0.1955  Acc@1: 85.9375 (86.3333)  Acc@5: 95.3125 (95.5000)  time: 1.7920  data: 0.0785  max mem: 6790
Train: Epoch[35/60] Total time: 0:00:17 (1.7999 s / it)
Averaged stats: Lr: 0.000099  Loss: 0.1955  Acc@1: 85.9375 (86.3333)  Acc@5: 95.3125 (95.5000)
Train: Epoch[36/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000093  Loss: 0.2478  Acc@1: 89.0625 (89.0625)  Acc@5: 98.4375 (98.4375)  time: 2.8936  data: 0.8316  max mem: 6790
Train: Epoch[36/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000093  Loss: 0.4151  Acc@1: 87.5000 (88.6667)  Acc@5: 96.8750 (96.5000)  time: 1.7897  data: 0.0833  max mem: 6790
Train: Epoch[36/60] Total time: 0:00:17 (1.7991 s / it)
Averaged stats: Lr: 0.000093  Loss: 0.4151  Acc@1: 87.5000 (88.6667)  Acc@5: 96.8750 (96.5000)
Train: Epoch[37/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000086  Loss: 0.3215  Acc@1: 85.9375 (85.9375)  Acc@5: 98.4375 (98.4375)  time: 2.7752  data: 0.7382  max mem: 6790
Train: Epoch[37/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000086  Loss: 0.6958  Acc@1: 89.0625 (89.1667)  Acc@5: 96.8750 (96.1667)  time: 1.7943  data: 0.0740  max mem: 6790
Train: Epoch[37/60] Total time: 0:00:18 (1.8031 s / it)
Averaged stats: Lr: 0.000086  Loss: 0.6958  Acc@1: 89.0625 (89.1667)  Acc@5: 96.8750 (96.1667)
Train: Epoch[38/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000080  Loss: 0.1946  Acc@1: 96.8750 (96.8750)  Acc@5: 98.4375 (98.4375)  time: 2.8899  data: 0.8842  max mem: 6790
Train: Epoch[38/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000080  Loss: 0.2001  Acc@1: 89.0625 (89.1667)  Acc@5: 98.4375 (97.6667)  time: 1.7857  data: 0.0886  max mem: 6790
Train: Epoch[38/60] Total time: 0:00:17 (1.7944 s / it)
Averaged stats: Lr: 0.000080  Loss: 0.2001  Acc@1: 89.0625 (89.1667)  Acc@5: 98.4375 (97.6667)
Train: Epoch[39/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000074  Loss: 0.2614  Acc@1: 89.0625 (89.0625)  Acc@5: 96.8750 (96.8750)  time: 2.8100  data: 0.7742  max mem: 6790
Train: Epoch[39/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000074  Loss: 0.3574  Acc@1: 87.5000 (87.6667)  Acc@5: 96.8750 (96.3333)  time: 1.7791  data: 0.0776  max mem: 6790
Train: Epoch[39/60] Total time: 0:00:17 (1.7870 s / it)
Averaged stats: Lr: 0.000074  Loss: 0.3574  Acc@1: 87.5000 (87.6667)  Acc@5: 96.8750 (96.3333)
Train: Epoch[40/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000068  Loss: 0.2501  Acc@1: 90.6250 (90.6250)  Acc@5: 98.4375 (98.4375)  time: 2.8661  data: 0.7428  max mem: 6790
Train: Epoch[40/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000068  Loss: 0.4936  Acc@1: 87.5000 (87.8333)  Acc@5: 96.8750 (97.0000)  time: 1.7857  data: 0.0744  max mem: 6790
Train: Epoch[40/60] Total time: 0:00:17 (1.7958 s / it)
Averaged stats: Lr: 0.000068  Loss: 0.4936  Acc@1: 87.5000 (87.8333)  Acc@5: 96.8750 (97.0000)
Train: Epoch[41/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000063  Loss: 0.2375  Acc@1: 89.0625 (89.0625)  Acc@5: 98.4375 (98.4375)  time: 2.8462  data: 0.7387  max mem: 6790
Train: Epoch[41/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000063  Loss: 0.3603  Acc@1: 89.0625 (88.8333)  Acc@5: 98.4375 (97.8333)  time: 1.7825  data: 0.0740  max mem: 6790
Train: Epoch[41/60] Total time: 0:00:17 (1.7905 s / it)
Averaged stats: Lr: 0.000063  Loss: 0.3603  Acc@1: 89.0625 (88.8333)  Acc@5: 98.4375 (97.8333)
Train: Epoch[42/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000057  Loss: 0.3182  Acc@1: 84.3750 (84.3750)  Acc@5: 96.8750 (96.8750)  time: 2.8716  data: 0.7165  max mem: 6790
Train: Epoch[42/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000057  Loss: 0.3150  Acc@1: 85.9375 (87.1667)  Acc@5: 96.8750 (96.8333)  time: 1.7858  data: 0.0718  max mem: 6790
Train: Epoch[42/60] Total time: 0:00:17 (1.7948 s / it)
Averaged stats: Lr: 0.000057  Loss: 0.3150  Acc@1: 85.9375 (87.1667)  Acc@5: 96.8750 (96.8333)
Train: Epoch[43/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000052  Loss: 0.2811  Acc@1: 89.0625 (89.0625)  Acc@5: 98.4375 (98.4375)  time: 2.8755  data: 0.7180  max mem: 6790
Train: Epoch[43/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000052  Loss: 0.2557  Acc@1: 89.0625 (89.3333)  Acc@5: 96.8750 (97.5000)  time: 1.7888  data: 0.0719  max mem: 6790
Train: Epoch[43/60] Total time: 0:00:17 (1.7969 s / it)
Averaged stats: Lr: 0.000052  Loss: 0.2557  Acc@1: 89.0625 (89.3333)  Acc@5: 96.8750 (97.5000)
Train: Epoch[44/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000046  Loss: 0.2918  Acc@1: 84.3750 (84.3750)  Acc@5: 95.3125 (95.3125)  time: 2.8211  data: 0.7439  max mem: 6790
Train: Epoch[44/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000046  Loss: 0.2317  Acc@1: 91.6667 (90.0000)  Acc@5: 96.8750 (97.1667)  time: 1.7820  data: 0.0745  max mem: 6790
Train: Epoch[44/60] Total time: 0:00:17 (1.7920 s / it)
Averaged stats: Lr: 0.000046  Loss: 0.2317  Acc@1: 91.6667 (90.0000)  Acc@5: 96.8750 (97.1667)
Train: Epoch[45/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000041  Loss: 0.2031  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)  time: 2.8677  data: 0.8032  max mem: 6790
Train: Epoch[45/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000041  Loss: 0.1939  Acc@1: 89.0625 (89.1667)  Acc@5: 96.8750 (97.6667)  time: 1.7861  data: 0.0805  max mem: 6790
Train: Epoch[45/60] Total time: 0:00:17 (1.7941 s / it)
Averaged stats: Lr: 0.000041  Loss: 0.1939  Acc@1: 89.0625 (89.1667)  Acc@5: 96.8750 (97.6667)
Train: Epoch[46/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000037  Loss: 0.2821  Acc@1: 81.2500 (81.2500)  Acc@5: 98.4375 (98.4375)  time: 2.8758  data: 0.8481  max mem: 6790
Train: Epoch[46/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000037  Loss: 0.1122  Acc@1: 92.1875 (91.1667)  Acc@5: 98.4375 (97.3333)  time: 1.8081  data: 0.0849  max mem: 6790
Train: Epoch[46/60] Total time: 0:00:18 (1.8180 s / it)
Averaged stats: Lr: 0.000037  Loss: 0.1122  Acc@1: 92.1875 (91.1667)  Acc@5: 98.4375 (97.3333)
Train: Epoch[47/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000032  Loss: 0.2695  Acc@1: 85.9375 (85.9375)  Acc@5: 96.8750 (96.8750)  time: 2.9508  data: 0.8661  max mem: 6790
Train: Epoch[47/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000032  Loss: 0.2150  Acc@1: 87.5000 (89.6667)  Acc@5: 98.4375 (97.5000)  time: 1.7924  data: 0.0867  max mem: 6790
Train: Epoch[47/60] Total time: 0:00:18 (1.8005 s / it)
Averaged stats: Lr: 0.000032  Loss: 0.2150  Acc@1: 87.5000 (89.6667)  Acc@5: 98.4375 (97.5000)
Train: Epoch[48/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000028  Loss: 0.2448  Acc@1: 90.6250 (90.6250)  Acc@5: 98.4375 (98.4375)  time: 2.8949  data: 0.7128  max mem: 6790
Train: Epoch[48/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000028  Loss: 0.2082  Acc@1: 90.6250 (90.1667)  Acc@5: 98.4375 (97.0000)  time: 1.7896  data: 0.0714  max mem: 6790
Train: Epoch[48/60] Total time: 0:00:17 (1.7991 s / it)
Averaged stats: Lr: 0.000028  Loss: 0.2082  Acc@1: 90.6250 (90.1667)  Acc@5: 98.4375 (97.0000)
Train: Epoch[49/60]  [ 0/10]  eta: 0:00:27  Lr: 0.000024  Loss: 0.3010  Acc@1: 84.3750 (84.3750)  Acc@5: 96.8750 (96.8750)  time: 2.7824  data: 0.7302  max mem: 6790
Train: Epoch[49/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000024  Loss: 0.3140  Acc@1: 87.5000 (89.0000)  Acc@5: 96.8750 (97.0000)  time: 1.7780  data: 0.0732  max mem: 6790
Train: Epoch[49/60] Total time: 0:00:17 (1.7861 s / it)
Averaged stats: Lr: 0.000024  Loss: 0.3140  Acc@1: 87.5000 (89.0000)  Acc@5: 96.8750 (97.0000)
Train: Epoch[50/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000020  Loss: 0.1923  Acc@1: 96.8750 (96.8750)  Acc@5: 96.8750 (96.8750)  time: 2.9262  data: 0.8576  max mem: 6790
Train: Epoch[50/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000020  Loss: 0.1312  Acc@1: 92.1875 (91.0000)  Acc@5: 96.8750 (97.6667)  time: 1.7926  data: 0.0859  max mem: 6790
Train: Epoch[50/60] Total time: 0:00:18 (1.8024 s / it)
Averaged stats: Lr: 0.000020  Loss: 0.1312  Acc@1: 92.1875 (91.0000)  Acc@5: 96.8750 (97.6667)
Train: Epoch[51/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000017  Loss: 0.1851  Acc@1: 90.6250 (90.6250)  Acc@5: 98.4375 (98.4375)  time: 2.8125  data: 0.7348  max mem: 6790
Train: Epoch[51/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000017  Loss: 0.1521  Acc@1: 89.0625 (89.0000)  Acc@5: 98.4375 (97.8333)  time: 1.7801  data: 0.0736  max mem: 6790
Train: Epoch[51/60] Total time: 0:00:17 (1.7879 s / it)
Averaged stats: Lr: 0.000017  Loss: 0.1521  Acc@1: 89.0625 (89.0000)  Acc@5: 98.4375 (97.8333)
Train: Epoch[52/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000014  Loss: 0.2291  Acc@1: 85.9375 (85.9375)  Acc@5: 95.3125 (95.3125)  time: 2.8511  data: 0.7766  max mem: 6790
Train: Epoch[52/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000014  Loss: 0.3943  Acc@1: 90.6250 (90.8333)  Acc@5: 96.8750 (97.6667)  time: 1.7846  data: 0.0778  max mem: 6790
Train: Epoch[52/60] Total time: 0:00:17 (1.7945 s / it)
Averaged stats: Lr: 0.000014  Loss: 0.3943  Acc@1: 90.6250 (90.8333)  Acc@5: 96.8750 (97.6667)
Train: Epoch[53/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000011  Loss: 0.2969  Acc@1: 84.3750 (84.3750)  Acc@5: 95.3125 (95.3125)  time: 2.8915  data: 0.7493  max mem: 6790
Train: Epoch[53/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000011  Loss: 0.3797  Acc@1: 85.9375 (87.1667)  Acc@5: 95.3125 (95.8333)  time: 1.7895  data: 0.0751  max mem: 6790
Train: Epoch[53/60] Total time: 0:00:17 (1.7974 s / it)
Averaged stats: Lr: 0.000011  Loss: 0.3797  Acc@1: 85.9375 (87.1667)  Acc@5: 95.3125 (95.8333)
Train: Epoch[54/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000008  Loss: 0.2395  Acc@1: 90.6250 (90.6250)  Acc@5: 96.8750 (96.8750)  time: 2.9288  data: 0.8492  max mem: 6790
Train: Epoch[54/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000008  Loss: 0.1449  Acc@1: 90.6250 (91.6667)  Acc@5: 96.8750 (97.6667)  time: 1.8132  data: 0.0851  max mem: 6790
Train: Epoch[54/60] Total time: 0:00:18 (1.8240 s / it)
Averaged stats: Lr: 0.000008  Loss: 0.1449  Acc@1: 90.6250 (91.6667)  Acc@5: 96.8750 (97.6667)
Train: Epoch[55/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000006  Loss: 0.2109  Acc@1: 89.0625 (89.0625)  Acc@5: 96.8750 (96.8750)  time: 2.8451  data: 0.7371  max mem: 6790
Train: Epoch[55/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000006  Loss: 0.1346  Acc@1: 89.0625 (89.5000)  Acc@5: 98.4375 (98.0000)  time: 1.7856  data: 0.0738  max mem: 6790
Train: Epoch[55/60] Total time: 0:00:17 (1.7938 s / it)
Averaged stats: Lr: 0.000006  Loss: 0.1346  Acc@1: 89.0625 (89.5000)  Acc@5: 98.4375 (98.0000)
Train: Epoch[56/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000004  Loss: 0.1577  Acc@1: 93.7500 (93.7500)  Acc@5: 98.4375 (98.4375)  time: 2.9099  data: 0.8110  max mem: 6790
Train: Epoch[56/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000004  Loss: 0.3147  Acc@1: 87.5000 (88.3333)  Acc@5: 98.4375 (97.6667)  time: 1.7941  data: 0.0812  max mem: 6790
Train: Epoch[56/60] Total time: 0:00:18 (1.8054 s / it)
Averaged stats: Lr: 0.000004  Loss: 0.3147  Acc@1: 87.5000 (88.3333)  Acc@5: 98.4375 (97.6667)
Train: Epoch[57/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000003  Loss: 0.2885  Acc@1: 85.9375 (85.9375)  Acc@5: 95.3125 (95.3125)  time: 2.8866  data: 0.8121  max mem: 6790
Train: Epoch[57/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000003  Loss: 0.1199  Acc@1: 87.5000 (89.1667)  Acc@5: 98.4375 (98.1667)  time: 1.7857  data: 0.0813  max mem: 6790
Train: Epoch[57/60] Total time: 0:00:17 (1.7937 s / it)
Averaged stats: Lr: 0.000003  Loss: 0.1199  Acc@1: 87.5000 (89.1667)  Acc@5: 98.4375 (98.1667)
Train: Epoch[58/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000002  Loss: 0.1321  Acc@1: 93.7500 (93.7500)  Acc@5: 98.4375 (98.4375)  time: 2.8784  data: 0.8378  max mem: 6790
Train: Epoch[58/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000002  Loss: 0.2927  Acc@1: 89.0625 (90.0000)  Acc@5: 98.4375 (97.6667)  time: 1.7885  data: 0.0839  max mem: 6790
Train: Epoch[58/60] Total time: 0:00:17 (1.7986 s / it)
Averaged stats: Lr: 0.000002  Loss: 0.2927  Acc@1: 89.0625 (90.0000)  Acc@5: 98.4375 (97.6667)
Train: Epoch[59/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000001  Loss: 0.1129  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)  time: 2.9077  data: 0.8646  max mem: 6790
Train: Epoch[59/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000001  Loss: 0.2167  Acc@1: 90.6250 (90.5000)  Acc@5: 98.4375 (97.6667)  time: 1.7912  data: 0.0866  max mem: 6790
Train: Epoch[59/60] Total time: 0:00:17 (1.7991 s / it)
Averaged stats: Lr: 0.000001  Loss: 0.2167  Acc@1: 90.6250 (90.5000)  Acc@5: 98.4375 (97.6667)
Train: Epoch[60/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000000  Loss: 0.2601  Acc@1: 87.5000 (87.5000)  Acc@5: 96.8750 (96.8750)  time: 2.8577  data: 0.7556  max mem: 6790
Train: Epoch[60/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000000  Loss: 0.1651  Acc@1: 89.0625 (90.0000)  Acc@5: 98.4375 (97.3333)  time: 1.7893  data: 0.0757  max mem: 6790
Train: Epoch[60/60] Total time: 0:00:17 (1.7991 s / it)
Averaged stats: Lr: 0.000000  Loss: 0.1651  Acc@1: 89.0625 (90.0000)  Acc@5: 98.4375 (97.3333)
Test: [Task 1]  [0/9]  eta: 0:00:14  Loss: 0.3292 (0.3292)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)  time: 1.6569  data: 0.9026  max mem: 6790
Test: [Task 1]  [8/9]  eta: 0:00:00  Loss: 0.1565 (0.2336)  Acc@1: 96.8750 (92.6214)  Acc@5: 100.0000 (99.6117)  time: 0.6442  data: 0.1006  max mem: 6790
Test: [Task 1] Total time: 0:00:05 (0.6533 s / it)
* Acc@1 92.621 Acc@5 99.612 loss 0.234
Batchwise eval time for task 1 = 0.6532905101776123
Test: [Task 2]  [0/9]  eta: 0:00:15  Loss: 0.2390 (0.2390)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 1.7616  data: 1.0017  max mem: 6790
Test: [Task 2]  [8/9]  eta: 0:00:00  Loss: 0.8617 (0.7322)  Acc@1: 73.4375 (74.4348)  Acc@5: 100.0000 (98.9565)  time: 0.6999  data: 0.1115  max mem: 6790
Test: [Task 2] Total time: 0:00:06 (0.7086 s / it)
* Acc@1 74.435 Acc@5 98.957 loss 0.732
Batchwise eval time for task 2 = 0.7086557547251383
Test: [Task 3]  [ 0/10]  eta: 0:00:16  Loss: 0.2144 (0.2144)  Acc@1: 96.8750 (96.8750)  Acc@5: 98.4375 (98.4375)  time: 1.6674  data: 0.9940  max mem: 6790
Test: [Task 3]  [ 9/10]  eta: 0:00:00  Loss: 0.2749 (0.3754)  Acc@1: 92.1875 (91.7785)  Acc@5: 100.0000 (99.4966)  time: 0.6842  data: 0.0996  max mem: 6790
Test: [Task 3] Total time: 0:00:06 (0.6925 s / it)
* Acc@1 91.779 Acc@5 99.497 loss 0.375
Batchwise eval time for task 3 = 0.692545485496521
[Average accuracy till task3]	Acc@1: 86.1210	Acc@5: 99.3549	Loss: 0.4471	Forgetting: 6.0084	Backward: -6.0084
Eval time for task 3 = 19.289504766464233
Using adam optimizer
Reinitialising optimizer
Similarity:  tensor(0.9161)  Task:  3
Old Num K:  7 New Num K:  8
Task number:  3
Train: Epoch[ 1/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000250  Loss: 3.0767  Acc@1: 0.0000 (0.0000)  Acc@5: 3.1250 (3.1250)  time: 3.0011  data: 0.7364  max mem: 6832
Train: Epoch[ 1/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000250  Loss: 3.6202  Acc@1: 0.0000 (0.1667)  Acc@5: 6.2500 (5.6667)  time: 1.9091  data: 0.0738  max mem: 6843
Train: Epoch[ 1/60] Total time: 0:00:19 (1.9178 s / it)
Averaged stats: Lr: 0.000250  Loss: 3.6202  Acc@1: 0.0000 (0.1667)  Acc@5: 6.2500 (5.6667)
Train: Epoch[ 2/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000250  Loss: 3.5172  Acc@1: 1.5625 (1.5625)  Acc@5: 15.6250 (15.6250)  time: 2.9445  data: 0.7640  max mem: 6843
Train: Epoch[ 2/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000250  Loss: 1.9800  Acc@1: 1.5625 (2.5000)  Acc@5: 17.1875 (21.0000)  time: 1.9219  data: 0.0765  max mem: 6843
Train: Epoch[ 2/60] Total time: 0:00:19 (1.9305 s / it)
Averaged stats: Lr: 0.000250  Loss: 1.9800  Acc@1: 1.5625 (2.5000)  Acc@5: 17.1875 (21.0000)
Train: Epoch[ 3/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000249  Loss: 2.3220  Acc@1: 7.8125 (7.8125)  Acc@5: 40.6250 (40.6250)  time: 2.9401  data: 0.8211  max mem: 6843
Train: Epoch[ 3/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000249  Loss: 2.0970  Acc@1: 7.8125 (9.3333)  Acc@5: 46.8750 (49.8333)  time: 1.8951  data: 0.0822  max mem: 6843
Train: Epoch[ 3/60] Total time: 0:00:19 (1.9056 s / it)
Averaged stats: Lr: 0.000249  Loss: 2.0970  Acc@1: 7.8125 (9.3333)  Acc@5: 46.8750 (49.8333)
Train: Epoch[ 4/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000248  Loss: 1.8688  Acc@1: 10.9375 (10.9375)  Acc@5: 59.3750 (59.3750)  time: 2.9670  data: 0.7156  max mem: 6843
Train: Epoch[ 4/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000248  Loss: 1.4646  Acc@1: 20.3125 (20.1667)  Acc@5: 67.1875 (67.0000)  time: 1.9020  data: 0.0717  max mem: 6843
Train: Epoch[ 4/60] Total time: 0:00:19 (1.9099 s / it)
Averaged stats: Lr: 0.000248  Loss: 1.4646  Acc@1: 20.3125 (20.1667)  Acc@5: 67.1875 (67.0000)
Train: Epoch[ 5/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000247  Loss: 1.4624  Acc@1: 28.1250 (28.1250)  Acc@5: 76.5625 (76.5625)  time: 3.0379  data: 0.7405  max mem: 6843
Train: Epoch[ 5/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000247  Loss: 1.4187  Acc@1: 28.1250 (28.5000)  Acc@5: 75.0000 (75.5000)  time: 1.9104  data: 0.0742  max mem: 6843
Train: Epoch[ 5/60] Total time: 0:00:19 (1.9209 s / it)
Averaged stats: Lr: 0.000247  Loss: 1.4187  Acc@1: 28.1250 (28.5000)  Acc@5: 75.0000 (75.5000)
Train: Epoch[ 6/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000246  Loss: 1.2078  Acc@1: 39.0625 (39.0625)  Acc@5: 87.5000 (87.5000)  time: 3.0370  data: 0.8544  max mem: 6843
Train: Epoch[ 6/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000246  Loss: 1.3983  Acc@1: 37.5000 (39.8333)  Acc@5: 81.2500 (83.8333)  time: 1.9109  data: 0.0856  max mem: 6843
Train: Epoch[ 6/60] Total time: 0:00:19 (1.9190 s / it)
Averaged stats: Lr: 0.000246  Loss: 1.3983  Acc@1: 37.5000 (39.8333)  Acc@5: 81.2500 (83.8333)
Train: Epoch[ 7/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000244  Loss: 1.2803  Acc@1: 45.3125 (45.3125)  Acc@5: 84.3750 (84.3750)  time: 2.9881  data: 0.8484  max mem: 6843
Train: Epoch[ 7/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000244  Loss: 1.0357  Acc@1: 46.8750 (45.6667)  Acc@5: 84.3750 (84.6667)  time: 1.9051  data: 0.0850  max mem: 6843
Train: Epoch[ 7/60] Total time: 0:00:19 (1.9144 s / it)
Averaged stats: Lr: 0.000244  Loss: 1.0357  Acc@1: 46.8750 (45.6667)  Acc@5: 84.3750 (84.6667)
Train: Epoch[ 8/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000242  Loss: 1.0922  Acc@1: 53.1250 (53.1250)  Acc@5: 93.7500 (93.7500)  time: 2.9765  data: 0.7185  max mem: 6843
Train: Epoch[ 8/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000242  Loss: 1.1094  Acc@1: 50.0000 (50.3333)  Acc@5: 87.5000 (88.6667)  time: 1.9048  data: 0.0720  max mem: 6843
Train: Epoch[ 8/60] Total time: 0:00:19 (1.9130 s / it)
Averaged stats: Lr: 0.000242  Loss: 1.1094  Acc@1: 50.0000 (50.3333)  Acc@5: 87.5000 (88.6667)
Train: Epoch[ 9/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000239  Loss: 1.0073  Acc@1: 54.6875 (54.6875)  Acc@5: 87.5000 (87.5000)  time: 3.0218  data: 0.8621  max mem: 6843
Train: Epoch[ 9/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000239  Loss: 0.8354  Acc@1: 53.1250 (52.6667)  Acc@5: 89.0625 (89.1667)  time: 1.9101  data: 0.0863  max mem: 6843
Train: Epoch[ 9/60] Total time: 0:00:19 (1.9191 s / it)
Averaged stats: Lr: 0.000239  Loss: 0.8354  Acc@1: 53.1250 (52.6667)  Acc@5: 89.0625 (89.1667)
Train: Epoch[10/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000236  Loss: 0.9200  Acc@1: 54.6875 (54.6875)  Acc@5: 93.7500 (93.7500)  time: 3.0368  data: 0.7266  max mem: 6843
Train: Epoch[10/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000236  Loss: 0.7546  Acc@1: 54.6875 (55.6667)  Acc@5: 92.1875 (91.3333)  time: 1.9099  data: 0.0728  max mem: 6843
Train: Epoch[10/60] Total time: 0:00:19 (1.9178 s / it)
Averaged stats: Lr: 0.000236  Loss: 0.7546  Acc@1: 54.6875 (55.6667)  Acc@5: 92.1875 (91.3333)
Train: Epoch[11/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000233  Loss: 0.8439  Acc@1: 64.0625 (64.0625)  Acc@5: 87.5000 (87.5000)  time: 3.0807  data: 0.8348  max mem: 6843
Train: Epoch[11/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000233  Loss: 0.7836  Acc@1: 53.1250 (55.8333)  Acc@5: 91.6667 (92.1667)  time: 1.9338  data: 0.0836  max mem: 6843
Train: Epoch[11/60] Total time: 0:00:19 (1.9444 s / it)
Averaged stats: Lr: 0.000233  Loss: 0.7836  Acc@1: 53.1250 (55.8333)  Acc@5: 91.6667 (92.1667)
Train: Epoch[12/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000230  Loss: 0.7976  Acc@1: 64.0625 (64.0625)  Acc@5: 93.7500 (93.7500)  time: 3.0733  data: 0.8039  max mem: 6843
Train: Epoch[12/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000230  Loss: 0.6861  Acc@1: 53.1250 (56.6667)  Acc@5: 92.1875 (91.0000)  time: 1.9112  data: 0.0805  max mem: 6843
Train: Epoch[12/60] Total time: 0:00:19 (1.9193 s / it)
Averaged stats: Lr: 0.000230  Loss: 0.6861  Acc@1: 53.1250 (56.6667)  Acc@5: 92.1875 (91.0000)
Train: Epoch[13/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000226  Loss: 0.8629  Acc@1: 46.8750 (46.8750)  Acc@5: 87.5000 (87.5000)  time: 2.9834  data: 0.8038  max mem: 6843
Train: Epoch[13/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000226  Loss: 0.8097  Acc@1: 60.9375 (58.8333)  Acc@5: 92.1875 (92.6667)  time: 1.9017  data: 0.0805  max mem: 6843
Train: Epoch[13/60] Total time: 0:00:19 (1.9128 s / it)
Averaged stats: Lr: 0.000226  Loss: 0.8097  Acc@1: 60.9375 (58.8333)  Acc@5: 92.1875 (92.6667)
Train: Epoch[14/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000222  Loss: 0.8821  Acc@1: 48.4375 (48.4375)  Acc@5: 95.3125 (95.3125)  time: 2.9999  data: 0.7099  max mem: 6843
Train: Epoch[14/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000222  Loss: 0.6447  Acc@1: 57.8125 (57.6667)  Acc@5: 90.6250 (90.5000)  time: 1.9042  data: 0.0711  max mem: 6843
Train: Epoch[14/60] Total time: 0:00:19 (1.9122 s / it)
Averaged stats: Lr: 0.000222  Loss: 0.6447  Acc@1: 57.8125 (57.6667)  Acc@5: 90.6250 (90.5000)
Train: Epoch[15/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000218  Loss: 0.6934  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (93.7500)  time: 3.0239  data: 0.8654  max mem: 6843
Train: Epoch[15/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000218  Loss: 0.7593  Acc@1: 62.5000 (60.8333)  Acc@5: 92.1875 (93.3333)  time: 1.9097  data: 0.0867  max mem: 6843
Train: Epoch[15/60] Total time: 0:00:19 (1.9196 s / it)
Averaged stats: Lr: 0.000218  Loss: 0.7593  Acc@1: 62.5000 (60.8333)  Acc@5: 92.1875 (93.3333)
Train: Epoch[16/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000213  Loss: 0.7152  Acc@1: 64.0625 (64.0625)  Acc@5: 96.8750 (96.8750)  time: 3.0023  data: 0.7731  max mem: 6843
Train: Epoch[16/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000213  Loss: 0.7628  Acc@1: 62.5000 (62.1667)  Acc@5: 95.8333 (94.6667)  time: 1.9059  data: 0.0774  max mem: 6843
Train: Epoch[16/60] Total time: 0:00:19 (1.9142 s / it)
Averaged stats: Lr: 0.000213  Loss: 0.7628  Acc@1: 62.5000 (62.1667)  Acc@5: 95.8333 (94.6667)
Train: Epoch[17/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000209  Loss: 0.7515  Acc@1: 56.2500 (56.2500)  Acc@5: 92.1875 (92.1875)  time: 3.0153  data: 0.7971  max mem: 6843
Train: Epoch[17/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000209  Loss: 0.6245  Acc@1: 60.9375 (60.1667)  Acc@5: 92.1875 (91.8333)  time: 1.9098  data: 0.0799  max mem: 6843
Train: Epoch[17/60] Total time: 0:00:19 (1.9204 s / it)
Averaged stats: Lr: 0.000209  Loss: 0.6245  Acc@1: 60.9375 (60.1667)  Acc@5: 92.1875 (91.8333)
Train: Epoch[18/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000204  Loss: 0.6900  Acc@1: 57.8125 (57.8125)  Acc@5: 92.1875 (92.1875)  time: 2.9746  data: 0.7452  max mem: 6843
Train: Epoch[18/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000204  Loss: 0.5395  Acc@1: 62.5000 (63.0000)  Acc@5: 93.7500 (93.0000)  time: 1.9267  data: 0.0746  max mem: 6843
Train: Epoch[18/60] Total time: 0:00:19 (1.9354 s / it)
Averaged stats: Lr: 0.000204  Loss: 0.5395  Acc@1: 62.5000 (63.0000)  Acc@5: 93.7500 (93.0000)
Train: Epoch[19/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000198  Loss: 0.6861  Acc@1: 60.9375 (60.9375)  Acc@5: 92.1875 (92.1875)  time: 3.0097  data: 0.8107  max mem: 6843
Train: Epoch[19/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000198  Loss: 0.6488  Acc@1: 66.6667 (66.1667)  Acc@5: 93.7500 (94.1667)  time: 1.9045  data: 0.0812  max mem: 6843
Train: Epoch[19/60] Total time: 0:00:19 (1.9143 s / it)
Averaged stats: Lr: 0.000198  Loss: 0.6488  Acc@1: 66.6667 (66.1667)  Acc@5: 93.7500 (94.1667)
Train: Epoch[20/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000193  Loss: 0.6142  Acc@1: 68.7500 (68.7500)  Acc@5: 96.8750 (96.8750)  time: 2.9666  data: 0.7277  max mem: 6843
Train: Epoch[20/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000193  Loss: 0.8684  Acc@1: 65.6250 (65.8333)  Acc@5: 93.7500 (94.5000)  time: 1.9035  data: 0.0729  max mem: 6843
Train: Epoch[20/60] Total time: 0:00:19 (1.9117 s / it)
Averaged stats: Lr: 0.000193  Loss: 0.8684  Acc@1: 65.6250 (65.8333)  Acc@5: 93.7500 (94.5000)
Train: Epoch[21/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000188  Loss: 0.7843  Acc@1: 57.8125 (57.8125)  Acc@5: 92.1875 (92.1875)  time: 3.0612  data: 0.8602  max mem: 6843
Train: Epoch[21/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000188  Loss: 0.6049  Acc@1: 65.6250 (64.3333)  Acc@5: 93.7500 (93.6667)  time: 1.9101  data: 0.0862  max mem: 6843
Train: Epoch[21/60] Total time: 0:00:19 (1.9193 s / it)
Averaged stats: Lr: 0.000188  Loss: 0.6049  Acc@1: 65.6250 (64.3333)  Acc@5: 93.7500 (93.6667)
Train: Epoch[22/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000182  Loss: 0.7262  Acc@1: 65.6250 (65.6250)  Acc@5: 92.1875 (92.1875)  time: 2.9677  data: 0.8231  max mem: 6843
Train: Epoch[22/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000182  Loss: 0.7551  Acc@1: 65.6250 (65.8333)  Acc@5: 92.1875 (94.0000)  time: 1.9039  data: 0.0824  max mem: 6843
Train: Epoch[22/60] Total time: 0:00:19 (1.9116 s / it)
Averaged stats: Lr: 0.000182  Loss: 0.7551  Acc@1: 65.6250 (65.8333)  Acc@5: 92.1875 (94.0000)
Train: Epoch[23/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000176  Loss: 0.7346  Acc@1: 57.8125 (57.8125)  Acc@5: 90.6250 (90.6250)  time: 3.0117  data: 0.8437  max mem: 6843
Train: Epoch[23/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000176  Loss: 0.5176  Acc@1: 68.7500 (68.1667)  Acc@5: 95.3125 (94.8333)  time: 1.9059  data: 0.0845  max mem: 6843
Train: Epoch[23/60] Total time: 0:00:19 (1.9162 s / it)
Averaged stats: Lr: 0.000176  Loss: 0.5176  Acc@1: 68.7500 (68.1667)  Acc@5: 95.3125 (94.8333)
Train: Epoch[24/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000170  Loss: 0.5527  Acc@1: 68.7500 (68.7500)  Acc@5: 95.3125 (95.3125)  time: 3.0207  data: 0.8384  max mem: 6843
Train: Epoch[24/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000170  Loss: 0.3623  Acc@1: 68.7500 (67.6667)  Acc@5: 95.3125 (95.1667)  time: 1.9055  data: 0.0840  max mem: 6843
Train: Epoch[24/60] Total time: 0:00:19 (1.9142 s / it)
Averaged stats: Lr: 0.000170  Loss: 0.3623  Acc@1: 68.7500 (67.6667)  Acc@5: 95.3125 (95.1667)
Train: Epoch[25/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000164  Loss: 0.6569  Acc@1: 64.0625 (64.0625)  Acc@5: 92.1875 (92.1875)  time: 3.0171  data: 0.8314  max mem: 6843
Train: Epoch[25/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000164  Loss: 0.6144  Acc@1: 68.7500 (68.1667)  Acc@5: 93.7500 (94.8333)  time: 1.9074  data: 0.0833  max mem: 6843
Train: Epoch[25/60] Total time: 0:00:19 (1.9171 s / it)
Averaged stats: Lr: 0.000164  Loss: 0.6144  Acc@1: 68.7500 (68.1667)  Acc@5: 93.7500 (94.8333)
Train: Epoch[26/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000157  Loss: 0.6081  Acc@1: 65.6250 (65.6250)  Acc@5: 93.7500 (93.7500)  time: 2.9976  data: 0.8378  max mem: 6843
Train: Epoch[26/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000157  Loss: 0.5371  Acc@1: 68.7500 (70.8333)  Acc@5: 95.3125 (94.8333)  time: 1.9041  data: 0.0839  max mem: 6843
Train: Epoch[26/60] Total time: 0:00:19 (1.9120 s / it)
Averaged stats: Lr: 0.000157  Loss: 0.5371  Acc@1: 68.7500 (70.8333)  Acc@5: 95.3125 (94.8333)
Train: Epoch[27/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000151  Loss: 0.6099  Acc@1: 68.7500 (68.7500)  Acc@5: 92.1875 (92.1875)  time: 3.0474  data: 0.8305  max mem: 6843
Train: Epoch[27/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000151  Loss: 0.7278  Acc@1: 65.6250 (70.1667)  Acc@5: 92.1875 (93.8333)  time: 1.9297  data: 0.0832  max mem: 6843
Train: Epoch[27/60] Total time: 0:00:19 (1.9397 s / it)
Averaged stats: Lr: 0.000151  Loss: 0.7278  Acc@1: 65.6250 (70.1667)  Acc@5: 92.1875 (93.8333)
Train: Epoch[28/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000145  Loss: 0.4308  Acc@1: 75.0000 (75.0000)  Acc@5: 96.8750 (96.8750)  time: 3.0588  data: 0.8842  max mem: 6843
Train: Epoch[28/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000145  Loss: 0.6877  Acc@1: 73.4375 (71.8333)  Acc@5: 93.7500 (94.1667)  time: 1.9092  data: 0.0886  max mem: 6843
Train: Epoch[28/60] Total time: 0:00:19 (1.9170 s / it)
Averaged stats: Lr: 0.000145  Loss: 0.6877  Acc@1: 73.4375 (71.8333)  Acc@5: 93.7500 (94.1667)
Train: Epoch[29/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000138  Loss: 0.6578  Acc@1: 65.6250 (65.6250)  Acc@5: 95.3125 (95.3125)  time: 2.9901  data: 0.8207  max mem: 6843
Train: Epoch[29/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000138  Loss: 0.5173  Acc@1: 70.3125 (71.5000)  Acc@5: 96.8750 (96.5000)  time: 1.9013  data: 0.0822  max mem: 6843
Train: Epoch[29/60] Total time: 0:00:19 (1.9107 s / it)
Averaged stats: Lr: 0.000138  Loss: 0.5173  Acc@1: 70.3125 (71.5000)  Acc@5: 96.8750 (96.5000)
Train: Epoch[30/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000132  Loss: 0.5663  Acc@1: 75.0000 (75.0000)  Acc@5: 95.3125 (95.3125)  time: 2.8747  data: 0.7290  max mem: 6843
Train: Epoch[30/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000132  Loss: 0.5580  Acc@1: 73.4375 (72.8333)  Acc@5: 95.3125 (95.0000)  time: 1.8880  data: 0.0730  max mem: 6843
Train: Epoch[30/60] Total time: 0:00:18 (1.8959 s / it)
Averaged stats: Lr: 0.000132  Loss: 0.5580  Acc@1: 73.4375 (72.8333)  Acc@5: 95.3125 (95.0000)
Train: Epoch[31/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000125  Loss: 0.5052  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)  time: 2.8702  data: 0.7095  max mem: 6843
Train: Epoch[31/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000125  Loss: 0.3702  Acc@1: 67.1875 (69.5000)  Acc@5: 93.7500 (93.8333)  time: 1.8875  data: 0.0711  max mem: 6843
Train: Epoch[31/60] Total time: 0:00:18 (1.8982 s / it)
Averaged stats: Lr: 0.000125  Loss: 0.3702  Acc@1: 67.1875 (69.5000)  Acc@5: 93.7500 (93.8333)
Train: Epoch[32/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000118  Loss: 0.6470  Acc@1: 65.6250 (65.6250)  Acc@5: 93.7500 (93.7500)  time: 2.9348  data: 0.8247  max mem: 6843
Train: Epoch[32/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000118  Loss: 0.5276  Acc@1: 71.8750 (72.6667)  Acc@5: 95.3125 (95.3333)  time: 1.8977  data: 0.0826  max mem: 6843
Train: Epoch[32/60] Total time: 0:00:19 (1.9056 s / it)
Averaged stats: Lr: 0.000118  Loss: 0.5276  Acc@1: 71.8750 (72.6667)  Acc@5: 95.3125 (95.3333)
Train: Epoch[33/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000112  Loss: 0.4924  Acc@1: 68.7500 (68.7500)  Acc@5: 95.3125 (95.3125)  time: 2.9241  data: 0.7264  max mem: 6843
Train: Epoch[33/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000112  Loss: 0.6317  Acc@1: 70.8333 (73.6667)  Acc@5: 95.3125 (94.5000)  time: 1.8955  data: 0.0728  max mem: 6843
Train: Epoch[33/60] Total time: 0:00:19 (1.9050 s / it)
Averaged stats: Lr: 0.000112  Loss: 0.6317  Acc@1: 70.8333 (73.6667)  Acc@5: 95.3125 (94.5000)
Train: Epoch[34/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000105  Loss: 0.4363  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)  time: 2.8776  data: 0.7133  max mem: 6843
Train: Epoch[34/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000105  Loss: 0.3757  Acc@1: 71.8750 (72.3333)  Acc@5: 95.3125 (96.5000)  time: 1.8899  data: 0.0715  max mem: 6843
Train: Epoch[34/60] Total time: 0:00:18 (1.8978 s / it)
Averaged stats: Lr: 0.000105  Loss: 0.3757  Acc@1: 71.8750 (72.3333)  Acc@5: 95.3125 (96.5000)
Train: Epoch[35/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000099  Loss: 0.5074  Acc@1: 68.7500 (68.7500)  Acc@5: 95.3125 (95.3125)  time: 2.9237  data: 0.6861  max mem: 6843
Train: Epoch[35/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000099  Loss: 0.2004  Acc@1: 75.0000 (75.5000)  Acc@5: 95.3125 (95.5000)  time: 1.8941  data: 0.0687  max mem: 6843
Train: Epoch[35/60] Total time: 0:00:19 (1.9036 s / it)
Averaged stats: Lr: 0.000099  Loss: 0.2004  Acc@1: 75.0000 (75.5000)  Acc@5: 95.3125 (95.5000)
Train: Epoch[36/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000093  Loss: 0.3295  Acc@1: 73.4375 (73.4375)  Acc@5: 98.4375 (98.4375)  time: 2.9662  data: 0.8405  max mem: 6843
Train: Epoch[36/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000093  Loss: 0.5050  Acc@1: 75.0000 (76.5000)  Acc@5: 95.3125 (96.3333)  time: 1.9001  data: 0.0842  max mem: 6843
Train: Epoch[36/60] Total time: 0:00:19 (1.9080 s / it)
Averaged stats: Lr: 0.000093  Loss: 0.5050  Acc@1: 75.0000 (76.5000)  Acc@5: 95.3125 (96.3333)
Train: Epoch[37/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000086  Loss: 0.5271  Acc@1: 76.5625 (76.5625)  Acc@5: 93.7500 (93.7500)  time: 2.9421  data: 0.8465  max mem: 6843
Train: Epoch[37/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000086  Loss: 0.4984  Acc@1: 76.5625 (75.8333)  Acc@5: 95.3125 (95.5000)  time: 1.9174  data: 0.0848  max mem: 6843
Train: Epoch[37/60] Total time: 0:00:19 (1.9304 s / it)
Averaged stats: Lr: 0.000086  Loss: 0.4984  Acc@1: 76.5625 (75.8333)  Acc@5: 95.3125 (95.5000)
Train: Epoch[38/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000080  Loss: 0.3941  Acc@1: 81.2500 (81.2500)  Acc@5: 96.8750 (96.8750)  time: 2.9063  data: 0.7205  max mem: 6843
Train: Epoch[38/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000080  Loss: 0.4230  Acc@1: 76.5625 (74.5000)  Acc@5: 96.8750 (97.3333)  time: 1.9047  data: 0.0722  max mem: 6843
Train: Epoch[38/60] Total time: 0:00:19 (1.9125 s / it)
Averaged stats: Lr: 0.000080  Loss: 0.4230  Acc@1: 76.5625 (74.5000)  Acc@5: 96.8750 (97.3333)
Train: Epoch[39/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000074  Loss: 0.5953  Acc@1: 67.1875 (67.1875)  Acc@5: 89.0625 (89.0625)  time: 3.0553  data: 0.8183  max mem: 6843
Train: Epoch[39/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000074  Loss: 0.4254  Acc@1: 76.5625 (75.1667)  Acc@5: 95.3125 (94.6667)  time: 1.9123  data: 0.0819  max mem: 6843
Train: Epoch[39/60] Total time: 0:00:19 (1.9217 s / it)
Averaged stats: Lr: 0.000074  Loss: 0.4254  Acc@1: 76.5625 (75.1667)  Acc@5: 95.3125 (94.6667)
Train: Epoch[40/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000068  Loss: 0.3567  Acc@1: 78.1250 (78.1250)  Acc@5: 98.4375 (98.4375)  time: 3.0449  data: 0.7577  max mem: 6843
Train: Epoch[40/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000068  Loss: 0.7232  Acc@1: 75.0000 (76.0000)  Acc@5: 95.3125 (95.6667)  time: 1.9050  data: 0.0759  max mem: 6843
Train: Epoch[40/60] Total time: 0:00:19 (1.9132 s / it)
Averaged stats: Lr: 0.000068  Loss: 0.7232  Acc@1: 75.0000 (76.0000)  Acc@5: 95.3125 (95.6667)
Train: Epoch[41/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000063  Loss: 0.4448  Acc@1: 78.1250 (78.1250)  Acc@5: 96.8750 (96.8750)  time: 3.0012  data: 0.8455  max mem: 6843
Train: Epoch[41/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000063  Loss: 0.5479  Acc@1: 76.5625 (73.5000)  Acc@5: 92.1875 (93.5000)  time: 1.9040  data: 0.0847  max mem: 6843
Train: Epoch[41/60] Total time: 0:00:19 (1.9126 s / it)
Averaged stats: Lr: 0.000063  Loss: 0.5479  Acc@1: 76.5625 (73.5000)  Acc@5: 92.1875 (93.5000)
Train: Epoch[42/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000057  Loss: 0.5264  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)  time: 2.9396  data: 0.8373  max mem: 6843
Train: Epoch[42/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000057  Loss: 0.4031  Acc@1: 75.0000 (74.6667)  Acc@5: 95.8333 (95.8333)  time: 1.8961  data: 0.0839  max mem: 6843
Train: Epoch[42/60] Total time: 0:00:19 (1.9041 s / it)
Averaged stats: Lr: 0.000057  Loss: 0.4031  Acc@1: 75.0000 (74.6667)  Acc@5: 95.8333 (95.8333)
Train: Epoch[43/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000052  Loss: 0.3657  Acc@1: 75.0000 (75.0000)  Acc@5: 96.8750 (96.8750)  time: 2.9469  data: 0.7916  max mem: 6843
Train: Epoch[43/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000052  Loss: 0.3161  Acc@1: 75.0000 (76.8333)  Acc@5: 98.4375 (97.1667)  time: 1.8984  data: 0.0793  max mem: 6843
Train: Epoch[43/60] Total time: 0:00:19 (1.9078 s / it)
Averaged stats: Lr: 0.000052  Loss: 0.3161  Acc@1: 75.0000 (76.8333)  Acc@5: 98.4375 (97.1667)
Train: Epoch[44/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000046  Loss: 0.4471  Acc@1: 79.6875 (79.6875)  Acc@5: 96.8750 (96.8750)  time: 2.9662  data: 0.7701  max mem: 6843
Train: Epoch[44/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000046  Loss: 0.5884  Acc@1: 73.4375 (77.5000)  Acc@5: 95.3125 (95.6667)  time: 1.9012  data: 0.0771  max mem: 6843
Train: Epoch[44/60] Total time: 0:00:19 (1.9093 s / it)
Averaged stats: Lr: 0.000046  Loss: 0.5884  Acc@1: 73.4375 (77.5000)  Acc@5: 95.3125 (95.6667)
Train: Epoch[45/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000041  Loss: 0.4768  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 3.0282  data: 0.8706  max mem: 6843
Train: Epoch[45/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000041  Loss: 0.3976  Acc@1: 78.1250 (78.3333)  Acc@5: 95.3125 (95.8333)  time: 1.9141  data: 0.0872  max mem: 6843
Train: Epoch[45/60] Total time: 0:00:19 (1.9244 s / it)
Averaged stats: Lr: 0.000041  Loss: 0.3976  Acc@1: 78.1250 (78.3333)  Acc@5: 95.3125 (95.8333)
Train: Epoch[46/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000037  Loss: 0.2911  Acc@1: 90.6250 (90.6250)  Acc@5: 98.4375 (98.4375)  time: 3.0128  data: 0.8202  max mem: 6843
Train: Epoch[46/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000037  Loss: 0.1955  Acc@1: 75.0000 (77.0000)  Acc@5: 95.3125 (95.6667)  time: 1.9300  data: 0.0821  max mem: 6843
Train: Epoch[46/60] Total time: 0:00:19 (1.9382 s / it)
Averaged stats: Lr: 0.000037  Loss: 0.1955  Acc@1: 75.0000 (77.0000)  Acc@5: 95.3125 (95.6667)
Train: Epoch[47/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000032  Loss: 0.4510  Acc@1: 79.6875 (79.6875)  Acc@5: 93.7500 (93.7500)  time: 2.9472  data: 0.7393  max mem: 6843
Train: Epoch[47/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000032  Loss: 0.3762  Acc@1: 78.1250 (77.5000)  Acc@5: 95.3125 (96.8333)  time: 1.8983  data: 0.0741  max mem: 6843
Train: Epoch[47/60] Total time: 0:00:19 (1.9072 s / it)
Averaged stats: Lr: 0.000032  Loss: 0.3762  Acc@1: 78.1250 (77.5000)  Acc@5: 95.3125 (96.8333)
Train: Epoch[48/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000028  Loss: 0.3883  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)  time: 2.9537  data: 0.7160  max mem: 6843
Train: Epoch[48/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000028  Loss: 0.3986  Acc@1: 76.5625 (77.8333)  Acc@5: 95.8333 (96.1667)  time: 1.8963  data: 0.0717  max mem: 6843
Train: Epoch[48/60] Total time: 0:00:19 (1.9043 s / it)
Averaged stats: Lr: 0.000028  Loss: 0.3986  Acc@1: 76.5625 (77.8333)  Acc@5: 95.8333 (96.1667)
Train: Epoch[49/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000024  Loss: 0.4328  Acc@1: 78.1250 (78.1250)  Acc@5: 92.1875 (92.1875)  time: 2.9549  data: 0.6741  max mem: 6843
Train: Epoch[49/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000024  Loss: 0.3986  Acc@1: 79.6875 (79.0000)  Acc@5: 95.8333 (95.6667)  time: 1.8942  data: 0.0675  max mem: 6843
Train: Epoch[49/60] Total time: 0:00:19 (1.9040 s / it)
Averaged stats: Lr: 0.000024  Loss: 0.3986  Acc@1: 79.6875 (79.0000)  Acc@5: 95.8333 (95.6667)
Train: Epoch[50/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000020  Loss: 0.4439  Acc@1: 76.5625 (76.5625)  Acc@5: 93.7500 (93.7500)  time: 2.9629  data: 0.8073  max mem: 6843
Train: Epoch[50/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000020  Loss: 0.3442  Acc@1: 76.5625 (78.0000)  Acc@5: 96.8750 (95.6667)  time: 1.8962  data: 0.0809  max mem: 6843
Train: Epoch[50/60] Total time: 0:00:19 (1.9039 s / it)
Averaged stats: Lr: 0.000020  Loss: 0.3442  Acc@1: 76.5625 (78.0000)  Acc@5: 96.8750 (95.6667)
Train: Epoch[51/60]  [ 0/10]  eta: 0:00:28  Lr: 0.000017  Loss: 0.4097  Acc@1: 78.1250 (78.1250)  Acc@5: 93.7500 (93.7500)  time: 2.8922  data: 0.6839  max mem: 6843
Train: Epoch[51/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000017  Loss: 0.5271  Acc@1: 75.0000 (75.5000)  Acc@5: 95.3125 (94.3333)  time: 1.8910  data: 0.0685  max mem: 6843
Train: Epoch[51/60] Total time: 0:00:19 (1.9005 s / it)
Averaged stats: Lr: 0.000017  Loss: 0.5271  Acc@1: 75.0000 (75.5000)  Acc@5: 95.3125 (94.3333)
Train: Epoch[52/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000014  Loss: 0.2861  Acc@1: 81.2500 (81.2500)  Acc@5: 98.4375 (98.4375)  time: 2.9709  data: 0.8595  max mem: 6843
Train: Epoch[52/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000014  Loss: 0.4078  Acc@1: 76.5625 (77.6667)  Acc@5: 95.3125 (96.1667)  time: 1.8993  data: 0.0861  max mem: 6843
Train: Epoch[52/60] Total time: 0:00:19 (1.9071 s / it)
Averaged stats: Lr: 0.000014  Loss: 0.4078  Acc@1: 76.5625 (77.6667)  Acc@5: 95.3125 (96.1667)
Train: Epoch[53/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000011  Loss: 0.4654  Acc@1: 75.0000 (75.0000)  Acc@5: 95.3125 (95.3125)  time: 3.0598  data: 0.8327  max mem: 6843
Train: Epoch[53/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000011  Loss: 0.5619  Acc@1: 78.1250 (78.0000)  Acc@5: 95.3125 (96.1667)  time: 1.9286  data: 0.0834  max mem: 6843
Train: Epoch[53/60] Total time: 0:00:19 (1.9393 s / it)
Averaged stats: Lr: 0.000011  Loss: 0.5619  Acc@1: 78.1250 (78.0000)  Acc@5: 95.3125 (96.1667)
Train: Epoch[54/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000008  Loss: 0.2839  Acc@1: 84.3750 (84.3750)  Acc@5: 98.4375 (98.4375)  time: 3.2888  data: 0.9252  max mem: 6843
Train: Epoch[54/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000008  Loss: 0.2406  Acc@1: 78.1250 (80.1667)  Acc@5: 96.8750 (96.8333)  time: 1.9461  data: 0.0926  max mem: 6843
Train: Epoch[54/60] Total time: 0:00:19 (1.9539 s / it)
Averaged stats: Lr: 0.000008  Loss: 0.2406  Acc@1: 78.1250 (80.1667)  Acc@5: 96.8750 (96.8333)
Train: Epoch[55/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000006  Loss: 0.2806  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 3.1890  data: 0.8129  max mem: 6843
Train: Epoch[55/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000006  Loss: 0.1168  Acc@1: 78.1250 (79.1667)  Acc@5: 96.8750 (96.3333)  time: 1.9337  data: 0.0814  max mem: 6843
Train: Epoch[55/60] Total time: 0:00:19 (1.9444 s / it)
Averaged stats: Lr: 0.000006  Loss: 0.1168  Acc@1: 78.1250 (79.1667)  Acc@5: 96.8750 (96.3333)
Train: Epoch[56/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000004  Loss: 0.4260  Acc@1: 73.4375 (73.4375)  Acc@5: 96.8750 (96.8750)  time: 2.9573  data: 0.8275  max mem: 6843
Train: Epoch[56/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000004  Loss: 0.3841  Acc@1: 78.1250 (78.8333)  Acc@5: 95.3125 (95.8333)  time: 1.8978  data: 0.0829  max mem: 6843
Train: Epoch[56/60] Total time: 0:00:19 (1.9056 s / it)
Averaged stats: Lr: 0.000004  Loss: 0.3841  Acc@1: 78.1250 (78.8333)  Acc@5: 95.3125 (95.8333)
Train: Epoch[57/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000003  Loss: 0.3134  Acc@1: 79.6875 (79.6875)  Acc@5: 95.3125 (95.3125)  time: 2.9395  data: 0.7071  max mem: 6843
Train: Epoch[57/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000003  Loss: 0.6208  Acc@1: 76.5625 (76.1667)  Acc@5: 96.8750 (96.5000)  time: 1.9057  data: 0.0709  max mem: 6843
Train: Epoch[57/60] Total time: 0:00:19 (1.9150 s / it)
Averaged stats: Lr: 0.000003  Loss: 0.6208  Acc@1: 76.5625 (76.1667)  Acc@5: 96.8750 (96.5000)
Train: Epoch[58/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000002  Loss: 0.4685  Acc@1: 76.5625 (76.5625)  Acc@5: 93.7500 (93.7500)  time: 3.0218  data: 0.7368  max mem: 6843
Train: Epoch[58/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000002  Loss: 0.5125  Acc@1: 76.5625 (78.1667)  Acc@5: 93.7500 (95.1667)  time: 1.9139  data: 0.0738  max mem: 6843
Train: Epoch[58/60] Total time: 0:00:19 (1.9218 s / it)
Averaged stats: Lr: 0.000002  Loss: 0.5125  Acc@1: 76.5625 (78.1667)  Acc@5: 93.7500 (95.1667)
Train: Epoch[59/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000001  Loss: 0.4075  Acc@1: 71.8750 (71.8750)  Acc@5: 90.6250 (90.6250)  time: 3.0538  data: 0.9279  max mem: 6843
Train: Epoch[59/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000001  Loss: 0.2362  Acc@1: 75.0000 (77.6667)  Acc@5: 95.3125 (95.3333)  time: 1.9047  data: 0.0929  max mem: 6843
Train: Epoch[59/60] Total time: 0:00:19 (1.9145 s / it)
Averaged stats: Lr: 0.000001  Loss: 0.2362  Acc@1: 75.0000 (77.6667)  Acc@5: 95.3125 (95.3333)
Train: Epoch[60/60]  [ 0/10]  eta: 0:00:29  Lr: 0.000000  Loss: 0.4701  Acc@1: 73.4375 (73.4375)  Acc@5: 90.6250 (90.6250)  time: 2.9497  data: 0.7052  max mem: 6843
Train: Epoch[60/60]  [ 9/10]  eta: 0:00:01  Lr: 0.000000  Loss: 0.1206  Acc@1: 76.5625 (76.1667)  Acc@5: 95.3125 (95.3333)  time: 1.9018  data: 0.0707  max mem: 6843
Train: Epoch[60/60] Total time: 0:00:19 (1.9099 s / it)
Averaged stats: Lr: 0.000000  Loss: 0.1206  Acc@1: 76.5625 (76.1667)  Acc@5: 95.3125 (95.3333)
Test: [Task 1]  [0/9]  eta: 0:00:14  Loss: 0.3578 (0.3578)  Acc@1: 92.1875 (92.1875)  Acc@5: 98.4375 (98.4375)  time: 1.6484  data: 0.9024  max mem: 6843
Test: [Task 1]  [8/9]  eta: 0:00:00  Loss: 0.1781 (0.2530)  Acc@1: 96.8750 (92.4272)  Acc@5: 100.0000 (99.4175)  time: 0.6651  data: 0.1005  max mem: 6843
Test: [Task 1] Total time: 0:00:06 (0.6739 s / it)
* Acc@1 92.427 Acc@5 99.417 loss 0.253
Batchwise eval time for task 1 = 0.6739470428890653
Test: [Task 2]  [0/9]  eta: 0:00:15  Loss: 0.2702 (0.2702)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 1.6727  data: 0.9966  max mem: 6843
Test: [Task 2]  [8/9]  eta: 0:00:00  Loss: 0.9243 (0.7815)  Acc@1: 71.8750 (73.5652)  Acc@5: 100.0000 (98.9565)  time: 0.7144  data: 0.1109  max mem: 6843
Test: [Task 2] Total time: 0:00:06 (0.7252 s / it)
* Acc@1 73.565 Acc@5 98.957 loss 0.782
Batchwise eval time for task 2 = 0.7252140839894613
Test: [Task 3]  [ 0/10]  eta: 0:00:17  Loss: 0.2604 (0.2604)  Acc@1: 95.3125 (95.3125)  Acc@5: 98.4375 (98.4375)  time: 1.7140  data: 1.0280  max mem: 6843
Test: [Task 3]  [ 9/10]  eta: 0:00:00  Loss: 0.2897 (0.4637)  Acc@1: 93.7500 (91.2752)  Acc@5: 98.4375 (98.9933)  time: 0.6746  data: 0.1030  max mem: 6843
Test: [Task 3] Total time: 0:00:06 (0.6826 s / it)
* Acc@1 91.275 Acc@5 98.993 loss 0.464
Batchwise eval time for task 3 = 0.6826461791992188
Test: [Task 4]  [ 0/10]  eta: 0:00:16  Loss: 1.0348 (1.0348)  Acc@1: 59.3750 (59.3750)  Acc@5: 95.3125 (95.3125)  time: 1.6862  data: 0.9534  max mem: 6843
Test: [Task 4]  [ 9/10]  eta: 0:00:00  Loss: 0.5932 (0.6152)  Acc@1: 85.9375 (80.5461)  Acc@5: 98.4375 (98.8055)  time: 0.6986  data: 0.0957  max mem: 6843
Test: [Task 4] Total time: 0:00:07 (0.7065 s / it)
* Acc@1 80.546 Acc@5 98.805 loss 0.615
Batchwise eval time for task 4 = 0.7065479755401611
[Average accuracy till task4]	Acc@1: 84.2870	Acc@5: 99.0432	Loss: 0.5284	Forgetting: 4.5280	Backward: -4.5280
Eval time for task 4 = 26.622748851776123
Using adam optimizer
Reinitialising optimizer
Similarity:  tensor(0.9165)  Task:  4
Old Num K:  8 New Num K:  9
Task number:  4
Train: Epoch[ 1/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000250  Loss: 3.3596  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  time: 3.1410  data: 0.8770  max mem: 6885
Train: Epoch[ 1/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000250  Loss: 3.7673  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.6667)  time: 2.0291  data: 0.0878  max mem: 6895
Train: Epoch[ 1/60] Total time: 0:00:20 (2.0386 s / it)
Averaged stats: Lr: 0.000250  Loss: 3.7673  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.6667)
Train: Epoch[ 2/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000250  Loss: 3.8130  Acc@1: 0.0000 (0.0000)  Acc@5: 1.5625 (1.5625)  time: 3.2133  data: 0.8200  max mem: 6895
Train: Epoch[ 2/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000250  Loss: 2.1904  Acc@1: 0.0000 (0.0000)  Acc@5: 12.5000 (11.0000)  time: 2.0409  data: 0.0821  max mem: 6895
Train: Epoch[ 2/60] Total time: 0:00:20 (2.0489 s / it)
Averaged stats: Lr: 0.000250  Loss: 2.1904  Acc@1: 0.0000 (0.0000)  Acc@5: 12.5000 (11.0000)
Train: Epoch[ 3/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000249  Loss: 2.2544  Acc@1: 0.0000 (0.0000)  Acc@5: 29.6875 (29.6875)  time: 3.3104  data: 0.9823  max mem: 6895
Train: Epoch[ 3/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000249  Loss: 1.8688  Acc@1: 1.5625 (3.0000)  Acc@5: 41.6667 (44.5000)  time: 2.0576  data: 0.0984  max mem: 6895
Train: Epoch[ 3/60] Total time: 0:00:20 (2.0676 s / it)
Averaged stats: Lr: 0.000249  Loss: 1.8688  Acc@1: 1.5625 (3.0000)  Acc@5: 41.6667 (44.5000)
Train: Epoch[ 4/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000248  Loss: 1.6444  Acc@1: 7.8125 (7.8125)  Acc@5: 56.2500 (56.2500)  time: 3.1132  data: 0.7957  max mem: 6895
Train: Epoch[ 4/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000248  Loss: 1.3554  Acc@1: 12.5000 (14.8333)  Acc@5: 75.0000 (72.5000)  time: 2.0337  data: 0.0797  max mem: 6895
Train: Epoch[ 4/60] Total time: 0:00:20 (2.0417 s / it)
Averaged stats: Lr: 0.000248  Loss: 1.3554  Acc@1: 12.5000 (14.8333)  Acc@5: 75.0000 (72.5000)
Train: Epoch[ 5/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000247  Loss: 1.2478  Acc@1: 25.0000 (25.0000)  Acc@5: 79.6875 (79.6875)  time: 3.0741  data: 0.7343  max mem: 6895
Train: Epoch[ 5/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000247  Loss: 0.9242  Acc@1: 31.2500 (30.3333)  Acc@5: 81.2500 (83.0000)  time: 2.0197  data: 0.0736  max mem: 6895
Train: Epoch[ 5/60] Total time: 0:00:20 (2.0292 s / it)
Averaged stats: Lr: 0.000247  Loss: 0.9242  Acc@1: 31.2500 (30.3333)  Acc@5: 81.2500 (83.0000)
Train: Epoch[ 6/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000246  Loss: 0.9316  Acc@1: 45.3125 (45.3125)  Acc@5: 89.0625 (89.0625)  time: 3.1857  data: 0.8473  max mem: 6895
Train: Epoch[ 6/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000246  Loss: 0.6063  Acc@1: 43.7500 (43.5000)  Acc@5: 87.5000 (88.6667)  time: 2.0346  data: 0.0849  max mem: 6895
Train: Epoch[ 6/60] Total time: 0:00:20 (2.0431 s / it)
Averaged stats: Lr: 0.000246  Loss: 0.6063  Acc@1: 43.7500 (43.5000)  Acc@5: 87.5000 (88.6667)
Train: Epoch[ 7/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000244  Loss: 0.7236  Acc@1: 42.1875 (42.1875)  Acc@5: 95.3125 (95.3125)  time: 3.2334  data: 0.8344  max mem: 6895
Train: Epoch[ 7/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000244  Loss: 0.9084  Acc@1: 56.2500 (54.3333)  Acc@5: 89.0625 (89.8333)  time: 2.0589  data: 0.0836  max mem: 6895
Train: Epoch[ 7/60] Total time: 0:00:20 (2.0693 s / it)
Averaged stats: Lr: 0.000244  Loss: 0.9084  Acc@1: 56.2500 (54.3333)  Acc@5: 89.0625 (89.8333)
Train: Epoch[ 8/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000242  Loss: 0.7592  Acc@1: 59.3750 (59.3750)  Acc@5: 89.0625 (89.0625)  time: 3.1689  data: 0.8380  max mem: 6895
Train: Epoch[ 8/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000242  Loss: 0.6160  Acc@1: 57.8125 (59.5000)  Acc@5: 89.0625 (91.8333)  time: 2.0359  data: 0.0839  max mem: 6895
Train: Epoch[ 8/60] Total time: 0:00:20 (2.0448 s / it)
Averaged stats: Lr: 0.000242  Loss: 0.6160  Acc@1: 57.8125 (59.5000)  Acc@5: 89.0625 (91.8333)
Train: Epoch[ 9/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000239  Loss: 0.7369  Acc@1: 57.8125 (57.8125)  Acc@5: 90.6250 (90.6250)  time: 3.1473  data: 0.7769  max mem: 6895
Train: Epoch[ 9/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000239  Loss: 0.5974  Acc@1: 57.8125 (62.8333)  Acc@5: 90.6250 (90.3333)  time: 2.0323  data: 0.0778  max mem: 6895
Train: Epoch[ 9/60] Total time: 0:00:20 (2.0414 s / it)
Averaged stats: Lr: 0.000239  Loss: 0.5974  Acc@1: 57.8125 (62.8333)  Acc@5: 90.6250 (90.3333)
Train: Epoch[10/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000236  Loss: 0.6636  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)  time: 3.1839  data: 0.8435  max mem: 6895
Train: Epoch[10/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000236  Loss: 0.5450  Acc@1: 67.1875 (68.5000)  Acc@5: 92.1875 (91.6667)  time: 2.0363  data: 0.0845  max mem: 6895
Train: Epoch[10/60] Total time: 0:00:20 (2.0442 s / it)
Averaged stats: Lr: 0.000236  Loss: 0.5450  Acc@1: 67.1875 (68.5000)  Acc@5: 92.1875 (91.6667)
Train: Epoch[11/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000233  Loss: 0.5238  Acc@1: 76.5625 (76.5625)  Acc@5: 95.3125 (95.3125)  time: 3.1179  data: 0.7882  max mem: 6895
Train: Epoch[11/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000233  Loss: 0.5169  Acc@1: 70.3125 (72.3333)  Acc@5: 92.1875 (92.8333)  time: 2.0208  data: 0.0790  max mem: 6895
Train: Epoch[11/60] Total time: 0:00:20 (2.0300 s / it)
Averaged stats: Lr: 0.000233  Loss: 0.5169  Acc@1: 70.3125 (72.3333)  Acc@5: 92.1875 (92.8333)
Train: Epoch[12/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000230  Loss: 0.5886  Acc@1: 76.5625 (76.5625)  Acc@5: 92.1875 (92.1875)  time: 3.1659  data: 0.8638  max mem: 6895
Train: Epoch[12/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000230  Loss: 0.5551  Acc@1: 73.4375 (75.0000)  Acc@5: 93.7500 (94.0000)  time: 2.0516  data: 0.0865  max mem: 6895
Train: Epoch[12/60] Total time: 0:00:20 (2.0602 s / it)
Averaged stats: Lr: 0.000230  Loss: 0.5551  Acc@1: 73.4375 (75.0000)  Acc@5: 93.7500 (94.0000)
Train: Epoch[13/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000226  Loss: 0.6255  Acc@1: 73.4375 (73.4375)  Acc@5: 87.5000 (87.5000)  time: 3.0446  data: 0.7183  max mem: 6895
Train: Epoch[13/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000226  Loss: 0.4704  Acc@1: 75.0000 (75.5000)  Acc@5: 92.1875 (92.0000)  time: 2.0172  data: 0.0720  max mem: 6895
Train: Epoch[13/60] Total time: 0:00:20 (2.0278 s / it)
Averaged stats: Lr: 0.000226  Loss: 0.4704  Acc@1: 75.0000 (75.5000)  Acc@5: 92.1875 (92.0000)
Train: Epoch[14/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000222  Loss: 0.5227  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)  time: 3.0832  data: 0.8273  max mem: 6895
Train: Epoch[14/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000222  Loss: 0.6957  Acc@1: 75.0000 (76.8333)  Acc@5: 91.6667 (92.8333)  time: 2.0260  data: 0.0829  max mem: 6895
Train: Epoch[14/60] Total time: 0:00:20 (2.0342 s / it)
Averaged stats: Lr: 0.000222  Loss: 0.6957  Acc@1: 75.0000 (76.8333)  Acc@5: 91.6667 (92.8333)
Train: Epoch[15/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000218  Loss: 0.4718  Acc@1: 82.8125 (82.8125)  Acc@5: 95.3125 (95.3125)  time: 3.1900  data: 0.8318  max mem: 6895
Train: Epoch[15/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000218  Loss: 0.3917  Acc@1: 78.1250 (79.0000)  Acc@5: 93.7500 (93.1667)  time: 2.0295  data: 0.0833  max mem: 6895
Train: Epoch[15/60] Total time: 0:00:20 (2.0383 s / it)
Averaged stats: Lr: 0.000218  Loss: 0.3917  Acc@1: 78.1250 (79.0000)  Acc@5: 93.7500 (93.1667)
Train: Epoch[16/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000213  Loss: 0.5432  Acc@1: 82.8125 (82.8125)  Acc@5: 90.6250 (90.6250)  time: 3.0632  data: 0.6936  max mem: 6895
Train: Epoch[16/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000213  Loss: 0.4935  Acc@1: 82.8125 (81.6667)  Acc@5: 93.7500 (94.1667)  time: 2.0385  data: 0.0695  max mem: 6895
Train: Epoch[16/60] Total time: 0:00:20 (2.0468 s / it)
Averaged stats: Lr: 0.000213  Loss: 0.4935  Acc@1: 82.8125 (81.6667)  Acc@5: 93.7500 (94.1667)
Train: Epoch[17/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000209  Loss: 0.5644  Acc@1: 82.8125 (82.8125)  Acc@5: 89.0625 (89.0625)  time: 3.0407  data: 0.6988  max mem: 6895
Train: Epoch[17/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000209  Loss: 0.4356  Acc@1: 81.2500 (81.3333)  Acc@5: 93.7500 (94.3333)  time: 2.0191  data: 0.0700  max mem: 6895
Train: Epoch[17/60] Total time: 0:00:20 (2.0285 s / it)
Averaged stats: Lr: 0.000209  Loss: 0.4356  Acc@1: 81.2500 (81.3333)  Acc@5: 93.7500 (94.3333)
Train: Epoch[18/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000204  Loss: 0.5567  Acc@1: 84.3750 (84.3750)  Acc@5: 93.7500 (93.7500)  time: 3.0417  data: 0.7085  max mem: 6895
Train: Epoch[18/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000204  Loss: 0.3052  Acc@1: 81.2500 (81.1667)  Acc@5: 96.8750 (96.0000)  time: 2.0175  data: 0.0710  max mem: 6895
Train: Epoch[18/60] Total time: 0:00:20 (2.0255 s / it)
Averaged stats: Lr: 0.000204  Loss: 0.3052  Acc@1: 81.2500 (81.1667)  Acc@5: 96.8750 (96.0000)
Train: Epoch[19/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000198  Loss: 0.3978  Acc@1: 82.8125 (82.8125)  Acc@5: 96.8750 (96.8750)  time: 3.1060  data: 0.7678  max mem: 6895
Train: Epoch[19/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000198  Loss: 0.3858  Acc@1: 83.3333 (83.5000)  Acc@5: 95.3125 (95.0000)  time: 2.0221  data: 0.0769  max mem: 6895
Train: Epoch[19/60] Total time: 0:00:20 (2.0312 s / it)
Averaged stats: Lr: 0.000198  Loss: 0.3858  Acc@1: 83.3333 (83.5000)  Acc@5: 95.3125 (95.0000)
Train: Epoch[20/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000193  Loss: 0.4466  Acc@1: 79.6875 (79.6875)  Acc@5: 93.7500 (93.7500)  time: 3.0828  data: 0.8788  max mem: 6895
Train: Epoch[20/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000193  Loss: 0.4287  Acc@1: 87.5000 (85.6667)  Acc@5: 95.3125 (96.0000)  time: 2.0201  data: 0.0880  max mem: 6895
Train: Epoch[20/60] Total time: 0:00:20 (2.0279 s / it)
Averaged stats: Lr: 0.000193  Loss: 0.4287  Acc@1: 87.5000 (85.6667)  Acc@5: 95.3125 (96.0000)
Train: Epoch[21/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000188  Loss: 0.4350  Acc@1: 81.2500 (81.2500)  Acc@5: 92.1875 (92.1875)  time: 3.0972  data: 0.7249  max mem: 6895
Train: Epoch[21/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000188  Loss: 0.4117  Acc@1: 81.2500 (80.8333)  Acc@5: 92.1875 (92.8333)  time: 2.0187  data: 0.0726  max mem: 6895
Train: Epoch[21/60] Total time: 0:00:20 (2.0277 s / it)
Averaged stats: Lr: 0.000188  Loss: 0.4117  Acc@1: 81.2500 (80.8333)  Acc@5: 92.1875 (92.8333)
Train: Epoch[22/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000182  Loss: 0.3076  Acc@1: 85.9375 (85.9375)  Acc@5: 100.0000 (100.0000)  time: 3.0525  data: 0.8186  max mem: 6895
Train: Epoch[22/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000182  Loss: 0.6584  Acc@1: 82.8125 (83.3333)  Acc@5: 93.7500 (95.3333)  time: 2.0182  data: 0.0820  max mem: 6895
Train: Epoch[22/60] Total time: 0:00:20 (2.0264 s / it)
Averaged stats: Lr: 0.000182  Loss: 0.6584  Acc@1: 82.8125 (83.3333)  Acc@5: 93.7500 (95.3333)
Train: Epoch[23/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000176  Loss: 0.3263  Acc@1: 92.1875 (92.1875)  Acc@5: 98.4375 (98.4375)  time: 3.0650  data: 0.7272  max mem: 6895
Train: Epoch[23/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000176  Loss: 0.2067  Acc@1: 85.9375 (84.6667)  Acc@5: 95.3125 (94.8333)  time: 2.0339  data: 0.0729  max mem: 6895
Train: Epoch[23/60] Total time: 0:00:20 (2.0429 s / it)
Averaged stats: Lr: 0.000176  Loss: 0.2067  Acc@1: 85.9375 (84.6667)  Acc@5: 95.3125 (94.8333)
Train: Epoch[24/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000170  Loss: 0.2914  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)  time: 3.0813  data: 0.7656  max mem: 6895
Train: Epoch[24/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000170  Loss: 0.3772  Acc@1: 85.9375 (86.6667)  Acc@5: 95.3125 (96.8333)  time: 2.0159  data: 0.0767  max mem: 6895
Train: Epoch[24/60] Total time: 0:00:20 (2.0238 s / it)
Averaged stats: Lr: 0.000170  Loss: 0.3772  Acc@1: 85.9375 (86.6667)  Acc@5: 95.3125 (96.8333)
Train: Epoch[25/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000164  Loss: 0.4025  Acc@1: 82.8125 (82.8125)  Acc@5: 90.6250 (90.6250)  time: 3.0967  data: 0.8152  max mem: 6895
Train: Epoch[25/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000164  Loss: 0.4201  Acc@1: 84.3750 (85.0000)  Acc@5: 95.3125 (95.5000)  time: 2.0210  data: 0.0817  max mem: 6895
Train: Epoch[25/60] Total time: 0:00:20 (2.0305 s / it)
Averaged stats: Lr: 0.000164  Loss: 0.4201  Acc@1: 84.3750 (85.0000)  Acc@5: 95.3125 (95.5000)
Train: Epoch[26/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000157  Loss: 0.5174  Acc@1: 82.8125 (82.8125)  Acc@5: 90.6250 (90.6250)  time: 3.0896  data: 0.8115  max mem: 6895
Train: Epoch[26/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000157  Loss: 0.3089  Acc@1: 82.8125 (86.3333)  Acc@5: 95.8333 (95.5000)  time: 2.0204  data: 0.0813  max mem: 6895
Train: Epoch[26/60] Total time: 0:00:20 (2.0282 s / it)
Averaged stats: Lr: 0.000157  Loss: 0.3089  Acc@1: 82.8125 (86.3333)  Acc@5: 95.8333 (95.5000)
Train: Epoch[27/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000151  Loss: 0.3715  Acc@1: 84.3750 (84.3750)  Acc@5: 96.8750 (96.8750)  time: 3.0977  data: 0.8692  max mem: 6895
Train: Epoch[27/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000151  Loss: 0.2090  Acc@1: 87.5000 (86.8333)  Acc@5: 95.8333 (96.3333)  time: 2.0185  data: 0.0870  max mem: 6895
Train: Epoch[27/60] Total time: 0:00:20 (2.0286 s / it)
Averaged stats: Lr: 0.000151  Loss: 0.2090  Acc@1: 87.5000 (86.8333)  Acc@5: 95.8333 (96.3333)
Train: Epoch[28/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000145  Loss: 0.3420  Acc@1: 90.6250 (90.6250)  Acc@5: 95.3125 (95.3125)  time: 3.0903  data: 0.7684  max mem: 6895
Train: Epoch[28/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000145  Loss: 0.6754  Acc@1: 87.5000 (86.6667)  Acc@5: 95.3125 (94.3333)  time: 2.0458  data: 0.0770  max mem: 6895
Train: Epoch[28/60] Total time: 0:00:20 (2.0544 s / it)
Averaged stats: Lr: 0.000145  Loss: 0.6754  Acc@1: 87.5000 (86.6667)  Acc@5: 95.3125 (94.3333)
Train: Epoch[29/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000138  Loss: 0.2601  Acc@1: 89.0625 (89.0625)  Acc@5: 98.4375 (98.4375)  time: 3.0709  data: 0.7960  max mem: 6895
Train: Epoch[29/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000138  Loss: 0.1934  Acc@1: 89.0625 (89.1667)  Acc@5: 98.4375 (97.0000)  time: 2.0150  data: 0.0797  max mem: 6895
Train: Epoch[29/60] Total time: 0:00:20 (2.0238 s / it)
Averaged stats: Lr: 0.000138  Loss: 0.1934  Acc@1: 89.0625 (89.1667)  Acc@5: 98.4375 (97.0000)
Train: Epoch[30/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000132  Loss: 0.4730  Acc@1: 85.9375 (85.9375)  Acc@5: 90.6250 (90.6250)  time: 3.0728  data: 0.7905  max mem: 6895
Train: Epoch[30/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000132  Loss: 0.2682  Acc@1: 89.0625 (89.3333)  Acc@5: 98.4375 (96.5000)  time: 2.0205  data: 0.0792  max mem: 6895
Train: Epoch[30/60] Total time: 0:00:20 (2.0284 s / it)
Averaged stats: Lr: 0.000132  Loss: 0.2682  Acc@1: 89.0625 (89.3333)  Acc@5: 98.4375 (96.5000)
Train: Epoch[31/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000125  Loss: 0.2182  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)  time: 3.0637  data: 0.7130  max mem: 6895
Train: Epoch[31/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000125  Loss: 0.2633  Acc@1: 89.0625 (89.3333)  Acc@5: 95.3125 (95.8333)  time: 2.0167  data: 0.0714  max mem: 6895
Train: Epoch[31/60] Total time: 0:00:20 (2.0272 s / it)
Averaged stats: Lr: 0.000125  Loss: 0.2633  Acc@1: 89.0625 (89.3333)  Acc@5: 95.3125 (95.8333)
Train: Epoch[32/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000118  Loss: 0.2116  Acc@1: 96.8750 (96.8750)  Acc@5: 98.4375 (98.4375)  time: 3.0725  data: 0.7248  max mem: 6895
Train: Epoch[32/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000118  Loss: 0.2849  Acc@1: 85.9375 (87.3333)  Acc@5: 98.4375 (96.8333)  time: 2.0269  data: 0.0726  max mem: 6895
Train: Epoch[32/60] Total time: 0:00:20 (2.0348 s / it)
Averaged stats: Lr: 0.000118  Loss: 0.2849  Acc@1: 85.9375 (87.3333)  Acc@5: 98.4375 (96.8333)
Train: Epoch[33/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000112  Loss: 0.3775  Acc@1: 84.3750 (84.3750)  Acc@5: 92.1875 (92.1875)  time: 3.1507  data: 0.8931  max mem: 6895
Train: Epoch[33/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000112  Loss: 0.2569  Acc@1: 89.0625 (89.3333)  Acc@5: 96.8750 (97.1667)  time: 2.0332  data: 0.0894  max mem: 6895
Train: Epoch[33/60] Total time: 0:00:20 (2.0446 s / it)
Averaged stats: Lr: 0.000112  Loss: 0.2569  Acc@1: 89.0625 (89.3333)  Acc@5: 96.8750 (97.1667)
Train: Epoch[34/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000105  Loss: 0.3126  Acc@1: 90.6250 (90.6250)  Acc@5: 95.3125 (95.3125)  time: 3.1017  data: 0.7841  max mem: 6895
Train: Epoch[34/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000105  Loss: 0.4009  Acc@1: 87.5000 (88.1667)  Acc@5: 96.8750 (96.1667)  time: 2.0516  data: 0.0786  max mem: 6895
Train: Epoch[34/60] Total time: 0:00:20 (2.0600 s / it)
Averaged stats: Lr: 0.000105  Loss: 0.4009  Acc@1: 87.5000 (88.1667)  Acc@5: 96.8750 (96.1667)
Train: Epoch[35/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000099  Loss: 0.2516  Acc@1: 90.6250 (90.6250)  Acc@5: 98.4375 (98.4375)  time: 3.1174  data: 0.8518  max mem: 6895
Train: Epoch[35/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000099  Loss: 0.2497  Acc@1: 90.6250 (89.5000)  Acc@5: 96.8750 (96.8333)  time: 2.0223  data: 0.0853  max mem: 6895
Train: Epoch[35/60] Total time: 0:00:20 (2.0314 s / it)
Averaged stats: Lr: 0.000099  Loss: 0.2497  Acc@1: 90.6250 (89.5000)  Acc@5: 96.8750 (96.8333)
Train: Epoch[36/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000093  Loss: 0.3349  Acc@1: 89.0625 (89.0625)  Acc@5: 93.7500 (93.7500)  time: 3.2287  data: 0.8587  max mem: 6895
Train: Epoch[36/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000093  Loss: 0.4945  Acc@1: 85.9375 (87.1667)  Acc@5: 95.3125 (95.6667)  time: 2.0419  data: 0.0860  max mem: 6895
Train: Epoch[36/60] Total time: 0:00:20 (2.0498 s / it)
Averaged stats: Lr: 0.000093  Loss: 0.4945  Acc@1: 85.9375 (87.1667)  Acc@5: 95.3125 (95.6667)
Train: Epoch[37/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000086  Loss: 0.3631  Acc@1: 85.9375 (85.9375)  Acc@5: 90.6250 (90.6250)  time: 3.1022  data: 0.7665  max mem: 6895
Train: Epoch[37/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000086  Loss: 0.2730  Acc@1: 85.9375 (87.3333)  Acc@5: 95.3125 (95.5000)  time: 2.0221  data: 0.0768  max mem: 6895
Train: Epoch[37/60] Total time: 0:00:20 (2.0317 s / it)
Averaged stats: Lr: 0.000086  Loss: 0.2730  Acc@1: 85.9375 (87.3333)  Acc@5: 95.3125 (95.5000)
Train: Epoch[38/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000080  Loss: 0.3065  Acc@1: 90.6250 (90.6250)  Acc@5: 98.4375 (98.4375)  time: 3.0825  data: 0.7821  max mem: 6895
Train: Epoch[38/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000080  Loss: 0.2889  Acc@1: 84.3750 (86.0000)  Acc@5: 95.3125 (95.1667)  time: 2.0148  data: 0.0783  max mem: 6895
Train: Epoch[38/60] Total time: 0:00:20 (2.0229 s / it)
Averaged stats: Lr: 0.000080  Loss: 0.2889  Acc@1: 84.3750 (86.0000)  Acc@5: 95.3125 (95.1667)
Train: Epoch[39/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000074  Loss: 0.2477  Acc@1: 85.9375 (85.9375)  Acc@5: 98.4375 (98.4375)  time: 3.0713  data: 0.7681  max mem: 6895
Train: Epoch[39/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000074  Loss: 0.3749  Acc@1: 87.5000 (88.0000)  Acc@5: 96.8750 (96.6667)  time: 2.0386  data: 0.0769  max mem: 6895
Train: Epoch[39/60] Total time: 0:00:20 (2.0494 s / it)
Averaged stats: Lr: 0.000074  Loss: 0.3749  Acc@1: 87.5000 (88.0000)  Acc@5: 96.8750 (96.6667)
Train: Epoch[40/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000068  Loss: 0.3771  Acc@1: 84.3750 (84.3750)  Acc@5: 93.7500 (93.7500)  time: 3.1100  data: 0.7067  max mem: 6895
Train: Epoch[40/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000068  Loss: 0.2124  Acc@1: 89.0625 (88.6667)  Acc@5: 96.8750 (97.1667)  time: 2.0210  data: 0.0708  max mem: 6895
Train: Epoch[40/60] Total time: 0:00:20 (2.0292 s / it)
Averaged stats: Lr: 0.000068  Loss: 0.2124  Acc@1: 89.0625 (88.6667)  Acc@5: 96.8750 (97.1667)
Train: Epoch[41/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000063  Loss: 0.2984  Acc@1: 85.9375 (85.9375)  Acc@5: 93.7500 (93.7500)  time: 3.0537  data: 0.8146  max mem: 6895
Train: Epoch[41/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000063  Loss: 0.3086  Acc@1: 85.9375 (87.0000)  Acc@5: 95.3125 (94.1667)  time: 2.0174  data: 0.0816  max mem: 6895
Train: Epoch[41/60] Total time: 0:00:20 (2.0265 s / it)
Averaged stats: Lr: 0.000063  Loss: 0.3086  Acc@1: 85.9375 (87.0000)  Acc@5: 95.3125 (94.1667)
Train: Epoch[42/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000057  Loss: 0.3440  Acc@1: 84.3750 (84.3750)  Acc@5: 93.7500 (93.7500)  time: 3.0323  data: 0.7012  max mem: 6895
Train: Epoch[42/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000057  Loss: 0.1077  Acc@1: 87.5000 (87.3333)  Acc@5: 95.3125 (95.6667)  time: 2.0159  data: 0.0703  max mem: 6895
Train: Epoch[42/60] Total time: 0:00:20 (2.0245 s / it)
Averaged stats: Lr: 0.000057  Loss: 0.1077  Acc@1: 87.5000 (87.3333)  Acc@5: 95.3125 (95.6667)
Train: Epoch[43/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000052  Loss: 0.3059  Acc@1: 79.6875 (79.6875)  Acc@5: 92.1875 (92.1875)  time: 3.1585  data: 0.7706  max mem: 6895
Train: Epoch[43/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000052  Loss: 0.2310  Acc@1: 87.5000 (88.5000)  Acc@5: 95.3125 (95.6667)  time: 2.0389  data: 0.0772  max mem: 6895
Train: Epoch[43/60] Total time: 0:00:20 (2.0500 s / it)
Averaged stats: Lr: 0.000052  Loss: 0.2310  Acc@1: 87.5000 (88.5000)  Acc@5: 95.3125 (95.6667)
Train: Epoch[44/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000046  Loss: 0.1840  Acc@1: 96.8750 (96.8750)  Acc@5: 98.4375 (98.4375)  time: 3.4263  data: 0.9647  max mem: 6895
Train: Epoch[44/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000046  Loss: 0.3023  Acc@1: 89.0625 (90.1667)  Acc@5: 96.8750 (96.3333)  time: 2.0983  data: 0.0966  max mem: 6895
Train: Epoch[44/60] Total time: 0:00:21 (2.1068 s / it)
Averaged stats: Lr: 0.000046  Loss: 0.3023  Acc@1: 89.0625 (90.1667)  Acc@5: 96.8750 (96.3333)
Train: Epoch[45/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000041  Loss: 0.1911  Acc@1: 93.7500 (93.7500)  Acc@5: 98.4375 (98.4375)  time: 3.3782  data: 1.0201  max mem: 6895
Train: Epoch[45/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000041  Loss: 0.1719  Acc@1: 89.0625 (89.8333)  Acc@5: 95.3125 (96.1667)  time: 2.0648  data: 0.1021  max mem: 6895
Train: Epoch[45/60] Total time: 0:00:20 (2.0742 s / it)
Averaged stats: Lr: 0.000041  Loss: 0.1719  Acc@1: 89.0625 (89.8333)  Acc@5: 95.3125 (96.1667)
Train: Epoch[46/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000037  Loss: 0.2607  Acc@1: 85.9375 (85.9375)  Acc@5: 95.3125 (95.3125)  time: 3.1676  data: 0.8259  max mem: 6895
Train: Epoch[46/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000037  Loss: 0.2272  Acc@1: 89.0625 (90.1667)  Acc@5: 95.8333 (96.8333)  time: 2.0325  data: 0.0827  max mem: 6895
Train: Epoch[46/60] Total time: 0:00:20 (2.0403 s / it)
Averaged stats: Lr: 0.000037  Loss: 0.2272  Acc@1: 89.0625 (90.1667)  Acc@5: 95.8333 (96.8333)
Train: Epoch[47/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000032  Loss: 0.2407  Acc@1: 87.5000 (87.5000)  Acc@5: 96.8750 (96.8750)  time: 3.0858  data: 0.7438  max mem: 6895
Train: Epoch[47/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000032  Loss: 0.5516  Acc@1: 89.0625 (89.6667)  Acc@5: 96.8750 (97.3333)  time: 2.0205  data: 0.0745  max mem: 6895
Train: Epoch[47/60] Total time: 0:00:20 (2.0305 s / it)
Averaged stats: Lr: 0.000032  Loss: 0.5516  Acc@1: 89.0625 (89.6667)  Acc@5: 96.8750 (97.3333)
Train: Epoch[48/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000028  Loss: 0.1765  Acc@1: 93.7500 (93.7500)  Acc@5: 98.4375 (98.4375)  time: 3.2648  data: 0.9182  max mem: 6895
Train: Epoch[48/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000028  Loss: 0.1152  Acc@1: 90.6250 (90.6667)  Acc@5: 96.8750 (97.1667)  time: 2.0424  data: 0.0920  max mem: 6895
Train: Epoch[48/60] Total time: 0:00:20 (2.0511 s / it)
Averaged stats: Lr: 0.000028  Loss: 0.1152  Acc@1: 90.6250 (90.6667)  Acc@5: 96.8750 (97.1667)
Train: Epoch[49/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000024  Loss: 0.2222  Acc@1: 82.8125 (82.8125)  Acc@5: 96.8750 (96.8750)  time: 3.2011  data: 0.9015  max mem: 6895
Train: Epoch[49/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000024  Loss: 0.3987  Acc@1: 87.5000 (88.1667)  Acc@5: 95.3125 (96.0000)  time: 2.0366  data: 0.0903  max mem: 6895
Train: Epoch[49/60] Total time: 0:00:20 (2.0461 s / it)
Averaged stats: Lr: 0.000024  Loss: 0.3987  Acc@1: 87.5000 (88.1667)  Acc@5: 95.3125 (96.0000)
Train: Epoch[50/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000020  Loss: 0.2321  Acc@1: 82.8125 (82.8125)  Acc@5: 96.8750 (96.8750)  time: 3.1553  data: 0.7545  max mem: 6895
Train: Epoch[50/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000020  Loss: 0.2263  Acc@1: 87.5000 (86.6667)  Acc@5: 96.8750 (96.3333)  time: 2.0512  data: 0.0756  max mem: 6895
Train: Epoch[50/60] Total time: 0:00:20 (2.0600 s / it)
Averaged stats: Lr: 0.000020  Loss: 0.2263  Acc@1: 87.5000 (86.6667)  Acc@5: 96.8750 (96.3333)
Train: Epoch[51/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000017  Loss: 0.1796  Acc@1: 93.7500 (93.7500)  Acc@5: 96.8750 (96.8750)  time: 3.1801  data: 0.7729  max mem: 6895
Train: Epoch[51/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000017  Loss: 0.0881  Acc@1: 92.1875 (91.6667)  Acc@5: 96.8750 (97.1667)  time: 2.0321  data: 0.0774  max mem: 6895
Train: Epoch[51/60] Total time: 0:00:20 (2.0429 s / it)
Averaged stats: Lr: 0.000017  Loss: 0.0881  Acc@1: 92.1875 (91.6667)  Acc@5: 96.8750 (97.1667)
Train: Epoch[52/60]  [ 0/10]  eta: 0:00:30  Lr: 0.000014  Loss: 0.1483  Acc@1: 87.5000 (87.5000)  Acc@5: 96.8750 (96.8750)  time: 3.0945  data: 0.8701  max mem: 6895
Train: Epoch[52/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000014  Loss: 0.2269  Acc@1: 90.6250 (89.1667)  Acc@5: 96.8750 (96.0000)  time: 2.0242  data: 0.0871  max mem: 6895
Train: Epoch[52/60] Total time: 0:00:20 (2.0323 s / it)
Averaged stats: Lr: 0.000014  Loss: 0.2269  Acc@1: 90.6250 (89.1667)  Acc@5: 96.8750 (96.0000)
Train: Epoch[53/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000011  Loss: 0.1198  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)  time: 3.1690  data: 0.8225  max mem: 6895
Train: Epoch[53/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000011  Loss: 0.3394  Acc@1: 89.0625 (89.6667)  Acc@5: 96.8750 (97.1667)  time: 2.0362  data: 0.0824  max mem: 6895
Train: Epoch[53/60] Total time: 0:00:20 (2.0464 s / it)
Averaged stats: Lr: 0.000011  Loss: 0.3394  Acc@1: 89.0625 (89.6667)  Acc@5: 96.8750 (97.1667)
Train: Epoch[54/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000008  Loss: 0.1357  Acc@1: 95.3125 (95.3125)  Acc@5: 98.4375 (98.4375)  time: 3.1815  data: 0.7672  max mem: 6895
Train: Epoch[54/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000008  Loss: 0.0473  Acc@1: 89.0625 (89.6667)  Acc@5: 96.8750 (96.5000)  time: 2.0479  data: 0.0769  max mem: 6895
Train: Epoch[54/60] Total time: 0:00:20 (2.0571 s / it)
Averaged stats: Lr: 0.000008  Loss: 0.0473  Acc@1: 89.0625 (89.6667)  Acc@5: 96.8750 (96.5000)
Train: Epoch[55/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000006  Loss: 0.2387  Acc@1: 87.5000 (87.5000)  Acc@5: 95.3125 (95.3125)  time: 3.4529  data: 1.0371  max mem: 6895
Train: Epoch[55/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000006  Loss: 0.0358  Acc@1: 89.0625 (89.6667)  Acc@5: 96.8750 (96.0000)  time: 2.0746  data: 0.1039  max mem: 6895
Train: Epoch[55/60] Total time: 0:00:20 (2.0850 s / it)
Averaged stats: Lr: 0.000006  Loss: 0.0358  Acc@1: 89.0625 (89.6667)  Acc@5: 96.8750 (96.0000)
Train: Epoch[56/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000004  Loss: 0.3060  Acc@1: 87.5000 (87.5000)  Acc@5: 95.3125 (95.3125)  time: 3.4193  data: 0.8571  max mem: 6895
Train: Epoch[56/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000004  Loss: 0.2312  Acc@1: 89.0625 (89.3333)  Acc@5: 96.8750 (97.0000)  time: 2.0598  data: 0.0858  max mem: 6895
Train: Epoch[56/60] Total time: 0:00:20 (2.0684 s / it)
Averaged stats: Lr: 0.000004  Loss: 0.2312  Acc@1: 89.0625 (89.3333)  Acc@5: 96.8750 (97.0000)
Train: Epoch[57/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000003  Loss: 0.1959  Acc@1: 89.0625 (89.0625)  Acc@5: 93.7500 (93.7500)  time: 3.2255  data: 0.8494  max mem: 6895
Train: Epoch[57/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000003  Loss: 0.0538  Acc@1: 92.1875 (90.8333)  Acc@5: 95.3125 (96.3333)  time: 2.0388  data: 0.0851  max mem: 6895
Train: Epoch[57/60] Total time: 0:00:20 (2.0484 s / it)
Averaged stats: Lr: 0.000003  Loss: 0.0538  Acc@1: 92.1875 (90.8333)  Acc@5: 95.3125 (96.3333)
Train: Epoch[58/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000002  Loss: 0.2329  Acc@1: 89.0625 (89.0625)  Acc@5: 96.8750 (96.8750)  time: 3.2899  data: 0.9522  max mem: 6895
Train: Epoch[58/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000002  Loss: 0.0900  Acc@1: 90.6250 (90.6667)  Acc@5: 96.8750 (97.3333)  time: 2.0431  data: 0.0953  max mem: 6895
Train: Epoch[58/60] Total time: 0:00:20 (2.0513 s / it)
Averaged stats: Lr: 0.000002  Loss: 0.0900  Acc@1: 90.6250 (90.6667)  Acc@5: 96.8750 (97.3333)
Train: Epoch[59/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000001  Loss: 0.2660  Acc@1: 89.0625 (89.0625)  Acc@5: 93.7500 (93.7500)  time: 3.2289  data: 0.8522  max mem: 6895
Train: Epoch[59/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000001  Loss: 0.2322  Acc@1: 87.5000 (88.6667)  Acc@5: 95.3125 (95.1667)  time: 2.0383  data: 0.0854  max mem: 6895
Train: Epoch[59/60] Total time: 0:00:20 (2.0505 s / it)
Averaged stats: Lr: 0.000001  Loss: 0.2322  Acc@1: 87.5000 (88.6667)  Acc@5: 95.3125 (95.1667)
Train: Epoch[60/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000000  Loss: 0.1689  Acc@1: 90.6250 (90.6250)  Acc@5: 96.8750 (96.8750)  time: 3.1720  data: 0.8031  max mem: 6895
Train: Epoch[60/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000000  Loss: 0.1996  Acc@1: 90.6250 (88.8333)  Acc@5: 95.8333 (96.5000)  time: 2.0554  data: 0.0804  max mem: 6895
Train: Epoch[60/60] Total time: 0:00:20 (2.0639 s / it)
Averaged stats: Lr: 0.000000  Loss: 0.1996  Acc@1: 90.6250 (88.8333)  Acc@5: 95.8333 (96.5000)
Test: [Task 1]  [0/9]  eta: 0:00:14  Loss: 0.3988 (0.3988)  Acc@1: 93.7500 (93.7500)  Acc@5: 98.4375 (98.4375)  time: 1.5992  data: 0.8579  max mem: 6895
Test: [Task 1]  [8/9]  eta: 0:00:00  Loss: 0.1958 (0.2702)  Acc@1: 96.8750 (92.6214)  Acc@5: 100.0000 (99.4175)  time: 0.6834  data: 0.0955  max mem: 6895
Test: [Task 1] Total time: 0:00:06 (0.6923 s / it)
* Acc@1 92.621 Acc@5 99.417 loss 0.270
Batchwise eval time for task 1 = 0.6922797891828749
Test: [Task 2]  [0/9]  eta: 0:00:14  Loss: 0.4152 (0.4152)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 1.6621  data: 0.9445  max mem: 6895
Test: [Task 2]  [8/9]  eta: 0:00:00  Loss: 0.9686 (0.8420)  Acc@1: 70.3125 (71.6522)  Acc@5: 100.0000 (98.9565)  time: 0.7345  data: 0.1051  max mem: 6895
Test: [Task 2] Total time: 0:00:06 (0.7459 s / it)
* Acc@1 71.652 Acc@5 98.957 loss 0.842
Batchwise eval time for task 2 = 0.745970196194119
Test: [Task 3]  [ 0/10]  eta: 0:00:16  Loss: 0.2845 (0.2845)  Acc@1: 95.3125 (95.3125)  Acc@5: 98.4375 (98.4375)  time: 1.6767  data: 0.8918  max mem: 6895
Test: [Task 3]  [ 9/10]  eta: 0:00:00  Loss: 0.3402 (0.5240)  Acc@1: 93.7500 (90.1007)  Acc@5: 98.4375 (98.9933)  time: 0.6954  data: 0.0894  max mem: 6895
Test: [Task 3] Total time: 0:00:07 (0.7038 s / it)
* Acc@1 90.101 Acc@5 98.993 loss 0.524
Batchwise eval time for task 3 = 0.7038059234619141
Test: [Task 4]  [ 0/10]  eta: 0:00:16  Loss: 1.2049 (1.2049)  Acc@1: 56.2500 (56.2500)  Acc@5: 95.3125 (95.3125)  time: 1.6842  data: 0.8999  max mem: 6895
Test: [Task 4]  [ 9/10]  eta: 0:00:00  Loss: 0.6010 (0.7098)  Acc@1: 85.9375 (79.6928)  Acc@5: 100.0000 (98.8055)  time: 0.6861  data: 0.0902  max mem: 6895
Test: [Task 4] Total time: 0:00:06 (0.6942 s / it)
* Acc@1 79.693 Acc@5 98.805 loss 0.710
Batchwise eval time for task 4 = 0.6942063570022583
Test: [Task 5]  [ 0/10]  eta: 0:00:17  Loss: 0.4683 (0.4683)  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)  time: 1.7228  data: 0.8766  max mem: 6895
Test: [Task 5]  [ 9/10]  eta: 0:00:00  Loss: 0.3042 (0.3363)  Acc@1: 96.8750 (94.7635)  Acc@5: 98.4375 (98.4797)  time: 0.7294  data: 0.0879  max mem: 6895
Test: [Task 5] Total time: 0:00:07 (0.7376 s / it)
* Acc@1 94.764 Acc@5 98.480 loss 0.336
Batchwise eval time for task 5 = 0.7376057624816894
[Average accuracy till task5]	Acc@1: 85.6844	Acc@5: 98.9305	Loss: 0.5365	Forgetting: 4.3326	Backward: -4.3326
Eval time for task 5 = 34.47228813171387
Using adam optimizer
Reinitialising optimizer
Similarity:  tensor(0.9111)  Task:  5
Old Num K:  9 New Num K:  10
Task number:  5
Train: Epoch[ 1/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000250  Loss: 3.0338  Acc@1: 0.0000 (0.0000)  Acc@5: 1.5625 (1.5625)  time: 3.3016  data: 0.7180  max mem: 6937
Train: Epoch[ 1/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000250  Loss: 3.2372  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (1.3356)  time: 2.2059  data: 0.0719  max mem: 6948
Train: Epoch[ 1/60] Total time: 0:00:22 (2.2158 s / it)
Averaged stats: Lr: 0.000250  Loss: 3.2372  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (1.3356)
Train: Epoch[ 2/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000250  Loss: 3.1183  Acc@1: 0.0000 (0.0000)  Acc@5: 6.2500 (6.2500)  time: 3.4070  data: 0.7722  max mem: 6948
Train: Epoch[ 2/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000250  Loss: 2.1750  Acc@1: 0.0000 (0.1669)  Acc@5: 12.5000 (12.3539)  time: 2.1837  data: 0.0774  max mem: 6949
Train: Epoch[ 2/60] Total time: 0:00:21 (2.1932 s / it)
Averaged stats: Lr: 0.000250  Loss: 2.1750  Acc@1: 0.0000 (0.1669)  Acc@5: 12.5000 (12.3539)
Train: Epoch[ 3/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000249  Loss: 2.3241  Acc@1: 0.0000 (0.0000)  Acc@5: 31.2500 (31.2500)  time: 3.3472  data: 0.8201  max mem: 6949
Train: Epoch[ 3/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000249  Loss: 1.7666  Acc@1: 1.5625 (3.3389)  Acc@5: 31.2500 (35.0584)  time: 2.1669  data: 0.0822  max mem: 6949
Train: Epoch[ 3/60] Total time: 0:00:21 (2.1770 s / it)
Averaged stats: Lr: 0.000249  Loss: 1.7666  Acc@1: 1.5625 (3.3389)  Acc@5: 31.2500 (35.0584)
Train: Epoch[ 4/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000248  Loss: 1.7253  Acc@1: 7.8125 (7.8125)  Acc@5: 51.5625 (51.5625)  time: 3.4131  data: 0.8151  max mem: 6949
Train: Epoch[ 4/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000248  Loss: 1.3086  Acc@1: 7.8125 (8.0134)  Acc@5: 57.8125 (58.2638)  time: 2.1701  data: 0.0817  max mem: 6949
Train: Epoch[ 4/60] Total time: 0:00:21 (2.1786 s / it)
Averaged stats: Lr: 0.000248  Loss: 1.3086  Acc@1: 7.8125 (8.0134)  Acc@5: 57.8125 (58.2638)
Train: Epoch[ 5/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000247  Loss: 1.3331  Acc@1: 20.3125 (20.3125)  Acc@5: 64.0625 (64.0625)  time: 3.2882  data: 0.8205  max mem: 6949
Train: Epoch[ 5/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000247  Loss: 1.5620  Acc@1: 15.6250 (16.0267)  Acc@5: 68.7500 (70.2838)  time: 2.1668  data: 0.0822  max mem: 6949
Train: Epoch[ 5/60] Total time: 0:00:21 (2.1760 s / it)
Averaged stats: Lr: 0.000247  Loss: 1.5620  Acc@1: 15.6250 (16.0267)  Acc@5: 68.7500 (70.2838)
Train: Epoch[ 6/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000246  Loss: 1.3062  Acc@1: 28.1250 (28.1250)  Acc@5: 70.3125 (70.3125)  time: 3.3076  data: 0.8002  max mem: 6949
Train: Epoch[ 6/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000246  Loss: 1.0915  Acc@1: 26.5625 (26.5442)  Acc@5: 78.1250 (78.2972)  time: 2.1594  data: 0.0802  max mem: 6949
Train: Epoch[ 6/60] Total time: 0:00:21 (2.1677 s / it)
Averaged stats: Lr: 0.000246  Loss: 1.0915  Acc@1: 26.5625 (26.5442)  Acc@5: 78.1250 (78.2972)
Train: Epoch[ 7/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000244  Loss: 0.9797  Acc@1: 34.3750 (34.3750)  Acc@5: 82.8125 (82.8125)  time: 3.2573  data: 0.7524  max mem: 6949
Train: Epoch[ 7/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000244  Loss: 1.1208  Acc@1: 32.8125 (33.7229)  Acc@5: 82.8125 (83.4725)  time: 2.1467  data: 0.0754  max mem: 6949
Train: Epoch[ 7/60] Total time: 0:00:21 (2.1555 s / it)
Averaged stats: Lr: 0.000244  Loss: 1.1208  Acc@1: 32.8125 (33.7229)  Acc@5: 82.8125 (83.4725)
Train: Epoch[ 8/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000242  Loss: 0.9465  Acc@1: 35.9375 (35.9375)  Acc@5: 87.5000 (87.5000)  time: 3.3655  data: 0.8111  max mem: 6949
Train: Epoch[ 8/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000242  Loss: 1.3410  Acc@1: 35.9375 (38.7312)  Acc@5: 85.9375 (84.6411)  time: 2.1562  data: 0.0812  max mem: 6949
Train: Epoch[ 8/60] Total time: 0:00:21 (2.1642 s / it)
Averaged stats: Lr: 0.000242  Loss: 1.3410  Acc@1: 35.9375 (38.7312)  Acc@5: 85.9375 (84.6411)
Train: Epoch[ 9/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000239  Loss: 0.7057  Acc@1: 51.5625 (51.5625)  Acc@5: 92.1875 (92.1875)  time: 3.2847  data: 0.7696  max mem: 6949
Train: Epoch[ 9/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000239  Loss: 0.6003  Acc@1: 45.3125 (46.0768)  Acc@5: 84.3750 (85.8097)  time: 2.1565  data: 0.0771  max mem: 6949
Train: Epoch[ 9/60] Total time: 0:00:21 (2.1655 s / it)
Averaged stats: Lr: 0.000239  Loss: 0.6003  Acc@1: 45.3125 (46.0768)  Acc@5: 84.3750 (85.8097)
Train: Epoch[10/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000236  Loss: 0.8450  Acc@1: 54.6875 (54.6875)  Acc@5: 92.1875 (92.1875)  time: 3.3008  data: 0.8089  max mem: 6949
Train: Epoch[10/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000236  Loss: 0.7625  Acc@1: 51.5625 (51.2521)  Acc@5: 86.9565 (87.4791)  time: 2.1712  data: 0.0810  max mem: 6949
Train: Epoch[10/60] Total time: 0:00:21 (2.1794 s / it)
Averaged stats: Lr: 0.000236  Loss: 0.7625  Acc@1: 51.5625 (51.2521)  Acc@5: 86.9565 (87.4791)
Train: Epoch[11/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000233  Loss: 0.8577  Acc@1: 57.8125 (57.8125)  Acc@5: 85.9375 (85.9375)  time: 3.3328  data: 0.7745  max mem: 6949
Train: Epoch[11/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000233  Loss: 0.7212  Acc@1: 54.6875 (57.0952)  Acc@5: 89.0625 (89.6494)  time: 2.1657  data: 0.0776  max mem: 6949
Train: Epoch[11/60] Total time: 0:00:21 (2.1765 s / it)
Averaged stats: Lr: 0.000233  Loss: 0.7212  Acc@1: 54.6875 (57.0952)  Acc@5: 89.0625 (89.6494)
Train: Epoch[12/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000230  Loss: 0.6440  Acc@1: 53.1250 (53.1250)  Acc@5: 92.1875 (92.1875)  time: 3.3706  data: 0.8055  max mem: 6949
Train: Epoch[12/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000230  Loss: 0.5530  Acc@1: 56.2500 (57.4290)  Acc@5: 90.6250 (89.3155)  time: 2.1784  data: 0.0807  max mem: 6949
Train: Epoch[12/60] Total time: 0:00:21 (2.1877 s / it)
Averaged stats: Lr: 0.000230  Loss: 0.5530  Acc@1: 56.2500 (57.4290)  Acc@5: 90.6250 (89.3155)
Train: Epoch[13/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000226  Loss: 0.6428  Acc@1: 65.6250 (65.6250)  Acc@5: 92.1875 (92.1875)  time: 3.5120  data: 0.9836  max mem: 6949
Train: Epoch[13/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000226  Loss: 0.6847  Acc@1: 59.3750 (58.4307)  Acc@5: 87.5000 (89.4825)  time: 2.1927  data: 0.0985  max mem: 6949
Train: Epoch[13/60] Total time: 0:00:22 (2.2025 s / it)
Averaged stats: Lr: 0.000226  Loss: 0.6847  Acc@1: 59.3750 (58.4307)  Acc@5: 87.5000 (89.4825)
Train: Epoch[14/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000222  Loss: 0.7603  Acc@1: 62.5000 (62.5000)  Acc@5: 89.0625 (89.0625)  time: 3.3644  data: 0.8209  max mem: 6949
Train: Epoch[14/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000222  Loss: 0.9095  Acc@1: 60.9375 (60.1002)  Acc@5: 87.5000 (88.1469)  time: 2.1650  data: 0.0822  max mem: 6949
Train: Epoch[14/60] Total time: 0:00:21 (2.1733 s / it)
Averaged stats: Lr: 0.000222  Loss: 0.9095  Acc@1: 60.9375 (60.1002)  Acc@5: 87.5000 (88.1469)
Train: Epoch[15/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000218  Loss: 0.8265  Acc@1: 54.6875 (54.6875)  Acc@5: 82.8125 (82.8125)  time: 3.3877  data: 0.8019  max mem: 6949
Train: Epoch[15/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000218  Loss: 0.6199  Acc@1: 62.5000 (65.1085)  Acc@5: 92.1875 (90.6511)  time: 2.1920  data: 0.0803  max mem: 6949
Train: Epoch[15/60] Total time: 0:00:22 (2.2032 s / it)
Averaged stats: Lr: 0.000218  Loss: 0.6199  Acc@1: 62.5000 (65.1085)  Acc@5: 92.1875 (90.6511)
Train: Epoch[16/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000213  Loss: 0.7644  Acc@1: 64.0625 (64.0625)  Acc@5: 90.6250 (90.6250)  time: 3.3556  data: 0.7727  max mem: 6949
Train: Epoch[16/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000213  Loss: 0.6391  Acc@1: 65.6250 (67.2788)  Acc@5: 90.6250 (90.9850)  time: 2.1670  data: 0.0774  max mem: 6949
Train: Epoch[16/60] Total time: 0:00:21 (2.1756 s / it)
Averaged stats: Lr: 0.000213  Loss: 0.6391  Acc@1: 65.6250 (67.2788)  Acc@5: 90.6250 (90.9850)
Train: Epoch[17/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000209  Loss: 0.6467  Acc@1: 73.4375 (73.4375)  Acc@5: 90.6250 (90.6250)  time: 3.3354  data: 0.7729  max mem: 6949
Train: Epoch[17/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000209  Loss: 0.9745  Acc@1: 67.1875 (68.7813)  Acc@5: 90.6250 (90.8180)  time: 2.1683  data: 0.0774  max mem: 6949
Train: Epoch[17/60] Total time: 0:00:21 (2.1781 s / it)
Averaged stats: Lr: 0.000209  Loss: 0.9745  Acc@1: 67.1875 (68.7813)  Acc@5: 90.6250 (90.8180)
Train: Epoch[18/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000204  Loss: 0.5505  Acc@1: 73.4375 (73.4375)  Acc@5: 90.6250 (90.6250)  time: 3.3125  data: 0.8201  max mem: 6949
Train: Epoch[18/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000204  Loss: 0.5145  Acc@1: 65.6250 (67.7796)  Acc@5: 90.6250 (90.3172)  time: 2.1578  data: 0.0822  max mem: 6949
Train: Epoch[18/60] Total time: 0:00:21 (2.1663 s / it)
Averaged stats: Lr: 0.000204  Loss: 0.5145  Acc@1: 65.6250 (67.7796)  Acc@5: 90.6250 (90.3172)
Train: Epoch[19/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000198  Loss: 0.5528  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 3.4028  data: 0.9001  max mem: 6949
Train: Epoch[19/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000198  Loss: 0.6073  Acc@1: 71.8750 (71.2855)  Acc@5: 92.1875 (93.1553)  time: 2.1758  data: 0.0902  max mem: 6949
Train: Epoch[19/60] Total time: 0:00:21 (2.1873 s / it)
Averaged stats: Lr: 0.000198  Loss: 0.6073  Acc@1: 71.8750 (71.2855)  Acc@5: 92.1875 (93.1553)
Train: Epoch[20/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000193  Loss: 0.5967  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)  time: 3.3729  data: 0.9402  max mem: 6949
Train: Epoch[20/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000193  Loss: 0.6892  Acc@1: 68.7500 (68.1135)  Acc@5: 92.1875 (90.9850)  time: 2.1848  data: 0.0942  max mem: 6949
Train: Epoch[20/60] Total time: 0:00:21 (2.1936 s / it)
Averaged stats: Lr: 0.000193  Loss: 0.6892  Acc@1: 68.7500 (68.1135)  Acc@5: 92.1875 (90.9850)
Train: Epoch[21/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000188  Loss: 0.6446  Acc@1: 71.8750 (71.8750)  Acc@5: 87.5000 (87.5000)  time: 3.3874  data: 0.8218  max mem: 6949
Train: Epoch[21/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000188  Loss: 0.6070  Acc@1: 71.8750 (72.2871)  Acc@5: 92.1875 (92.8214)  time: 2.1655  data: 0.0823  max mem: 6949
Train: Epoch[21/60] Total time: 0:00:21 (2.1754 s / it)
Averaged stats: Lr: 0.000188  Loss: 0.6070  Acc@1: 71.8750 (72.2871)  Acc@5: 92.1875 (92.8214)
Train: Epoch[22/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000182  Loss: 0.5525  Acc@1: 76.5625 (76.5625)  Acc@5: 96.8750 (96.8750)  time: 3.3503  data: 0.8908  max mem: 6949
Train: Epoch[22/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000182  Loss: 0.6064  Acc@1: 73.4375 (73.1219)  Acc@5: 92.1875 (94.3239)  time: 2.1576  data: 0.0892  max mem: 6949
Train: Epoch[22/60] Total time: 0:00:21 (2.1657 s / it)
Averaged stats: Lr: 0.000182  Loss: 0.6064  Acc@1: 73.4375 (73.1219)  Acc@5: 92.1875 (94.3239)
Train: Epoch[23/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000176  Loss: 0.4546  Acc@1: 75.0000 (75.0000)  Acc@5: 96.8750 (96.8750)  time: 3.2664  data: 0.8833  max mem: 6949
Train: Epoch[23/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000176  Loss: 0.5151  Acc@1: 75.0000 (76.4608)  Acc@5: 93.7500 (94.1569)  time: 2.1499  data: 0.0885  max mem: 6949
Train: Epoch[23/60] Total time: 0:00:21 (2.1610 s / it)
Averaged stats: Lr: 0.000176  Loss: 0.5151  Acc@1: 75.0000 (76.4608)  Acc@5: 93.7500 (94.1569)
Train: Epoch[24/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000170  Loss: 0.4888  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)  time: 3.3018  data: 0.9030  max mem: 6949
Train: Epoch[24/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000170  Loss: 0.4664  Acc@1: 70.3125 (72.6210)  Acc@5: 93.7500 (91.9866)  time: 2.1482  data: 0.0904  max mem: 6949
Train: Epoch[24/60] Total time: 0:00:21 (2.1562 s / it)
Averaged stats: Lr: 0.000170  Loss: 0.4664  Acc@1: 70.3125 (72.6210)  Acc@5: 93.7500 (91.9866)
Train: Epoch[25/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000164  Loss: 0.6442  Acc@1: 71.8750 (71.8750)  Acc@5: 89.0625 (89.0625)  time: 3.2498  data: 0.8165  max mem: 6949
Train: Epoch[25/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000164  Loss: 0.5925  Acc@1: 71.8750 (73.2888)  Acc@5: 91.3044 (92.3205)  time: 2.1488  data: 0.0818  max mem: 6949
Train: Epoch[25/60] Total time: 0:00:21 (2.1590 s / it)
Averaged stats: Lr: 0.000164  Loss: 0.5925  Acc@1: 71.8750 (73.2888)  Acc@5: 91.3044 (92.3205)
Train: Epoch[26/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000157  Loss: 0.4969  Acc@1: 81.2500 (81.2500)  Acc@5: 95.3125 (95.3125)  time: 3.2862  data: 0.7367  max mem: 6949
Train: Epoch[26/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000157  Loss: 0.4271  Acc@1: 76.5625 (77.1285)  Acc@5: 90.6250 (92.3205)  time: 2.1720  data: 0.0738  max mem: 6949
Train: Epoch[26/60] Total time: 0:00:21 (2.1818 s / it)
Averaged stats: Lr: 0.000157  Loss: 0.4271  Acc@1: 76.5625 (77.1285)  Acc@5: 90.6250 (92.3205)
Train: Epoch[27/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000151  Loss: 0.4284  Acc@1: 82.8125 (82.8125)  Acc@5: 96.8750 (96.8750)  time: 3.3445  data: 0.8107  max mem: 6949
Train: Epoch[27/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000151  Loss: 0.4080  Acc@1: 78.1250 (77.2955)  Acc@5: 93.7500 (94.1569)  time: 2.1609  data: 0.0812  max mem: 6949
Train: Epoch[27/60] Total time: 0:00:21 (2.1714 s / it)
Averaged stats: Lr: 0.000151  Loss: 0.4080  Acc@1: 78.1250 (77.2955)  Acc@5: 93.7500 (94.1569)
Train: Epoch[28/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000145  Loss: 0.4282  Acc@1: 76.5625 (76.5625)  Acc@5: 95.3125 (95.3125)  time: 3.3728  data: 0.8355  max mem: 6949
Train: Epoch[28/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000145  Loss: 0.8438  Acc@1: 73.4375 (76.6277)  Acc@5: 92.1875 (92.4875)  time: 2.1805  data: 0.0837  max mem: 6949
Train: Epoch[28/60] Total time: 0:00:21 (2.1901 s / it)
Averaged stats: Lr: 0.000145  Loss: 0.8438  Acc@1: 73.4375 (76.6277)  Acc@5: 92.1875 (92.4875)
Train: Epoch[29/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000138  Loss: 0.6010  Acc@1: 67.1875 (67.1875)  Acc@5: 90.6250 (90.6250)  time: 3.5906  data: 1.0105  max mem: 6949
Train: Epoch[29/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000138  Loss: 0.3634  Acc@1: 78.2609 (77.1285)  Acc@5: 92.1875 (93.1553)  time: 2.2066  data: 0.1012  max mem: 6949
Train: Epoch[29/60] Total time: 0:00:22 (2.2160 s / it)
Averaged stats: Lr: 0.000138  Loss: 0.3634  Acc@1: 78.2609 (77.1285)  Acc@5: 92.1875 (93.1553)
Train: Epoch[30/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000132  Loss: 0.4844  Acc@1: 76.5625 (76.5625)  Acc@5: 92.1875 (92.1875)  time: 3.3412  data: 0.7934  max mem: 6949
Train: Epoch[30/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000132  Loss: 0.5348  Acc@1: 78.2609 (79.6327)  Acc@5: 92.1875 (93.4891)  time: 2.1569  data: 0.0795  max mem: 6949
Train: Epoch[30/60] Total time: 0:00:21 (2.1648 s / it)
Averaged stats: Lr: 0.000132  Loss: 0.5348  Acc@1: 78.2609 (79.6327)  Acc@5: 92.1875 (93.4891)
Train: Epoch[31/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000125  Loss: 0.4493  Acc@1: 71.8750 (71.8750)  Acc@5: 93.7500 (93.7500)  time: 3.2974  data: 0.8538  max mem: 6949
Train: Epoch[31/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000125  Loss: 0.6007  Acc@1: 76.5625 (77.7963)  Acc@5: 93.7500 (94.1569)  time: 2.1740  data: 0.0855  max mem: 6949
Train: Epoch[31/60] Total time: 0:00:21 (2.1844 s / it)
Averaged stats: Lr: 0.000125  Loss: 0.6007  Acc@1: 76.5625 (77.7963)  Acc@5: 93.7500 (94.1569)
Train: Epoch[32/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000118  Loss: 0.3342  Acc@1: 84.3750 (84.3750)  Acc@5: 100.0000 (100.0000)  time: 3.3946  data: 0.8936  max mem: 6949
Train: Epoch[32/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000118  Loss: 0.6193  Acc@1: 78.1250 (78.2972)  Acc@5: 92.1875 (93.3222)  time: 2.1601  data: 0.0895  max mem: 6949
Train: Epoch[32/60] Total time: 0:00:21 (2.1682 s / it)
Averaged stats: Lr: 0.000118  Loss: 0.6193  Acc@1: 78.1250 (78.2972)  Acc@5: 92.1875 (93.3222)
Train: Epoch[33/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000112  Loss: 0.3378  Acc@1: 89.0625 (89.0625)  Acc@5: 98.4375 (98.4375)  time: 3.2595  data: 0.7505  max mem: 6949
Train: Epoch[33/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000112  Loss: 0.5611  Acc@1: 76.5625 (78.6311)  Acc@5: 93.7500 (93.8230)  time: 2.1487  data: 0.0752  max mem: 6949
Train: Epoch[33/60] Total time: 0:00:21 (2.1578 s / it)
Averaged stats: Lr: 0.000112  Loss: 0.5611  Acc@1: 76.5625 (78.6311)  Acc@5: 93.7500 (93.8230)
Train: Epoch[34/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000105  Loss: 0.3606  Acc@1: 90.6250 (90.6250)  Acc@5: 96.8750 (96.8750)  time: 3.2950  data: 0.8589  max mem: 6949
Train: Epoch[34/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000105  Loss: 0.5196  Acc@1: 79.6875 (81.6361)  Acc@5: 93.7500 (93.1553)  time: 2.1536  data: 0.0860  max mem: 6949
Train: Epoch[34/60] Total time: 0:00:21 (2.1618 s / it)
Averaged stats: Lr: 0.000105  Loss: 0.5196  Acc@1: 79.6875 (81.6361)  Acc@5: 93.7500 (93.1553)
Train: Epoch[35/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000099  Loss: 0.3375  Acc@1: 79.6875 (79.6875)  Acc@5: 96.8750 (96.8750)  time: 3.1946  data: 0.7276  max mem: 6949
Train: Epoch[35/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000099  Loss: 0.2247  Acc@1: 79.6875 (80.9683)  Acc@5: 93.7500 (94.3239)  time: 2.1470  data: 0.0729  max mem: 6949
Train: Epoch[35/60] Total time: 0:00:21 (2.1568 s / it)
Averaged stats: Lr: 0.000099  Loss: 0.2247  Acc@1: 79.6875 (80.9683)  Acc@5: 93.7500 (94.3239)
Train: Epoch[36/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000093  Loss: 0.4225  Acc@1: 79.6875 (79.6875)  Acc@5: 98.4375 (98.4375)  time: 3.5037  data: 0.7649  max mem: 6949
Train: Epoch[36/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000093  Loss: 0.5043  Acc@1: 78.1250 (79.1319)  Acc@5: 93.7500 (94.3239)  time: 2.1764  data: 0.0766  max mem: 6949
Train: Epoch[36/60] Total time: 0:00:21 (2.1851 s / it)
Averaged stats: Lr: 0.000093  Loss: 0.5043  Acc@1: 78.1250 (79.1319)  Acc@5: 93.7500 (94.3239)
Train: Epoch[37/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000086  Loss: 0.4697  Acc@1: 79.6875 (79.6875)  Acc@5: 89.0625 (89.0625)  time: 3.3403  data: 0.8568  max mem: 6949
Train: Epoch[37/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000086  Loss: 0.3600  Acc@1: 76.5625 (79.6327)  Acc@5: 92.1875 (92.4875)  time: 2.1578  data: 0.0858  max mem: 6949
Train: Epoch[37/60] Total time: 0:00:21 (2.1684 s / it)
Averaged stats: Lr: 0.000086  Loss: 0.3600  Acc@1: 76.5625 (79.6327)  Acc@5: 92.1875 (92.4875)
Train: Epoch[38/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000080  Loss: 0.3979  Acc@1: 84.3750 (84.3750)  Acc@5: 95.3125 (95.3125)  time: 3.2676  data: 0.7349  max mem: 6949
Train: Epoch[38/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000080  Loss: 0.2457  Acc@1: 79.6875 (80.9683)  Acc@5: 95.3125 (94.8247)  time: 2.1506  data: 0.0736  max mem: 6949
Train: Epoch[38/60] Total time: 0:00:21 (2.1588 s / it)
Averaged stats: Lr: 0.000080  Loss: 0.2457  Acc@1: 79.6875 (80.9683)  Acc@5: 95.3125 (94.8247)
Train: Epoch[39/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000074  Loss: 0.3317  Acc@1: 82.8125 (82.8125)  Acc@5: 98.4375 (98.4375)  time: 3.2812  data: 0.8067  max mem: 6949
Train: Epoch[39/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000074  Loss: 0.3317  Acc@1: 82.8125 (81.6361)  Acc@5: 95.3125 (94.6578)  time: 2.1517  data: 0.0808  max mem: 6949
Train: Epoch[39/60] Total time: 0:00:21 (2.1616 s / it)
Averaged stats: Lr: 0.000074  Loss: 0.3317  Acc@1: 82.8125 (81.6361)  Acc@5: 95.3125 (94.6578)
Train: Epoch[40/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000068  Loss: 0.5028  Acc@1: 76.5625 (76.5625)  Acc@5: 90.6250 (90.6250)  time: 3.2786  data: 0.8075  max mem: 6949
Train: Epoch[40/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000068  Loss: 0.3527  Acc@1: 78.1250 (78.4641)  Acc@5: 93.7500 (92.9883)  time: 2.1449  data: 0.0809  max mem: 6949
Train: Epoch[40/60] Total time: 0:00:21 (2.1531 s / it)
Averaged stats: Lr: 0.000068  Loss: 0.3527  Acc@1: 78.1250 (78.4641)  Acc@5: 93.7500 (92.9883)
Train: Epoch[41/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000063  Loss: 0.4619  Acc@1: 76.5625 (76.5625)  Acc@5: 95.3125 (95.3125)  time: 3.3543  data: 0.8803  max mem: 6949
Train: Epoch[41/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000063  Loss: 0.1533  Acc@1: 81.2500 (81.4691)  Acc@5: 93.7500 (94.8247)  time: 2.1781  data: 0.0881  max mem: 6949
Train: Epoch[41/60] Total time: 0:00:21 (2.1900 s / it)
Averaged stats: Lr: 0.000063  Loss: 0.1533  Acc@1: 81.2500 (81.4691)  Acc@5: 93.7500 (94.8247)
Train: Epoch[42/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000057  Loss: 0.3751  Acc@1: 84.3750 (84.3750)  Acc@5: 95.3125 (95.3125)  time: 3.4272  data: 0.8943  max mem: 6949
Train: Epoch[42/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000057  Loss: 0.3686  Acc@1: 78.1250 (79.2988)  Acc@5: 92.1875 (93.8230)  time: 2.1650  data: 0.0896  max mem: 6949
Train: Epoch[42/60] Total time: 0:00:21 (2.1731 s / it)
Averaged stats: Lr: 0.000057  Loss: 0.3686  Acc@1: 78.1250 (79.2988)  Acc@5: 92.1875 (93.8230)
Train: Epoch[43/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000052  Loss: 0.5306  Acc@1: 76.5625 (76.5625)  Acc@5: 89.0625 (89.0625)  time: 3.2639  data: 0.7163  max mem: 6949
Train: Epoch[43/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000052  Loss: 0.3402  Acc@1: 78.1250 (79.7997)  Acc@5: 93.7500 (93.4891)  time: 2.1465  data: 0.0718  max mem: 6949
Train: Epoch[43/60] Total time: 0:00:21 (2.1555 s / it)
Averaged stats: Lr: 0.000052  Loss: 0.3402  Acc@1: 78.1250 (79.7997)  Acc@5: 93.7500 (93.4891)
Train: Epoch[44/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000046  Loss: 0.4559  Acc@1: 85.9375 (85.9375)  Acc@5: 93.7500 (93.7500)  time: 3.2789  data: 0.8416  max mem: 6949
Train: Epoch[44/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000046  Loss: 0.2249  Acc@1: 82.8125 (81.1352)  Acc@5: 93.7500 (93.8230)  time: 2.1504  data: 0.0843  max mem: 6949
Train: Epoch[44/60] Total time: 0:00:21 (2.1589 s / it)
Averaged stats: Lr: 0.000046  Loss: 0.2249  Acc@1: 82.8125 (81.1352)  Acc@5: 93.7500 (93.8230)
Train: Epoch[45/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000041  Loss: 0.4422  Acc@1: 76.5625 (76.5625)  Acc@5: 90.6250 (90.6250)  time: 3.3309  data: 0.8117  max mem: 6949
Train: Epoch[45/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000041  Loss: 0.5698  Acc@1: 78.2609 (80.9683)  Acc@5: 92.1875 (92.8214)  time: 2.1596  data: 0.0813  max mem: 6949
Train: Epoch[45/60] Total time: 0:00:21 (2.1692 s / it)
Averaged stats: Lr: 0.000041  Loss: 0.5698  Acc@1: 78.2609 (80.9683)  Acc@5: 92.1875 (92.8214)
Train: Epoch[46/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000037  Loss: 0.4114  Acc@1: 85.9375 (85.9375)  Acc@5: 93.7500 (93.7500)  time: 3.3958  data: 0.9301  max mem: 6949
Train: Epoch[46/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000037  Loss: 0.3147  Acc@1: 79.6875 (81.3022)  Acc@5: 95.3125 (95.1586)  time: 2.1852  data: 0.0931  max mem: 6949
Train: Epoch[46/60] Total time: 0:00:21 (2.1939 s / it)
Averaged stats: Lr: 0.000037  Loss: 0.3147  Acc@1: 79.6875 (81.3022)  Acc@5: 95.3125 (95.1586)
Train: Epoch[47/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000032  Loss: 0.3939  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)  time: 3.3332  data: 0.7872  max mem: 6949
Train: Epoch[47/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000032  Loss: 0.1723  Acc@1: 84.3750 (84.1402)  Acc@5: 95.3125 (95.3255)  time: 2.1538  data: 0.0789  max mem: 6949
Train: Epoch[47/60] Total time: 0:00:21 (2.1644 s / it)
Averaged stats: Lr: 0.000032  Loss: 0.1723  Acc@1: 84.3750 (84.1402)  Acc@5: 95.3125 (95.3255)
Train: Epoch[48/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000028  Loss: 0.3432  Acc@1: 81.2500 (81.2500)  Acc@5: 95.3125 (95.3125)  time: 3.3009  data: 0.7322  max mem: 6949
Train: Epoch[48/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000028  Loss: 0.4440  Acc@1: 81.2500 (81.8030)  Acc@5: 95.3125 (94.9917)  time: 2.1517  data: 0.0734  max mem: 6949
Train: Epoch[48/60] Total time: 0:00:21 (2.1599 s / it)
Averaged stats: Lr: 0.000028  Loss: 0.4440  Acc@1: 81.2500 (81.8030)  Acc@5: 95.3125 (94.9917)
Train: Epoch[49/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000024  Loss: 0.3194  Acc@1: 84.3750 (84.3750)  Acc@5: 96.8750 (96.8750)  time: 3.2926  data: 0.8667  max mem: 6949
Train: Epoch[49/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000024  Loss: 0.2269  Acc@1: 84.3750 (83.9733)  Acc@5: 95.3125 (95.4925)  time: 2.1460  data: 0.0868  max mem: 6949
Train: Epoch[49/60] Total time: 0:00:21 (2.1561 s / it)
Averaged stats: Lr: 0.000024  Loss: 0.2269  Acc@1: 84.3750 (83.9733)  Acc@5: 95.3125 (95.4925)
Train: Epoch[50/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000020  Loss: 0.3777  Acc@1: 82.8125 (82.8125)  Acc@5: 95.3125 (95.3125)  time: 3.2420  data: 0.7169  max mem: 6949
Train: Epoch[50/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000020  Loss: 0.3605  Acc@1: 78.1250 (78.2972)  Acc@5: 92.1875 (93.4891)  time: 2.1395  data: 0.0718  max mem: 6949
Train: Epoch[50/60] Total time: 0:00:21 (2.1474 s / it)
Averaged stats: Lr: 0.000020  Loss: 0.3605  Acc@1: 78.1250 (78.2972)  Acc@5: 92.1875 (93.4891)
Train: Epoch[51/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000017  Loss: 0.3098  Acc@1: 85.9375 (85.9375)  Acc@5: 95.3125 (95.3125)  time: 3.2419  data: 0.7168  max mem: 6949
Train: Epoch[51/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000017  Loss: 0.1921  Acc@1: 82.8125 (82.6377)  Acc@5: 93.7500 (93.9900)  time: 2.1623  data: 0.0718  max mem: 6949
Train: Epoch[51/60] Total time: 0:00:21 (2.1720 s / it)
Averaged stats: Lr: 0.000017  Loss: 0.1921  Acc@1: 82.8125 (82.6377)  Acc@5: 93.7500 (93.9900)
Train: Epoch[52/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000014  Loss: 0.4994  Acc@1: 78.1250 (78.1250)  Acc@5: 90.6250 (90.6250)  time: 3.2257  data: 0.7116  max mem: 6949
Train: Epoch[52/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000014  Loss: 0.7120  Acc@1: 82.8125 (83.1386)  Acc@5: 92.1875 (93.1553)  time: 2.1372  data: 0.0713  max mem: 6949
Train: Epoch[52/60] Total time: 0:00:21 (2.1451 s / it)
Averaged stats: Lr: 0.000014  Loss: 0.7120  Acc@1: 82.8125 (83.1386)  Acc@5: 92.1875 (93.1553)
Train: Epoch[53/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000011  Loss: 0.2789  Acc@1: 82.8125 (82.8125)  Acc@5: 96.8750 (96.8750)  time: 3.3174  data: 0.8738  max mem: 6949
Train: Epoch[53/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000011  Loss: 0.3162  Acc@1: 82.8125 (83.3055)  Acc@5: 95.3125 (93.8230)  time: 2.1486  data: 0.0875  max mem: 6949
Train: Epoch[53/60] Total time: 0:00:21 (2.1586 s / it)
Averaged stats: Lr: 0.000011  Loss: 0.3162  Acc@1: 82.8125 (83.3055)  Acc@5: 95.3125 (93.8230)
Train: Epoch[54/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000008  Loss: 0.2919  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 3.2079  data: 0.7014  max mem: 6949
Train: Epoch[54/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000008  Loss: 0.1985  Acc@1: 81.2500 (80.1336)  Acc@5: 93.7500 (92.4875)  time: 2.1363  data: 0.0703  max mem: 6949
Train: Epoch[54/60] Total time: 0:00:21 (2.1443 s / it)
Averaged stats: Lr: 0.000008  Loss: 0.1985  Acc@1: 81.2500 (80.1336)  Acc@5: 93.7500 (92.4875)
Train: Epoch[55/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000006  Loss: 0.3547  Acc@1: 78.1250 (78.1250)  Acc@5: 95.3125 (95.3125)  time: 3.2313  data: 0.7450  max mem: 6949
Train: Epoch[55/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000006  Loss: 0.4066  Acc@1: 81.2500 (82.1369)  Acc@5: 95.3125 (94.3239)  time: 2.1409  data: 0.0746  max mem: 6949
Train: Epoch[55/60] Total time: 0:00:21 (2.1504 s / it)
Averaged stats: Lr: 0.000006  Loss: 0.4066  Acc@1: 81.2500 (82.1369)  Acc@5: 95.3125 (94.3239)
Train: Epoch[56/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000004  Loss: 0.3616  Acc@1: 79.6875 (79.6875)  Acc@5: 95.3125 (95.3125)  time: 3.2492  data: 0.7240  max mem: 6949
Train: Epoch[56/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000004  Loss: 0.2820  Acc@1: 84.3750 (82.3038)  Acc@5: 93.7500 (94.3239)  time: 2.1451  data: 0.0725  max mem: 6949
Train: Epoch[56/60] Total time: 0:00:21 (2.1532 s / it)
Averaged stats: Lr: 0.000004  Loss: 0.2820  Acc@1: 84.3750 (82.3038)  Acc@5: 93.7500 (94.3239)
Train: Epoch[57/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000003  Loss: 0.2396  Acc@1: 81.2500 (81.2500)  Acc@5: 98.4375 (98.4375)  time: 3.4524  data: 0.8600  max mem: 6949
Train: Epoch[57/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000003  Loss: 0.2391  Acc@1: 84.3750 (84.9750)  Acc@5: 93.7500 (94.1569)  time: 2.1625  data: 0.0861  max mem: 6949
Train: Epoch[57/60] Total time: 0:00:21 (2.1723 s / it)
Averaged stats: Lr: 0.000003  Loss: 0.2391  Acc@1: 84.3750 (84.9750)  Acc@5: 93.7500 (94.1569)
Train: Epoch[58/60]  [ 0/10]  eta: 0:00:31  Lr: 0.000002  Loss: 0.4569  Acc@1: 71.8750 (71.8750)  Acc@5: 90.6250 (90.6250)  time: 3.1894  data: 0.7084  max mem: 6949
Train: Epoch[58/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000002  Loss: 0.5321  Acc@1: 81.2500 (81.9700)  Acc@5: 93.7500 (94.6578)  time: 2.1352  data: 0.0710  max mem: 6949
Train: Epoch[58/60] Total time: 0:00:21 (2.1438 s / it)
Averaged stats: Lr: 0.000002  Loss: 0.5321  Acc@1: 81.2500 (81.9700)  Acc@5: 93.7500 (94.6578)
Train: Epoch[59/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000001  Loss: 0.3824  Acc@1: 79.6875 (79.6875)  Acc@5: 95.3125 (95.3125)  time: 3.2844  data: 0.8403  max mem: 6949
Train: Epoch[59/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000001  Loss: 0.3441  Acc@1: 81.2500 (82.1369)  Acc@5: 95.3125 (94.9917)  time: 2.1480  data: 0.0842  max mem: 6949
Train: Epoch[59/60] Total time: 0:00:21 (2.1586 s / it)
Averaged stats: Lr: 0.000001  Loss: 0.3441  Acc@1: 81.2500 (82.1369)  Acc@5: 95.3125 (94.9917)
Train: Epoch[60/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000000  Loss: 0.2446  Acc@1: 87.5000 (87.5000)  Acc@5: 96.8750 (96.8750)  time: 3.3264  data: 0.8776  max mem: 6949
Train: Epoch[60/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000000  Loss: 0.1832  Acc@1: 84.3750 (83.1386)  Acc@5: 95.3125 (95.1586)  time: 2.1623  data: 0.0879  max mem: 6949
Train: Epoch[60/60] Total time: 0:00:21 (2.1707 s / it)
Averaged stats: Lr: 0.000000  Loss: 0.1832  Acc@1: 84.3750 (83.1386)  Acc@5: 95.3125 (95.1586)
Test: [Task 1]  [0/9]  eta: 0:00:15  Loss: 0.4049 (0.4049)  Acc@1: 92.1875 (92.1875)  Acc@5: 98.4375 (98.4375)  time: 1.6796  data: 0.9303  max mem: 6949
Test: [Task 1]  [8/9]  eta: 0:00:00  Loss: 0.2330 (0.2872)  Acc@1: 96.8750 (92.4272)  Acc@5: 100.0000 (99.2233)  time: 0.7167  data: 0.1036  max mem: 6949
Test: [Task 1] Total time: 0:00:06 (0.7266 s / it)
* Acc@1 92.427 Acc@5 99.223 loss 0.287
Batchwise eval time for task 1 = 0.7266717486911349
Test: [Task 2]  [0/9]  eta: 0:00:18  Loss: 0.5966 (0.5966)  Acc@1: 79.6875 (79.6875)  Acc@5: 98.4375 (98.4375)  time: 2.0786  data: 1.1535  max mem: 6949
Test: [Task 2]  [8/9]  eta: 0:00:00  Loss: 1.0285 (0.9904)  Acc@1: 59.3750 (65.2174)  Acc@5: 98.4375 (98.0870)  time: 0.8074  data: 0.1284  max mem: 6949
Test: [Task 2] Total time: 0:00:07 (0.8175 s / it)
* Acc@1 65.217 Acc@5 98.087 loss 0.990
Batchwise eval time for task 2 = 0.8175440894232856
Test: [Task 3]  [ 0/10]  eta: 0:00:19  Loss: 0.3254 (0.3254)  Acc@1: 95.3125 (95.3125)  Acc@5: 98.4375 (98.4375)  time: 1.9657  data: 1.0802  max mem: 6949
Test: [Task 3]  [ 9/10]  eta: 0:00:00  Loss: 0.3506 (0.5426)  Acc@1: 93.7500 (90.2685)  Acc@5: 98.4375 (98.9933)  time: 0.7470  data: 0.1083  max mem: 6949
Test: [Task 3] Total time: 0:00:07 (0.7557 s / it)
* Acc@1 90.268 Acc@5 98.993 loss 0.543
Batchwise eval time for task 3 = 0.7556778430938721
Test: [Task 4]  [ 0/10]  eta: 0:00:18  Loss: 1.2585 (1.2585)  Acc@1: 53.1250 (53.1250)  Acc@5: 95.3125 (95.3125)  time: 1.8003  data: 0.9296  max mem: 6949
Test: [Task 4]  [ 9/10]  eta: 0:00:00  Loss: 0.6191 (0.7397)  Acc@1: 85.9375 (79.0102)  Acc@5: 100.0000 (98.8055)  time: 0.7219  data: 0.0932  max mem: 6949
Test: [Task 4] Total time: 0:00:07 (0.7299 s / it)
* Acc@1 79.010 Acc@5 98.805 loss 0.740
Batchwise eval time for task 4 = 0.7298787832260132
Test: [Task 5]  [ 0/10]  eta: 0:00:17  Loss: 0.4713 (0.4713)  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)  time: 1.7381  data: 0.9483  max mem: 6949
Test: [Task 5]  [ 9/10]  eta: 0:00:00  Loss: 0.3330 (0.4081)  Acc@1: 92.1875 (93.7500)  Acc@5: 98.4375 (98.3108)  time: 0.7230  data: 0.0951  max mem: 6949
Test: [Task 5] Total time: 0:00:07 (0.7320 s / it)
* Acc@1 93.750 Acc@5 98.311 loss 0.408
Batchwise eval time for task 5 = 0.7319803714752198
Test: [Task 6]  [0/9]  eta: 0:00:18  Loss: 0.6998 (0.6998)  Acc@1: 81.2500 (81.2500)  Acc@5: 98.4375 (98.4375)  time: 2.0054  data: 1.1792  max mem: 6949
Test: [Task 6]  [8/9]  eta: 0:00:00  Loss: 0.7041 (0.7008)  Acc@1: 85.9375 (86.0424)  Acc@5: 98.4375 (98.5866)  time: 0.8502  data: 0.1312  max mem: 6949
Test: [Task 6] Total time: 0:00:07 (0.8605 s / it)
* Acc@1 86.042 Acc@5 98.587 loss 0.701
Batchwise eval time for task 6 = 0.860486798816257
[Average accuracy till task6]	Acc@1: 84.3732	Acc@5: 98.6677	Loss: 0.6114	Forgetting: 5.0976	Backward: -5.0976
Eval time for task 6 = 44.035696268081665
Using adam optimizer
Reinitialising optimizer
Similarity:  tensor(0.9016)  Task:  6
Old Num K:  10 New Num K:  11
Task number:  6
Train: Epoch[ 1/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000250  Loss: 3.2232  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  time: 3.5380  data: 0.8864  max mem: 6988
Train: Epoch[ 1/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000250  Loss: 2.7886  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.1672)  time: 2.3471  data: 0.0888  max mem: 7001
Train: Epoch[ 1/60] Total time: 0:00:23 (2.3557 s / it)
Averaged stats: Lr: 0.000250  Loss: 2.7886  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.1672)
Train: Epoch[ 2/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000250  Loss: 2.8305  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  time: 3.3807  data: 0.7017  max mem: 7001
Train: Epoch[ 2/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000250  Loss: 2.4469  Acc@1: 0.0000 (0.0000)  Acc@5: 1.5625 (2.5084)  time: 2.2628  data: 0.0703  max mem: 7001
Train: Epoch[ 2/60] Total time: 0:00:22 (2.2709 s / it)
Averaged stats: Lr: 0.000250  Loss: 2.4469  Acc@1: 0.0000 (0.0000)  Acc@5: 1.5625 (2.5084)
Train: Epoch[ 3/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000249  Loss: 2.6062  Acc@1: 0.0000 (0.0000)  Acc@5: 1.5625 (1.5625)  time: 3.3792  data: 0.7772  max mem: 7001
Train: Epoch[ 3/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000249  Loss: 1.9582  Acc@1: 0.0000 (0.8361)  Acc@5: 10.9375 (12.5418)  time: 2.2571  data: 0.0778  max mem: 7001
Train: Epoch[ 3/60] Total time: 0:00:22 (2.2664 s / it)
Averaged stats: Lr: 0.000249  Loss: 1.9582  Acc@1: 0.0000 (0.8361)  Acc@5: 10.9375 (12.5418)
Train: Epoch[ 4/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000248  Loss: 2.0847  Acc@1: 1.5625 (1.5625)  Acc@5: 21.8750 (21.8750)  time: 3.4560  data: 0.7649  max mem: 7001
Train: Epoch[ 4/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000248  Loss: 1.6120  Acc@1: 1.5625 (3.1773)  Acc@5: 26.5625 (28.2609)  time: 2.2614  data: 0.0766  max mem: 7001
Train: Epoch[ 4/60] Total time: 0:00:22 (2.2699 s / it)
Averaged stats: Lr: 0.000248  Loss: 1.6120  Acc@1: 1.5625 (3.1773)  Acc@5: 26.5625 (28.2609)
Train: Epoch[ 5/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000247  Loss: 1.8014  Acc@1: 7.8125 (7.8125)  Acc@5: 32.8125 (32.8125)  time: 3.4454  data: 0.9215  max mem: 7001
Train: Epoch[ 5/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000247  Loss: 1.6619  Acc@1: 9.3750 (10.5351)  Acc@5: 40.6250 (46.6555)  time: 2.2827  data: 0.0923  max mem: 7001
Train: Epoch[ 5/60] Total time: 0:00:22 (2.2938 s / it)
Averaged stats: Lr: 0.000247  Loss: 1.6619  Acc@1: 9.3750 (10.5351)  Acc@5: 40.6250 (46.6555)
Train: Epoch[ 6/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000246  Loss: 1.6701  Acc@1: 18.7500 (18.7500)  Acc@5: 42.1875 (42.1875)  time: 3.4460  data: 0.7681  max mem: 7001
Train: Epoch[ 6/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000246  Loss: 1.6208  Acc@1: 18.7500 (18.2274)  Acc@5: 54.6875 (56.5217)  time: 2.2604  data: 0.0769  max mem: 7001
Train: Epoch[ 6/60] Total time: 0:00:22 (2.2684 s / it)
Averaged stats: Lr: 0.000246  Loss: 1.6208  Acc@1: 18.7500 (18.2274)  Acc@5: 54.6875 (56.5217)
Train: Epoch[ 7/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000244  Loss: 1.3628  Acc@1: 21.8750 (21.8750)  Acc@5: 64.0625 (64.0625)  time: 3.4659  data: 0.8474  max mem: 7001
Train: Epoch[ 7/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000244  Loss: 1.3640  Acc@1: 21.8750 (22.9097)  Acc@5: 64.0625 (66.5552)  time: 2.2698  data: 0.0849  max mem: 7001
Train: Epoch[ 7/60] Total time: 0:00:22 (2.2793 s / it)
Averaged stats: Lr: 0.000244  Loss: 1.3640  Acc@1: 21.8750 (22.9097)  Acc@5: 64.0625 (66.5552)
Train: Epoch[ 8/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000242  Loss: 1.4327  Acc@1: 23.4375 (23.4375)  Acc@5: 62.5000 (62.5000)  time: 3.3992  data: 0.8159  max mem: 7001
Train: Epoch[ 8/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000242  Loss: 1.0187  Acc@1: 23.4375 (24.2475)  Acc@5: 71.8750 (71.7391)  time: 2.2778  data: 0.0817  max mem: 7001
Train: Epoch[ 8/60] Total time: 0:00:22 (2.2864 s / it)
Averaged stats: Lr: 0.000242  Loss: 1.0187  Acc@1: 23.4375 (24.2475)  Acc@5: 71.8750 (71.7391)
Train: Epoch[ 9/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000239  Loss: 1.0186  Acc@1: 37.5000 (37.5000)  Acc@5: 85.9375 (85.9375)  time: 3.6566  data: 0.9890  max mem: 7001
Train: Epoch[ 9/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000239  Loss: 1.0965  Acc@1: 29.6875 (29.7659)  Acc@5: 78.1250 (76.9231)  time: 2.2950  data: 0.0990  max mem: 7001
Train: Epoch[ 9/60] Total time: 0:00:23 (2.3048 s / it)
Averaged stats: Lr: 0.000239  Loss: 1.0965  Acc@1: 29.6875 (29.7659)  Acc@5: 78.1250 (76.9231)
Train: Epoch[10/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000236  Loss: 1.0797  Acc@1: 37.5000 (37.5000)  Acc@5: 79.6875 (79.6875)  time: 3.5028  data: 0.9139  max mem: 7001
Train: Epoch[10/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000236  Loss: 0.9876  Acc@1: 29.6875 (34.6154)  Acc@5: 81.2500 (81.1037)  time: 2.2908  data: 0.0915  max mem: 7001
Train: Epoch[10/60] Total time: 0:00:22 (2.2995 s / it)
Averaged stats: Lr: 0.000236  Loss: 0.9876  Acc@1: 29.6875 (34.6154)  Acc@5: 81.2500 (81.1037)
Train: Epoch[11/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000233  Loss: 1.2753  Acc@1: 26.5625 (26.5625)  Acc@5: 73.4375 (73.4375)  time: 3.4716  data: 0.8422  max mem: 7001
Train: Epoch[11/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000233  Loss: 1.2886  Acc@1: 31.2500 (36.1204)  Acc@5: 78.1250 (79.7659)  time: 2.2736  data: 0.0844  max mem: 7001
Train: Epoch[11/60] Total time: 0:00:22 (2.2842 s / it)
Averaged stats: Lr: 0.000233  Loss: 1.2886  Acc@1: 31.2500 (36.1204)  Acc@5: 78.1250 (79.7659)
Train: Epoch[12/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000230  Loss: 1.1530  Acc@1: 43.7500 (43.7500)  Acc@5: 75.0000 (75.0000)  time: 3.5425  data: 0.9431  max mem: 7001
Train: Epoch[12/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000230  Loss: 0.8202  Acc@1: 39.0625 (39.4649)  Acc@5: 82.8125 (82.4415)  time: 2.2738  data: 0.0944  max mem: 7001
Train: Epoch[12/60] Total time: 0:00:22 (2.2822 s / it)
Averaged stats: Lr: 0.000230  Loss: 0.8202  Acc@1: 39.0625 (39.4649)  Acc@5: 82.8125 (82.4415)
Train: Epoch[13/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000226  Loss: 1.1404  Acc@1: 32.8125 (32.8125)  Acc@5: 75.0000 (75.0000)  time: 3.4963  data: 0.7767  max mem: 7001
Train: Epoch[13/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000226  Loss: 1.2150  Acc@1: 43.7500 (42.6421)  Acc@5: 85.9375 (84.9498)  time: 2.2785  data: 0.0778  max mem: 7001
Train: Epoch[13/60] Total time: 0:00:22 (2.2875 s / it)
Averaged stats: Lr: 0.000226  Loss: 1.2150  Acc@1: 43.7500 (42.6421)  Acc@5: 85.9375 (84.9498)
Train: Epoch[14/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000222  Loss: 0.9570  Acc@1: 45.3125 (45.3125)  Acc@5: 84.3750 (84.3750)  time: 3.4093  data: 0.8684  max mem: 7001
Train: Epoch[14/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000222  Loss: 0.9028  Acc@1: 45.3125 (47.9933)  Acc@5: 85.9375 (86.6221)  time: 2.2846  data: 0.0870  max mem: 7001
Train: Epoch[14/60] Total time: 0:00:22 (2.2933 s / it)
Averaged stats: Lr: 0.000222  Loss: 0.9028  Acc@1: 45.3125 (47.9933)  Acc@5: 85.9375 (86.6221)
Train: Epoch[15/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000218  Loss: 0.9104  Acc@1: 43.7500 (43.7500)  Acc@5: 81.2500 (81.2500)  time: 3.3741  data: 0.8004  max mem: 7001
Train: Epoch[15/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000218  Loss: 0.9992  Acc@1: 50.0000 (49.3311)  Acc@5: 84.3750 (85.2843)  time: 2.2605  data: 0.0802  max mem: 7001
Train: Epoch[15/60] Total time: 0:00:22 (2.2697 s / it)
Averaged stats: Lr: 0.000218  Loss: 0.9992  Acc@1: 50.0000 (49.3311)  Acc@5: 84.3750 (85.2843)
Train: Epoch[16/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000213  Loss: 0.9177  Acc@1: 46.8750 (46.8750)  Acc@5: 84.3750 (84.3750)  time: 3.4566  data: 0.8082  max mem: 7001
Train: Epoch[16/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000213  Loss: 0.9096  Acc@1: 50.0000 (50.8361)  Acc@5: 84.3750 (85.9532)  time: 2.2667  data: 0.0810  max mem: 7001
Train: Epoch[16/60] Total time: 0:00:22 (2.2747 s / it)
Averaged stats: Lr: 0.000213  Loss: 0.9096  Acc@1: 50.0000 (50.8361)  Acc@5: 84.3750 (85.9532)
Train: Epoch[17/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000209  Loss: 0.7004  Acc@1: 53.1250 (53.1250)  Acc@5: 95.3125 (95.3125)  time: 3.4564  data: 0.8525  max mem: 7001
Train: Epoch[17/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000209  Loss: 0.7543  Acc@1: 53.1250 (54.0134)  Acc@5: 84.3750 (86.7893)  time: 2.2643  data: 0.0854  max mem: 7001
Train: Epoch[17/60] Total time: 0:00:22 (2.2749 s / it)
Averaged stats: Lr: 0.000209  Loss: 0.7543  Acc@1: 53.1250 (54.0134)  Acc@5: 84.3750 (86.7893)
Train: Epoch[18/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000204  Loss: 0.6742  Acc@1: 67.1875 (67.1875)  Acc@5: 90.6250 (90.6250)  time: 3.4837  data: 0.8759  max mem: 7001
Train: Epoch[18/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000204  Loss: 1.1442  Acc@1: 56.2500 (56.0201)  Acc@5: 87.5000 (85.4515)  time: 2.2830  data: 0.0877  max mem: 7001
Train: Epoch[18/60] Total time: 0:00:22 (2.2913 s / it)
Averaged stats: Lr: 0.000204  Loss: 1.1442  Acc@1: 56.2500 (56.0201)  Acc@5: 87.5000 (85.4515)
Train: Epoch[19/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000198  Loss: 0.8390  Acc@1: 54.6875 (54.6875)  Acc@5: 82.8125 (82.8125)  time: 3.3271  data: 0.7553  max mem: 7001
Train: Epoch[19/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000198  Loss: 0.4946  Acc@1: 57.8125 (57.3579)  Acc@5: 87.5000 (88.1271)  time: 2.2458  data: 0.0757  max mem: 7001
Train: Epoch[19/60] Total time: 0:00:22 (2.2555 s / it)
Averaged stats: Lr: 0.000198  Loss: 0.4946  Acc@1: 57.8125 (57.3579)  Acc@5: 87.5000 (88.1271)
Train: Epoch[20/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000193  Loss: 0.8029  Acc@1: 59.3750 (59.3750)  Acc@5: 87.5000 (87.5000)  time: 3.3565  data: 0.7044  max mem: 7001
Train: Epoch[20/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000193  Loss: 0.8834  Acc@1: 56.2500 (57.8595)  Acc@5: 85.9375 (85.9532)  time: 2.2614  data: 0.0706  max mem: 7001
Train: Epoch[20/60] Total time: 0:00:22 (2.2707 s / it)
Averaged stats: Lr: 0.000193  Loss: 0.8834  Acc@1: 56.2500 (57.8595)  Acc@5: 85.9375 (85.9532)
Train: Epoch[21/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000188  Loss: 0.6863  Acc@1: 65.6250 (65.6250)  Acc@5: 92.1875 (92.1875)  time: 3.6444  data: 0.9364  max mem: 7001
Train: Epoch[21/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000188  Loss: 0.9481  Acc@1: 60.9375 (60.0334)  Acc@5: 85.9375 (87.1237)  time: 2.3001  data: 0.0938  max mem: 7001
Train: Epoch[21/60] Total time: 0:00:23 (2.3096 s / it)
Averaged stats: Lr: 0.000188  Loss: 0.9481  Acc@1: 60.9375 (60.0334)  Acc@5: 85.9375 (87.1237)
Train: Epoch[22/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000182  Loss: 0.7926  Acc@1: 64.0625 (64.0625)  Acc@5: 85.9375 (85.9375)  time: 3.3956  data: 0.8840  max mem: 7001
Train: Epoch[22/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000182  Loss: 0.5460  Acc@1: 60.9375 (62.5418)  Acc@5: 89.0625 (88.7960)  time: 2.2767  data: 0.0885  max mem: 7001
Train: Epoch[22/60] Total time: 0:00:22 (2.2853 s / it)
Averaged stats: Lr: 0.000182  Loss: 0.5460  Acc@1: 60.9375 (62.5418)  Acc@5: 89.0625 (88.7960)
Train: Epoch[23/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000176  Loss: 0.6251  Acc@1: 64.0625 (64.0625)  Acc@5: 95.3125 (95.3125)  time: 3.4310  data: 0.8587  max mem: 7001
Train: Epoch[23/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000176  Loss: 0.7686  Acc@1: 64.0625 (64.5485)  Acc@5: 89.0625 (90.3010)  time: 2.2586  data: 0.0860  max mem: 7001
Train: Epoch[23/60] Total time: 0:00:22 (2.2688 s / it)
Averaged stats: Lr: 0.000176  Loss: 0.7686  Acc@1: 64.0625 (64.5485)  Acc@5: 89.0625 (90.3010)
Train: Epoch[24/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000170  Loss: 0.6147  Acc@1: 64.0625 (64.0625)  Acc@5: 92.1875 (92.1875)  time: 3.4142  data: 0.7687  max mem: 7001
Train: Epoch[24/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000170  Loss: 0.8313  Acc@1: 62.5000 (65.2174)  Acc@5: 89.0625 (88.2943)  time: 2.2582  data: 0.0770  max mem: 7001
Train: Epoch[24/60] Total time: 0:00:22 (2.2665 s / it)
Averaged stats: Lr: 0.000170  Loss: 0.8313  Acc@1: 62.5000 (65.2174)  Acc@5: 89.0625 (88.2943)
Train: Epoch[25/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000164  Loss: 0.6892  Acc@1: 67.1875 (67.1875)  Acc@5: 87.5000 (87.5000)  time: 3.4558  data: 0.8008  max mem: 7001
Train: Epoch[25/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000164  Loss: 0.6815  Acc@1: 67.1875 (68.2274)  Acc@5: 89.0625 (88.7960)  time: 2.2653  data: 0.0802  max mem: 7001
Train: Epoch[25/60] Total time: 0:00:22 (2.2756 s / it)
Averaged stats: Lr: 0.000164  Loss: 0.6815  Acc@1: 67.1875 (68.2274)  Acc@5: 89.0625 (88.7960)
Train: Epoch[26/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000157  Loss: 0.7156  Acc@1: 70.3125 (70.3125)  Acc@5: 85.9375 (85.9375)  time: 3.3539  data: 0.7248  max mem: 7001
Train: Epoch[26/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000157  Loss: 0.5892  Acc@1: 70.3125 (70.7358)  Acc@5: 90.6250 (90.4682)  time: 2.2710  data: 0.0726  max mem: 7001
Train: Epoch[26/60] Total time: 0:00:22 (2.2795 s / it)
Averaged stats: Lr: 0.000157  Loss: 0.5892  Acc@1: 70.3125 (70.7358)  Acc@5: 90.6250 (90.4682)
Train: Epoch[27/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000151  Loss: 0.8114  Acc@1: 65.6250 (65.6250)  Acc@5: 79.6875 (79.6875)  time: 3.4529  data: 0.7607  max mem: 7001
Train: Epoch[27/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000151  Loss: 0.8296  Acc@1: 68.7500 (70.7358)  Acc@5: 87.5000 (89.2977)  time: 2.2617  data: 0.0762  max mem: 7001
Train: Epoch[27/60] Total time: 0:00:22 (2.2715 s / it)
Averaged stats: Lr: 0.000151  Loss: 0.8296  Acc@1: 68.7500 (70.7358)  Acc@5: 87.5000 (89.2977)
Train: Epoch[28/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000145  Loss: 0.6489  Acc@1: 73.4375 (73.4375)  Acc@5: 87.5000 (87.5000)  time: 3.5442  data: 0.8864  max mem: 7001
Train: Epoch[28/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000145  Loss: 0.6310  Acc@1: 73.4375 (72.4080)  Acc@5: 90.6250 (90.9699)  time: 2.2765  data: 0.0888  max mem: 7001
Train: Epoch[28/60] Total time: 0:00:22 (2.2843 s / it)
Averaged stats: Lr: 0.000145  Loss: 0.6310  Acc@1: 73.4375 (72.4080)  Acc@5: 90.6250 (90.9699)
Train: Epoch[29/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000138  Loss: 0.6436  Acc@1: 73.4375 (73.4375)  Acc@5: 89.0625 (89.0625)  time: 3.3869  data: 0.7433  max mem: 7001
Train: Epoch[29/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000138  Loss: 0.6098  Acc@1: 72.7273 (71.0702)  Acc@5: 89.0625 (89.9666)  time: 2.2549  data: 0.0745  max mem: 7001
Train: Epoch[29/60] Total time: 0:00:22 (2.2651 s / it)
Averaged stats: Lr: 0.000138  Loss: 0.6098  Acc@1: 72.7273 (71.0702)  Acc@5: 89.0625 (89.9666)
Train: Epoch[30/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000132  Loss: 0.6039  Acc@1: 73.4375 (73.4375)  Acc@5: 90.6250 (90.6250)  time: 3.4237  data: 0.7276  max mem: 7001
Train: Epoch[30/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000132  Loss: 0.7171  Acc@1: 70.3125 (69.0635)  Acc@5: 86.3636 (88.4615)  time: 2.2625  data: 0.0729  max mem: 7001
Train: Epoch[30/60] Total time: 0:00:22 (2.2706 s / it)
Averaged stats: Lr: 0.000132  Loss: 0.7171  Acc@1: 70.3125 (69.0635)  Acc@5: 86.3636 (88.4615)
Train: Epoch[31/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000125  Loss: 0.7119  Acc@1: 75.0000 (75.0000)  Acc@5: 85.9375 (85.9375)  time: 3.6496  data: 0.8404  max mem: 7001
Train: Epoch[31/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000125  Loss: 0.8471  Acc@1: 70.3125 (71.0702)  Acc@5: 90.6250 (90.6355)  time: 2.2962  data: 0.0842  max mem: 7001
Train: Epoch[31/60] Total time: 0:00:23 (2.3082 s / it)
Averaged stats: Lr: 0.000125  Loss: 0.8471  Acc@1: 70.3125 (71.0702)  Acc@5: 90.6250 (90.6355)
Train: Epoch[32/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000118  Loss: 0.6815  Acc@1: 67.1875 (67.1875)  Acc@5: 87.5000 (87.5000)  time: 3.4709  data: 0.7790  max mem: 7001
Train: Epoch[32/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000118  Loss: 0.9898  Acc@1: 67.1875 (67.7258)  Acc@5: 89.0625 (88.7960)  time: 2.2646  data: 0.0780  max mem: 7001
Train: Epoch[32/60] Total time: 0:00:22 (2.2729 s / it)
Averaged stats: Lr: 0.000118  Loss: 0.9898  Acc@1: 67.1875 (67.7258)  Acc@5: 89.0625 (88.7960)
Train: Epoch[33/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000112  Loss: 0.6293  Acc@1: 64.0625 (64.0625)  Acc@5: 87.5000 (87.5000)  time: 3.3837  data: 0.7348  max mem: 7001
Train: Epoch[33/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000112  Loss: 0.4078  Acc@1: 71.8750 (73.0769)  Acc@5: 87.5000 (90.3010)  time: 2.2555  data: 0.0736  max mem: 7001
Train: Epoch[33/60] Total time: 0:00:22 (2.2655 s / it)
Averaged stats: Lr: 0.000112  Loss: 0.4078  Acc@1: 71.8750 (73.0769)  Acc@5: 87.5000 (90.3010)
Train: Epoch[34/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000105  Loss: 0.6542  Acc@1: 71.8750 (71.8750)  Acc@5: 87.5000 (87.5000)  time: 3.3495  data: 0.8909  max mem: 7001
Train: Epoch[34/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000105  Loss: 0.5505  Acc@1: 70.3125 (72.4080)  Acc@5: 89.0625 (90.1338)  time: 2.2509  data: 0.0892  max mem: 7001
Train: Epoch[34/60] Total time: 0:00:22 (2.2590 s / it)
Averaged stats: Lr: 0.000105  Loss: 0.5505  Acc@1: 70.3125 (72.4080)  Acc@5: 89.0625 (90.1338)
Train: Epoch[35/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000099  Loss: 0.4875  Acc@1: 76.5625 (76.5625)  Acc@5: 93.7500 (93.7500)  time: 3.5410  data: 0.7416  max mem: 7001
Train: Epoch[35/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000099  Loss: 0.5588  Acc@1: 73.4375 (75.2508)  Acc@5: 90.9091 (90.9699)  time: 2.2664  data: 0.0743  max mem: 7001
Train: Epoch[35/60] Total time: 0:00:22 (2.2750 s / it)
Averaged stats: Lr: 0.000099  Loss: 0.5588  Acc@1: 73.4375 (75.2508)  Acc@5: 90.9091 (90.9699)
Train: Epoch[36/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000093  Loss: 0.5633  Acc@1: 71.8750 (71.8750)  Acc@5: 92.1875 (92.1875)  time: 3.3420  data: 0.8689  max mem: 7001
Train: Epoch[36/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000093  Loss: 0.4389  Acc@1: 71.8750 (71.7391)  Acc@5: 85.9375 (88.6288)  time: 2.2406  data: 0.0870  max mem: 7001
Train: Epoch[36/60] Total time: 0:00:22 (2.2484 s / it)
Averaged stats: Lr: 0.000093  Loss: 0.4389  Acc@1: 71.8750 (71.7391)  Acc@5: 85.9375 (88.6288)
Train: Epoch[37/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000086  Loss: 0.5033  Acc@1: 73.4375 (73.4375)  Acc@5: 96.8750 (96.8750)  time: 3.2745  data: 0.7310  max mem: 7001
Train: Epoch[37/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000086  Loss: 0.8261  Acc@1: 70.3125 (72.0736)  Acc@5: 89.0625 (89.7993)  time: 2.2317  data: 0.0732  max mem: 7001
Train: Epoch[37/60] Total time: 0:00:22 (2.2414 s / it)
Averaged stats: Lr: 0.000086  Loss: 0.8261  Acc@1: 70.3125 (72.0736)  Acc@5: 89.0625 (89.7993)
Train: Epoch[38/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000080  Loss: 0.4517  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 3.4482  data: 0.8678  max mem: 7001
Train: Epoch[38/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000080  Loss: 0.5737  Acc@1: 73.4375 (74.4147)  Acc@5: 92.1875 (91.6388)  time: 2.2633  data: 0.0869  max mem: 7001
Train: Epoch[38/60] Total time: 0:00:22 (2.2723 s / it)
Averaged stats: Lr: 0.000080  Loss: 0.5737  Acc@1: 73.4375 (74.4147)  Acc@5: 92.1875 (91.6388)
Train: Epoch[39/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000074  Loss: 0.4698  Acc@1: 79.6875 (79.6875)  Acc@5: 92.1875 (92.1875)  time: 3.4031  data: 0.8255  max mem: 7001
Train: Epoch[39/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000074  Loss: 0.3362  Acc@1: 73.4375 (74.9164)  Acc@5: 92.1875 (90.9699)  time: 2.2734  data: 0.0827  max mem: 7001
Train: Epoch[39/60] Total time: 0:00:22 (2.2825 s / it)
Averaged stats: Lr: 0.000074  Loss: 0.3362  Acc@1: 73.4375 (74.9164)  Acc@5: 92.1875 (90.9699)
Train: Epoch[40/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000068  Loss: 0.5344  Acc@1: 70.3125 (70.3125)  Acc@5: 92.1875 (92.1875)  time: 3.2943  data: 0.6928  max mem: 7001
Train: Epoch[40/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000068  Loss: 0.6009  Acc@1: 76.5625 (77.2575)  Acc@5: 90.6250 (90.6355)  time: 2.2352  data: 0.0694  max mem: 7001
Train: Epoch[40/60] Total time: 0:00:22 (2.2440 s / it)
Averaged stats: Lr: 0.000068  Loss: 0.6009  Acc@1: 76.5625 (77.2575)  Acc@5: 90.6250 (90.6355)
Train: Epoch[41/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000063  Loss: 0.5496  Acc@1: 75.0000 (75.0000)  Acc@5: 89.0625 (89.0625)  time: 3.2944  data: 0.6706  max mem: 7001
Train: Epoch[41/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000063  Loss: 0.4375  Acc@1: 75.0000 (74.4147)  Acc@5: 90.6250 (90.6355)  time: 2.2350  data: 0.0672  max mem: 7001
Train: Epoch[41/60] Total time: 0:00:22 (2.2455 s / it)
Averaged stats: Lr: 0.000063  Loss: 0.4375  Acc@1: 75.0000 (74.4147)  Acc@5: 90.6250 (90.6355)
Train: Epoch[42/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000057  Loss: 0.5690  Acc@1: 75.0000 (75.0000)  Acc@5: 85.9375 (85.9375)  time: 3.2407  data: 0.7036  max mem: 7001
Train: Epoch[42/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000057  Loss: 0.2817  Acc@1: 78.1250 (77.5920)  Acc@5: 90.6250 (91.6388)  time: 2.2456  data: 0.0705  max mem: 7001
Train: Epoch[42/60] Total time: 0:00:22 (2.2537 s / it)
Averaged stats: Lr: 0.000057  Loss: 0.2817  Acc@1: 78.1250 (77.5920)  Acc@5: 90.6250 (91.6388)
Train: Epoch[43/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000052  Loss: 0.3707  Acc@1: 81.2500 (81.2500)  Acc@5: 96.8750 (96.8750)  time: 3.4168  data: 0.8082  max mem: 7001
Train: Epoch[43/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000052  Loss: 0.5744  Acc@1: 78.1250 (79.4314)  Acc@5: 90.6250 (91.9732)  time: 2.2773  data: 0.0810  max mem: 7001
Train: Epoch[43/60] Total time: 0:00:22 (2.2893 s / it)
Averaged stats: Lr: 0.000052  Loss: 0.5744  Acc@1: 78.1250 (79.4314)  Acc@5: 90.6250 (91.9732)
Train: Epoch[44/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000046  Loss: 0.3969  Acc@1: 82.8125 (82.8125)  Acc@5: 95.3125 (95.3125)  time: 3.3173  data: 0.6851  max mem: 7001
Train: Epoch[44/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000046  Loss: 0.6465  Acc@1: 75.0000 (76.5886)  Acc@5: 90.6250 (91.9732)  time: 2.2368  data: 0.0686  max mem: 7001
Train: Epoch[44/60] Total time: 0:00:22 (2.2448 s / it)
Averaged stats: Lr: 0.000046  Loss: 0.6465  Acc@1: 75.0000 (76.5886)  Acc@5: 90.6250 (91.9732)
Train: Epoch[45/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000041  Loss: 0.5035  Acc@1: 79.6875 (79.6875)  Acc@5: 89.0625 (89.0625)  time: 3.2733  data: 0.6739  max mem: 7001
Train: Epoch[45/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000041  Loss: 0.5252  Acc@1: 75.0000 (76.2542)  Acc@5: 92.1875 (92.3077)  time: 2.2354  data: 0.0675  max mem: 7001
Train: Epoch[45/60] Total time: 0:00:22 (2.2441 s / it)
Averaged stats: Lr: 0.000041  Loss: 0.5252  Acc@1: 75.0000 (76.2542)  Acc@5: 92.1875 (92.3077)
Train: Epoch[46/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000037  Loss: 0.5753  Acc@1: 75.0000 (75.0000)  Acc@5: 90.6250 (90.6250)  time: 3.2446  data: 0.7114  max mem: 7001
Train: Epoch[46/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000037  Loss: 0.3240  Acc@1: 76.5625 (76.4214)  Acc@5: 92.1875 (91.6388)  time: 2.2286  data: 0.0713  max mem: 7001
Train: Epoch[46/60] Total time: 0:00:22 (2.2365 s / it)
Averaged stats: Lr: 0.000037  Loss: 0.3240  Acc@1: 76.5625 (76.4214)  Acc@5: 92.1875 (91.6388)
Train: Epoch[47/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000032  Loss: 0.3592  Acc@1: 78.1250 (78.1250)  Acc@5: 96.8750 (96.8750)  time: 3.2545  data: 0.6833  max mem: 7001
Train: Epoch[47/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000032  Loss: 0.5852  Acc@1: 76.5625 (77.4247)  Acc@5: 92.1875 (92.4749)  time: 2.2523  data: 0.0684  max mem: 7001
Train: Epoch[47/60] Total time: 0:00:22 (2.2618 s / it)
Averaged stats: Lr: 0.000032  Loss: 0.5852  Acc@1: 76.5625 (77.4247)  Acc@5: 92.1875 (92.4749)
Train: Epoch[48/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000028  Loss: 0.3589  Acc@1: 79.6875 (79.6875)  Acc@5: 92.1875 (92.1875)  time: 3.4142  data: 0.9095  max mem: 7001
Train: Epoch[48/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000028  Loss: 0.4602  Acc@1: 76.5625 (76.2542)  Acc@5: 92.1875 (90.9699)  time: 2.2470  data: 0.0911  max mem: 7001
Train: Epoch[48/60] Total time: 0:00:22 (2.2549 s / it)
Averaged stats: Lr: 0.000028  Loss: 0.4602  Acc@1: 76.5625 (76.2542)  Acc@5: 92.1875 (90.9699)
Train: Epoch[49/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000024  Loss: 0.5573  Acc@1: 70.3125 (70.3125)  Acc@5: 85.9375 (85.9375)  time: 3.3232  data: 0.7267  max mem: 7001
Train: Epoch[49/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000024  Loss: 0.5326  Acc@1: 76.5625 (77.4247)  Acc@5: 90.9091 (90.3010)  time: 2.2398  data: 0.0728  max mem: 7001
Train: Epoch[49/60] Total time: 0:00:22 (2.2495 s / it)
Averaged stats: Lr: 0.000024  Loss: 0.5326  Acc@1: 76.5625 (77.4247)  Acc@5: 90.9091 (90.3010)
Train: Epoch[50/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000020  Loss: 0.3902  Acc@1: 81.2500 (81.2500)  Acc@5: 92.1875 (92.1875)  time: 3.3016  data: 0.7249  max mem: 7001
Train: Epoch[50/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000020  Loss: 0.5377  Acc@1: 78.1250 (77.2575)  Acc@5: 92.1875 (91.6388)  time: 2.2394  data: 0.0726  max mem: 7001
Train: Epoch[50/60] Total time: 0:00:22 (2.2470 s / it)
Averaged stats: Lr: 0.000020  Loss: 0.5377  Acc@1: 78.1250 (77.2575)  Acc@5: 92.1875 (91.6388)
Train: Epoch[51/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000017  Loss: 0.5831  Acc@1: 78.1250 (78.1250)  Acc@5: 85.9375 (85.9375)  time: 3.3808  data: 0.8437  max mem: 7001
Train: Epoch[51/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000017  Loss: 0.3977  Acc@1: 78.1250 (78.4281)  Acc@5: 90.6250 (91.3043)  time: 2.2672  data: 0.0845  max mem: 7001
Train: Epoch[51/60] Total time: 0:00:22 (2.2780 s / it)
Averaged stats: Lr: 0.000017  Loss: 0.3977  Acc@1: 78.1250 (78.4281)  Acc@5: 90.6250 (91.3043)
Train: Epoch[52/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000014  Loss: 0.5213  Acc@1: 71.8750 (71.8750)  Acc@5: 87.5000 (87.5000)  time: 3.3645  data: 0.7853  max mem: 7001
Train: Epoch[52/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000014  Loss: 0.3315  Acc@1: 75.0000 (76.7559)  Acc@5: 90.6250 (91.4716)  time: 2.2521  data: 0.0787  max mem: 7001
Train: Epoch[52/60] Total time: 0:00:22 (2.2605 s / it)
Averaged stats: Lr: 0.000014  Loss: 0.3315  Acc@1: 75.0000 (76.7559)  Acc@5: 90.6250 (91.4716)
Train: Epoch[53/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000011  Loss: 0.6768  Acc@1: 73.4375 (73.4375)  Acc@5: 84.3750 (84.3750)  time: 3.3996  data: 0.8731  max mem: 7001
Train: Epoch[53/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000011  Loss: 0.5735  Acc@1: 75.0000 (76.7559)  Acc@5: 90.6250 (90.9699)  time: 2.2467  data: 0.0874  max mem: 7001
Train: Epoch[53/60] Total time: 0:00:22 (2.2558 s / it)
Averaged stats: Lr: 0.000011  Loss: 0.5735  Acc@1: 75.0000 (76.7559)  Acc@5: 90.6250 (90.9699)
Train: Epoch[54/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000008  Loss: 0.3263  Acc@1: 85.9375 (85.9375)  Acc@5: 93.7500 (93.7500)  time: 3.2805  data: 0.7361  max mem: 7001
Train: Epoch[54/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000008  Loss: 0.2934  Acc@1: 76.5625 (77.0903)  Acc@5: 90.6250 (90.6355)  time: 2.2350  data: 0.0737  max mem: 7001
Train: Epoch[54/60] Total time: 0:00:22 (2.2430 s / it)
Averaged stats: Lr: 0.000008  Loss: 0.2934  Acc@1: 76.5625 (77.0903)  Acc@5: 90.6250 (90.6355)
Train: Epoch[55/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000006  Loss: 0.4799  Acc@1: 71.8750 (71.8750)  Acc@5: 87.5000 (87.5000)  time: 3.3262  data: 0.7058  max mem: 7001
Train: Epoch[55/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000006  Loss: 0.5703  Acc@1: 76.5625 (75.2508)  Acc@5: 90.6250 (90.8027)  time: 2.2372  data: 0.0707  max mem: 7001
Train: Epoch[55/60] Total time: 0:00:22 (2.2466 s / it)
Averaged stats: Lr: 0.000006  Loss: 0.5703  Acc@1: 76.5625 (75.2508)  Acc@5: 90.6250 (90.8027)
Train: Epoch[56/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000004  Loss: 0.7278  Acc@1: 71.8750 (71.8750)  Acc@5: 84.3750 (84.3750)  time: 3.4704  data: 0.6814  max mem: 7001
Train: Epoch[56/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000004  Loss: 0.2481  Acc@1: 76.5625 (77.5920)  Acc@5: 92.1875 (91.9732)  time: 2.2533  data: 0.0683  max mem: 7001
Train: Epoch[56/60] Total time: 0:00:22 (2.2614 s / it)
Averaged stats: Lr: 0.000004  Loss: 0.2481  Acc@1: 76.5625 (77.5920)  Acc@5: 92.1875 (91.9732)
Train: Epoch[57/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000003  Loss: 0.4823  Acc@1: 70.3125 (70.3125)  Acc@5: 89.0625 (89.0625)  time: 3.3679  data: 0.7031  max mem: 7001
Train: Epoch[57/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000003  Loss: 0.3780  Acc@1: 81.2500 (80.9365)  Acc@5: 93.7500 (93.9799)  time: 2.2415  data: 0.0704  max mem: 7001
Train: Epoch[57/60] Total time: 0:00:22 (2.2513 s / it)
Averaged stats: Lr: 0.000003  Loss: 0.3780  Acc@1: 81.2500 (80.9365)  Acc@5: 93.7500 (93.9799)
Train: Epoch[58/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000002  Loss: 0.4844  Acc@1: 75.0000 (75.0000)  Acc@5: 95.3125 (95.3125)  time: 3.3489  data: 0.7624  max mem: 7001
Train: Epoch[58/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000002  Loss: 0.2219  Acc@1: 78.1250 (78.5953)  Acc@5: 90.6250 (91.9732)  time: 2.2431  data: 0.0764  max mem: 7001
Train: Epoch[58/60] Total time: 0:00:22 (2.2511 s / it)
Averaged stats: Lr: 0.000002  Loss: 0.2219  Acc@1: 78.1250 (78.5953)  Acc@5: 90.6250 (91.9732)
Train: Epoch[59/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000001  Loss: 0.2880  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)  time: 3.3341  data: 0.7047  max mem: 7001
Train: Epoch[59/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000001  Loss: 0.4028  Acc@1: 76.5625 (75.4181)  Acc@5: 92.1875 (91.6388)  time: 2.2358  data: 0.0706  max mem: 7001
Train: Epoch[59/60] Total time: 0:00:22 (2.2454 s / it)
Averaged stats: Lr: 0.000001  Loss: 0.4028  Acc@1: 76.5625 (75.4181)  Acc@5: 92.1875 (91.6388)
Train: Epoch[60/60]  [ 0/10]  eta: 0:00:32  Lr: 0.000000  Loss: 0.3611  Acc@1: 76.5625 (76.5625)  Acc@5: 90.6250 (90.6250)  time: 3.2895  data: 0.7309  max mem: 7001
Train: Epoch[60/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000000  Loss: 0.5372  Acc@1: 75.0000 (75.5853)  Acc@5: 90.6250 (90.6355)  time: 2.2574  data: 0.0732  max mem: 7001
Train: Epoch[60/60] Total time: 0:00:22 (2.2658 s / it)
Averaged stats: Lr: 0.000000  Loss: 0.5372  Acc@1: 75.0000 (75.5853)  Acc@5: 90.6250 (90.6355)
Test: [Task 1]  [0/9]  eta: 0:00:15  Loss: 0.4142 (0.4142)  Acc@1: 93.7500 (93.7500)  Acc@5: 98.4375 (98.4375)  time: 1.7573  data: 0.8862  max mem: 7001
Test: [Task 1]  [8/9]  eta: 0:00:00  Loss: 0.2419 (0.2981)  Acc@1: 96.8750 (92.2330)  Acc@5: 100.0000 (99.0291)  time: 0.7407  data: 0.0987  max mem: 7001
Test: [Task 1] Total time: 0:00:06 (0.7494 s / it)
* Acc@1 92.233 Acc@5 99.029 loss 0.298
Batchwise eval time for task 1 = 0.7493971718682183
Test: [Task 2]  [0/9]  eta: 0:00:16  Loss: 0.5996 (0.5996)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 1.8356  data: 0.9605  max mem: 7001
Test: [Task 2]  [8/9]  eta: 0:00:00  Loss: 1.1175 (1.0501)  Acc@1: 57.8125 (64.8696)  Acc@5: 98.4375 (98.2609)  time: 0.7985  data: 0.1069  max mem: 7001
Test: [Task 2] Total time: 0:00:07 (0.8073 s / it)
* Acc@1 64.870 Acc@5 98.261 loss 1.050
Batchwise eval time for task 2 = 0.8072853088378906
Test: [Task 3]  [ 0/10]  eta: 0:00:17  Loss: 0.3518 (0.3518)  Acc@1: 95.3125 (95.3125)  Acc@5: 98.4375 (98.4375)  time: 1.7507  data: 0.9755  max mem: 7001
Test: [Task 3]  [ 9/10]  eta: 0:00:00  Loss: 0.4062 (0.5890)  Acc@1: 93.7500 (90.4362)  Acc@5: 98.4375 (98.8255)  time: 0.7430  data: 0.0978  max mem: 7001
Test: [Task 3] Total time: 0:00:07 (0.7510 s / it)
* Acc@1 90.436 Acc@5 98.826 loss 0.589
Batchwise eval time for task 3 = 0.7510681629180909
Test: [Task 4]  [ 0/10]  eta: 0:00:18  Loss: 1.2529 (1.2529)  Acc@1: 57.8125 (57.8125)  Acc@5: 95.3125 (95.3125)  time: 1.8704  data: 0.9885  max mem: 7001
Test: [Task 4]  [ 9/10]  eta: 0:00:00  Loss: 0.6950 (0.7612)  Acc@1: 85.9375 (80.3754)  Acc@5: 98.4375 (98.8055)  time: 0.7489  data: 0.0990  max mem: 7001
Test: [Task 4] Total time: 0:00:07 (0.7572 s / it)
* Acc@1 80.375 Acc@5 98.805 loss 0.761
Batchwise eval time for task 4 = 0.7572509527206421
Test: [Task 5]  [ 0/10]  eta: 0:00:17  Loss: 0.5046 (0.5046)  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)  time: 1.7225  data: 0.8923  max mem: 7001
Test: [Task 5]  [ 9/10]  eta: 0:00:00  Loss: 0.3779 (0.4619)  Acc@1: 92.1875 (93.7500)  Acc@5: 98.4375 (98.3108)  time: 0.7402  data: 0.0894  max mem: 7001
Test: [Task 5] Total time: 0:00:07 (0.7482 s / it)
* Acc@1 93.750 Acc@5 98.311 loss 0.462
Batchwise eval time for task 5 = 0.7482435464859009
Test: [Task 6]  [0/9]  eta: 0:00:16  Loss: 0.6893 (0.6893)  Acc@1: 85.9375 (85.9375)  Acc@5: 98.4375 (98.4375)  time: 1.8710  data: 0.9557  max mem: 7001
Test: [Task 6]  [8/9]  eta: 0:00:00  Loss: 0.7543 (0.7942)  Acc@1: 85.9375 (85.6890)  Acc@5: 98.4375 (98.0565)  time: 0.7958  data: 0.1064  max mem: 7001
Test: [Task 6] Total time: 0:00:07 (0.8053 s / it)
* Acc@1 85.689 Acc@5 98.057 loss 0.794
Batchwise eval time for task 6 = 0.8053696950276693
Test: [Task 7]  [ 0/10]  eta: 0:00:18  Loss: 1.1211 (1.1211)  Acc@1: 79.6875 (79.6875)  Acc@5: 98.4375 (98.4375)  time: 1.8802  data: 0.9146  max mem: 7001
Test: [Task 7]  [ 9/10]  eta: 0:00:00  Loss: 0.7440 (0.9461)  Acc@1: 79.6875 (80.7692)  Acc@5: 96.8750 (96.8227)  time: 0.7576  data: 0.0917  max mem: 7001
Test: [Task 7] Total time: 0:00:07 (0.7657 s / it)
* Acc@1 80.769 Acc@5 96.823 loss 0.946
Batchwise eval time for task 7 = 0.7656834363937378
[Average accuracy till task7]	Acc@1: 83.9374	Acc@5: 98.3016	Loss: 0.7001	Forgetting: 4.1417	Backward: -4.1417
Eval time for task 7 = 51.7158944606781
Using adam optimizer
Reinitialising optimizer
Similarity:  tensor(0.9034)  Task:  7
Old Num K:  11 New Num K:  12
Task number:  7
Train: Epoch[ 1/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000250  Loss: 3.2729  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  time: 3.5479  data: 0.7620  max mem: 7043
Train: Epoch[ 1/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000250  Loss: 3.5540  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  time: 2.3866  data: 0.0763  max mem: 7053
Train: Epoch[ 1/60] Total time: 0:00:23 (2.3972 s / it)
Averaged stats: Lr: 0.000250  Loss: 3.5540  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)
Train: Epoch[ 2/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000250  Loss: 3.1895  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  time: 3.4788  data: 0.8020  max mem: 7053
Train: Epoch[ 2/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000250  Loss: 2.5753  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (1.1686)  time: 2.3775  data: 0.0803  max mem: 7053
Train: Epoch[ 2/60] Total time: 0:00:23 (2.3857 s / it)
Averaged stats: Lr: 0.000250  Loss: 2.5753  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (1.1686)
Train: Epoch[ 3/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000249  Loss: 2.4868  Acc@1: 0.0000 (0.0000)  Acc@5: 4.6875 (4.6875)  time: 3.6098  data: 0.9154  max mem: 7053
Train: Epoch[ 3/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000249  Loss: 2.2701  Acc@1: 0.0000 (0.1669)  Acc@5: 4.6875 (6.3439)  time: 2.3895  data: 0.0917  max mem: 7053
Train: Epoch[ 3/60] Total time: 0:00:23 (2.3985 s / it)
Averaged stats: Lr: 0.000249  Loss: 2.2701  Acc@1: 0.0000 (0.1669)  Acc@5: 4.6875 (6.3439)
Train: Epoch[ 4/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000248  Loss: 2.2171  Acc@1: 0.0000 (0.0000)  Acc@5: 9.3750 (9.3750)  time: 3.7280  data: 0.8154  max mem: 7053
Train: Epoch[ 4/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000248  Loss: 1.8974  Acc@1: 0.0000 (0.6678)  Acc@5: 17.3913 (21.0351)  time: 2.4028  data: 0.0817  max mem: 7053
Train: Epoch[ 4/60] Total time: 0:00:24 (2.4113 s / it)
Averaged stats: Lr: 0.000248  Loss: 1.8974  Acc@1: 0.0000 (0.6678)  Acc@5: 17.3913 (21.0351)
Train: Epoch[ 5/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000247  Loss: 1.7967  Acc@1: 3.1250 (3.1250)  Acc@5: 29.6875 (29.6875)  time: 3.5022  data: 0.7681  max mem: 7053
Train: Epoch[ 5/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000247  Loss: 1.5384  Acc@1: 4.6875 (6.1770)  Acc@5: 39.0625 (37.2287)  time: 2.3796  data: 0.0769  max mem: 7053
Train: Epoch[ 5/60] Total time: 0:00:23 (2.3888 s / it)
Averaged stats: Lr: 0.000247  Loss: 1.5384  Acc@1: 4.6875 (6.1770)  Acc@5: 39.0625 (37.2287)
Train: Epoch[ 6/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000246  Loss: 1.7524  Acc@1: 7.8125 (7.8125)  Acc@5: 40.6250 (40.6250)  time: 3.5145  data: 0.8105  max mem: 7053
Train: Epoch[ 6/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000246  Loss: 1.5133  Acc@1: 12.5000 (11.6861)  Acc@5: 48.4375 (48.2471)  time: 2.3784  data: 0.0812  max mem: 7053
Train: Epoch[ 6/60] Total time: 0:00:23 (2.3865 s / it)
Averaged stats: Lr: 0.000246  Loss: 1.5133  Acc@1: 12.5000 (11.6861)  Acc@5: 48.4375 (48.2471)
Train: Epoch[ 7/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000244  Loss: 1.5778  Acc@1: 26.5625 (26.5625)  Acc@5: 56.2500 (56.2500)  time: 3.5284  data: 0.7727  max mem: 7053
Train: Epoch[ 7/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000244  Loss: 1.2542  Acc@1: 15.6250 (17.3623)  Acc@5: 59.3750 (60.6010)  time: 2.4041  data: 0.0774  max mem: 7053
Train: Epoch[ 7/60] Total time: 0:00:24 (2.4157 s / it)
Averaged stats: Lr: 0.000244  Loss: 1.2542  Acc@1: 15.6250 (17.3623)  Acc@5: 59.3750 (60.6010)
Train: Epoch[ 8/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000242  Loss: 1.4706  Acc@1: 18.7500 (18.7500)  Acc@5: 57.8125 (57.8125)  time: 3.4888  data: 0.7364  max mem: 7053
Train: Epoch[ 8/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000242  Loss: 1.4825  Acc@1: 18.7500 (20.2003)  Acc@5: 64.0625 (65.9432)  time: 2.3795  data: 0.0738  max mem: 7053
Train: Epoch[ 8/60] Total time: 0:00:23 (2.3879 s / it)
Averaged stats: Lr: 0.000242  Loss: 1.4825  Acc@1: 18.7500 (20.2003)  Acc@5: 64.0625 (65.9432)
Train: Epoch[ 9/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000239  Loss: 1.3365  Acc@1: 15.6250 (15.6250)  Acc@5: 73.4375 (73.4375)  time: 3.5587  data: 0.9050  max mem: 7053
Train: Epoch[ 9/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000239  Loss: 1.2538  Acc@1: 26.0870 (25.2087)  Acc@5: 68.7500 (70.1169)  time: 2.3837  data: 0.0906  max mem: 7053
Train: Epoch[ 9/60] Total time: 0:00:23 (2.3934 s / it)
Averaged stats: Lr: 0.000239  Loss: 1.2538  Acc@1: 26.0870 (25.2087)  Acc@5: 68.7500 (70.1169)
Train: Epoch[10/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000236  Loss: 1.3733  Acc@1: 21.8750 (21.8750)  Acc@5: 71.8750 (71.8750)  time: 3.4647  data: 0.7951  max mem: 7053
Train: Epoch[10/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000236  Loss: 1.0955  Acc@1: 28.1250 (27.8798)  Acc@5: 73.9130 (75.4591)  time: 2.3759  data: 0.0796  max mem: 7053
Train: Epoch[10/60] Total time: 0:00:23 (2.3844 s / it)
Averaged stats: Lr: 0.000236  Loss: 1.0955  Acc@1: 28.1250 (27.8798)  Acc@5: 73.9130 (75.4591)
Train: Epoch[11/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000233  Loss: 1.3190  Acc@1: 34.3750 (34.3750)  Acc@5: 68.7500 (68.7500)  time: 3.6724  data: 0.8488  max mem: 7053
Train: Epoch[11/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000233  Loss: 1.1976  Acc@1: 31.2500 (32.5543)  Acc@5: 75.0000 (75.4591)  time: 2.3945  data: 0.0850  max mem: 7053
Train: Epoch[11/60] Total time: 0:00:24 (2.4050 s / it)
Averaged stats: Lr: 0.000233  Loss: 1.1976  Acc@1: 31.2500 (32.5543)  Acc@5: 75.0000 (75.4591)
Train: Epoch[12/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000230  Loss: 1.3126  Acc@1: 35.9375 (35.9375)  Acc@5: 71.8750 (71.8750)  time: 3.5023  data: 0.8317  max mem: 7053
Train: Epoch[12/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000230  Loss: 1.3684  Acc@1: 32.8125 (35.7262)  Acc@5: 79.6875 (79.1319)  time: 2.3825  data: 0.0833  max mem: 7053
Train: Epoch[12/60] Total time: 0:00:23 (2.3909 s / it)
Averaged stats: Lr: 0.000230  Loss: 1.3684  Acc@1: 32.8125 (35.7262)  Acc@5: 79.6875 (79.1319)
Train: Epoch[13/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000226  Loss: 0.8726  Acc@1: 43.7500 (43.7500)  Acc@5: 87.5000 (87.5000)  time: 3.5973  data: 0.8304  max mem: 7053
Train: Epoch[13/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000226  Loss: 0.9410  Acc@1: 35.9375 (38.8982)  Acc@5: 84.3750 (83.9733)  time: 2.3924  data: 0.0832  max mem: 7053
Train: Epoch[13/60] Total time: 0:00:24 (2.4031 s / it)
Averaged stats: Lr: 0.000226  Loss: 0.9410  Acc@1: 35.9375 (38.8982)  Acc@5: 84.3750 (83.9733)
Train: Epoch[14/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000222  Loss: 1.2241  Acc@1: 35.9375 (35.9375)  Acc@5: 76.5625 (76.5625)  time: 3.5023  data: 0.8083  max mem: 7053
Train: Epoch[14/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000222  Loss: 1.1086  Acc@1: 37.5000 (39.2321)  Acc@5: 82.8125 (82.6377)  time: 2.4037  data: 0.0810  max mem: 7053
Train: Epoch[14/60] Total time: 0:00:24 (2.4125 s / it)
Averaged stats: Lr: 0.000222  Loss: 1.1086  Acc@1: 37.5000 (39.2321)  Acc@5: 82.8125 (82.6377)
Train: Epoch[15/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000218  Loss: 0.9205  Acc@1: 54.6875 (54.6875)  Acc@5: 87.5000 (87.5000)  time: 3.5989  data: 0.8057  max mem: 7053
Train: Epoch[15/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000218  Loss: 0.9656  Acc@1: 39.1304 (42.2371)  Acc@5: 84.3750 (85.1419)  time: 2.3927  data: 0.0807  max mem: 7053
Train: Epoch[15/60] Total time: 0:00:24 (2.4020 s / it)
Averaged stats: Lr: 0.000218  Loss: 0.9656  Acc@1: 39.1304 (42.2371)  Acc@5: 84.3750 (85.1419)
Train: Epoch[16/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000213  Loss: 1.0529  Acc@1: 43.7500 (43.7500)  Acc@5: 87.5000 (87.5000)  time: 3.4755  data: 0.7486  max mem: 7053
Train: Epoch[16/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000213  Loss: 1.1434  Acc@1: 42.1875 (42.2371)  Acc@5: 85.9375 (84.3072)  time: 2.3716  data: 0.0750  max mem: 7053
Train: Epoch[16/60] Total time: 0:00:23 (2.3799 s / it)
Averaged stats: Lr: 0.000213  Loss: 1.1434  Acc@1: 42.1875 (42.2371)  Acc@5: 85.9375 (84.3072)
Train: Epoch[17/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000209  Loss: 0.9247  Acc@1: 50.0000 (50.0000)  Acc@5: 90.6250 (90.6250)  time: 3.5393  data: 0.7348  max mem: 7053
Train: Epoch[17/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000209  Loss: 1.0460  Acc@1: 45.3125 (47.5793)  Acc@5: 85.9375 (85.6427)  time: 2.3816  data: 0.0736  max mem: 7053
Train: Epoch[17/60] Total time: 0:00:23 (2.3920 s / it)
Averaged stats: Lr: 0.000209  Loss: 1.0460  Acc@1: 45.3125 (47.5793)  Acc@5: 85.9375 (85.6427)
Train: Epoch[18/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000204  Loss: 0.9592  Acc@1: 45.3125 (45.3125)  Acc@5: 84.3750 (84.3750)  time: 3.4872  data: 0.7758  max mem: 7053
Train: Epoch[18/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000204  Loss: 1.0954  Acc@1: 48.4375 (49.5826)  Acc@5: 87.5000 (87.1452)  time: 2.3933  data: 0.0777  max mem: 7053
Train: Epoch[18/60] Total time: 0:00:24 (2.4018 s / it)
Averaged stats: Lr: 0.000204  Loss: 1.0954  Acc@1: 48.4375 (49.5826)  Acc@5: 87.5000 (87.1452)
Train: Epoch[19/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000198  Loss: 0.7563  Acc@1: 48.4375 (48.4375)  Acc@5: 85.9375 (85.9375)  time: 3.5573  data: 0.8741  max mem: 7053
Train: Epoch[19/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000198  Loss: 1.1026  Acc@1: 48.4375 (49.7496)  Acc@5: 84.3750 (85.3088)  time: 2.3774  data: 0.0875  max mem: 7053
Train: Epoch[19/60] Total time: 0:00:23 (2.3882 s / it)
Averaged stats: Lr: 0.000198  Loss: 1.1026  Acc@1: 48.4375 (49.7496)  Acc@5: 84.3750 (85.3088)
Train: Epoch[20/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000193  Loss: 0.7977  Acc@1: 65.6250 (65.6250)  Acc@5: 89.0625 (89.0625)  time: 3.5330  data: 0.8790  max mem: 7053
Train: Epoch[20/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000193  Loss: 0.8666  Acc@1: 51.5625 (54.4240)  Acc@5: 89.0625 (88.6477)  time: 2.3816  data: 0.0880  max mem: 7053
Train: Epoch[20/60] Total time: 0:00:23 (2.3893 s / it)
Averaged stats: Lr: 0.000193  Loss: 0.8666  Acc@1: 51.5625 (54.4240)  Acc@5: 89.0625 (88.6477)
Train: Epoch[21/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000188  Loss: 0.9096  Acc@1: 51.5625 (51.5625)  Acc@5: 90.6250 (90.6250)  time: 3.5597  data: 0.9112  max mem: 7053
Train: Epoch[21/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000188  Loss: 0.9654  Acc@1: 54.6875 (55.7596)  Acc@5: 87.5000 (88.3139)  time: 2.4082  data: 0.0912  max mem: 7053
Train: Epoch[21/60] Total time: 0:00:24 (2.4177 s / it)
Averaged stats: Lr: 0.000188  Loss: 0.9654  Acc@1: 54.6875 (55.7596)  Acc@5: 87.5000 (88.3139)
Train: Epoch[22/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000182  Loss: 0.7160  Acc@1: 54.6875 (54.6875)  Acc@5: 93.7500 (93.7500)  time: 3.4484  data: 0.7126  max mem: 7053
Train: Epoch[22/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000182  Loss: 0.7939  Acc@1: 54.6875 (56.4274)  Acc@5: 89.0625 (90.1503)  time: 2.3735  data: 0.0714  max mem: 7053
Train: Epoch[22/60] Total time: 0:00:23 (2.3816 s / it)
Averaged stats: Lr: 0.000182  Loss: 0.7939  Acc@1: 54.6875 (56.4274)  Acc@5: 89.0625 (90.1503)
Train: Epoch[23/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000176  Loss: 0.7453  Acc@1: 54.6875 (54.6875)  Acc@5: 89.0625 (89.0625)  time: 3.4643  data: 0.7713  max mem: 7053
Train: Epoch[23/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000176  Loss: 0.7865  Acc@1: 56.2500 (56.4274)  Acc@5: 87.5000 (88.6477)  time: 2.3721  data: 0.0773  max mem: 7053
Train: Epoch[23/60] Total time: 0:00:23 (2.3814 s / it)
Averaged stats: Lr: 0.000176  Loss: 0.7865  Acc@1: 56.2500 (56.4274)  Acc@5: 87.5000 (88.6477)
Train: Epoch[24/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000170  Loss: 0.8874  Acc@1: 53.1250 (53.1250)  Acc@5: 87.5000 (87.5000)  time: 3.4512  data: 0.7796  max mem: 7053
Train: Epoch[24/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000170  Loss: 0.8438  Acc@1: 59.3750 (59.0985)  Acc@5: 87.5000 (88.4808)  time: 2.3689  data: 0.0781  max mem: 7053
Train: Epoch[24/60] Total time: 0:00:23 (2.3768 s / it)
Averaged stats: Lr: 0.000170  Loss: 0.8438  Acc@1: 59.3750 (59.0985)  Acc@5: 87.5000 (88.4808)
Train: Epoch[25/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000164  Loss: 0.9169  Acc@1: 59.3750 (59.3750)  Acc@5: 84.3750 (84.3750)  time: 3.4986  data: 0.8343  max mem: 7053
Train: Epoch[25/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000164  Loss: 1.0759  Acc@1: 57.8125 (59.4324)  Acc@5: 89.0625 (88.9816)  time: 2.4036  data: 0.0836  max mem: 7053
Train: Epoch[25/60] Total time: 0:00:24 (2.4135 s / it)
Averaged stats: Lr: 0.000164  Loss: 1.0759  Acc@1: 57.8125 (59.4324)  Acc@5: 89.0625 (88.9816)
Train: Epoch[26/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000157  Loss: 0.7604  Acc@1: 60.9375 (60.9375)  Acc@5: 89.0625 (89.0625)  time: 3.4917  data: 0.7358  max mem: 7053
Train: Epoch[26/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000157  Loss: 1.1812  Acc@1: 59.3750 (59.4324)  Acc@5: 89.0625 (88.3139)  time: 2.3796  data: 0.0737  max mem: 7053
Train: Epoch[26/60] Total time: 0:00:23 (2.3879 s / it)
Averaged stats: Lr: 0.000157  Loss: 1.1812  Acc@1: 59.3750 (59.4324)  Acc@5: 89.0625 (88.3139)
Train: Epoch[27/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000151  Loss: 0.5983  Acc@1: 71.8750 (71.8750)  Acc@5: 96.8750 (96.8750)  time: 3.5123  data: 0.7706  max mem: 7053
Train: Epoch[27/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000151  Loss: 0.8198  Acc@1: 59.3750 (61.4357)  Acc@5: 89.0625 (90.3172)  time: 2.3772  data: 0.0772  max mem: 7053
Train: Epoch[27/60] Total time: 0:00:23 (2.3873 s / it)
Averaged stats: Lr: 0.000151  Loss: 0.8198  Acc@1: 59.3750 (61.4357)  Acc@5: 89.0625 (90.3172)
Train: Epoch[28/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000145  Loss: 0.7231  Acc@1: 60.9375 (60.9375)  Acc@5: 87.5000 (87.5000)  time: 3.4090  data: 0.7559  max mem: 7053
Train: Epoch[28/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000145  Loss: 0.9671  Acc@1: 59.3750 (59.0985)  Acc@5: 87.5000 (86.9783)  time: 2.3908  data: 0.0757  max mem: 7053
Train: Epoch[28/60] Total time: 0:00:23 (2.3991 s / it)
Averaged stats: Lr: 0.000145  Loss: 0.9671  Acc@1: 59.3750 (59.0985)  Acc@5: 87.5000 (86.9783)
Train: Epoch[29/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000138  Loss: 0.6547  Acc@1: 70.3125 (70.3125)  Acc@5: 96.8750 (96.8750)  time: 3.4430  data: 0.7799  max mem: 7053
Train: Epoch[29/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000138  Loss: 0.7973  Acc@1: 59.3750 (61.6027)  Acc@5: 87.5000 (89.4825)  time: 2.3725  data: 0.0781  max mem: 7053
Train: Epoch[29/60] Total time: 0:00:23 (2.3826 s / it)
Averaged stats: Lr: 0.000138  Loss: 0.7973  Acc@1: 59.3750 (61.6027)  Acc@5: 87.5000 (89.4825)
Train: Epoch[30/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000132  Loss: 0.7058  Acc@1: 70.3125 (70.3125)  Acc@5: 89.0625 (89.0625)  time: 3.4506  data: 0.8390  max mem: 7053
Train: Epoch[30/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000132  Loss: 0.9263  Acc@1: 60.9375 (62.9382)  Acc@5: 89.0625 (89.9833)  time: 2.3610  data: 0.0840  max mem: 7053
Train: Epoch[30/60] Total time: 0:00:23 (2.3691 s / it)
Averaged stats: Lr: 0.000132  Loss: 0.9263  Acc@1: 60.9375 (62.9382)  Acc@5: 89.0625 (89.9833)
Train: Epoch[31/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000125  Loss: 0.7063  Acc@1: 56.2500 (56.2500)  Acc@5: 89.0625 (89.0625)  time: 3.5009  data: 0.7663  max mem: 7053
Train: Epoch[31/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000125  Loss: 0.9132  Acc@1: 62.5000 (63.1052)  Acc@5: 89.0625 (88.6477)  time: 2.3802  data: 0.0768  max mem: 7053
Train: Epoch[31/60] Total time: 0:00:23 (2.3894 s / it)
Averaged stats: Lr: 0.000125  Loss: 0.9132  Acc@1: 62.5000 (63.1052)  Acc@5: 89.0625 (88.6477)
Train: Epoch[32/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000118  Loss: 0.6650  Acc@1: 62.5000 (62.5000)  Acc@5: 87.5000 (87.5000)  time: 3.5285  data: 0.7913  max mem: 7053
Train: Epoch[32/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000118  Loss: 0.6657  Acc@1: 65.2174 (66.2771)  Acc@5: 91.3044 (91.3189)  time: 2.4048  data: 0.0793  max mem: 7053
Train: Epoch[32/60] Total time: 0:00:24 (2.4136 s / it)
Averaged stats: Lr: 0.000118  Loss: 0.6657  Acc@1: 65.2174 (66.2771)  Acc@5: 91.3044 (91.3189)
Train: Epoch[33/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000112  Loss: 0.5505  Acc@1: 71.8750 (71.8750)  Acc@5: 93.7500 (93.7500)  time: 3.5107  data: 0.8776  max mem: 7053
Train: Epoch[33/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000112  Loss: 0.5859  Acc@1: 64.0625 (65.4424)  Acc@5: 92.1875 (91.6528)  time: 2.3787  data: 0.0879  max mem: 7053
Train: Epoch[33/60] Total time: 0:00:23 (2.3888 s / it)
Averaged stats: Lr: 0.000112  Loss: 0.5859  Acc@1: 64.0625 (65.4424)  Acc@5: 92.1875 (91.6528)
Train: Epoch[34/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000105  Loss: 0.7389  Acc@1: 62.5000 (62.5000)  Acc@5: 89.0625 (89.0625)  time: 3.4366  data: 0.7128  max mem: 7053
Train: Epoch[34/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000105  Loss: 0.5190  Acc@1: 65.6250 (65.6093)  Acc@5: 89.0625 (89.8164)  time: 2.3712  data: 0.0714  max mem: 7053
Train: Epoch[34/60] Total time: 0:00:23 (2.3793 s / it)
Averaged stats: Lr: 0.000105  Loss: 0.5190  Acc@1: 65.6250 (65.6093)  Acc@5: 89.0625 (89.8164)
Train: Epoch[35/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000099  Loss: 0.7299  Acc@1: 70.3125 (70.3125)  Acc@5: 90.6250 (90.6250)  time: 3.4275  data: 0.7423  max mem: 7053
Train: Epoch[35/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000099  Loss: 0.7958  Acc@1: 65.6250 (67.4457)  Acc@5: 90.6250 (90.6511)  time: 2.3885  data: 0.0744  max mem: 7053
Train: Epoch[35/60] Total time: 0:00:24 (2.4002 s / it)
Averaged stats: Lr: 0.000099  Loss: 0.7958  Acc@1: 65.6250 (67.4457)  Acc@5: 90.6250 (90.6511)
Train: Epoch[36/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000093  Loss: 0.6877  Acc@1: 65.6250 (65.6250)  Acc@5: 90.6250 (90.6250)  time: 3.4599  data: 0.7294  max mem: 7053
Train: Epoch[36/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000093  Loss: 0.8488  Acc@1: 64.0625 (64.6077)  Acc@5: 90.6250 (90.1503)  time: 2.3742  data: 0.0731  max mem: 7053
Train: Epoch[36/60] Total time: 0:00:23 (2.3822 s / it)
Averaged stats: Lr: 0.000093  Loss: 0.8488  Acc@1: 64.0625 (64.6077)  Acc@5: 90.6250 (90.1503)
Train: Epoch[37/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000086  Loss: 0.6418  Acc@1: 62.5000 (62.5000)  Acc@5: 96.8750 (96.8750)  time: 3.5329  data: 0.7619  max mem: 7053
Train: Epoch[37/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000086  Loss: 0.5887  Acc@1: 70.3125 (68.6144)  Acc@5: 90.6250 (92.3205)  time: 2.3703  data: 0.0763  max mem: 7053
Train: Epoch[37/60] Total time: 0:00:23 (2.3793 s / it)
Averaged stats: Lr: 0.000086  Loss: 0.5887  Acc@1: 70.3125 (68.6144)  Acc@5: 90.6250 (92.3205)
Train: Epoch[38/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000080  Loss: 0.7463  Acc@1: 65.6250 (65.6250)  Acc@5: 85.9375 (85.9375)  time: 3.3103  data: 0.6892  max mem: 7053
Train: Epoch[38/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000080  Loss: 0.5353  Acc@1: 65.6250 (66.2771)  Acc@5: 89.0625 (89.4825)  time: 2.3445  data: 0.0690  max mem: 7053
Train: Epoch[38/60] Total time: 0:00:23 (2.3525 s / it)
Averaged stats: Lr: 0.000080  Loss: 0.5353  Acc@1: 65.6250 (66.2771)  Acc@5: 89.0625 (89.4825)
Train: Epoch[39/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000074  Loss: 0.6567  Acc@1: 64.0625 (64.0625)  Acc@5: 89.0625 (89.0625)  time: 3.4609  data: 0.7574  max mem: 7053
Train: Epoch[39/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000074  Loss: 0.7304  Acc@1: 65.6250 (68.1135)  Acc@5: 87.5000 (88.6477)  time: 2.3824  data: 0.0759  max mem: 7053
Train: Epoch[39/60] Total time: 0:00:23 (2.3932 s / it)
Averaged stats: Lr: 0.000074  Loss: 0.7304  Acc@1: 65.6250 (68.1135)  Acc@5: 87.5000 (88.6477)
Train: Epoch[40/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000068  Loss: 0.5534  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)  time: 3.4395  data: 0.6941  max mem: 7053
Train: Epoch[40/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000068  Loss: 0.7077  Acc@1: 70.3125 (70.2838)  Acc@5: 89.0625 (91.1519)  time: 2.3597  data: 0.0695  max mem: 7053
Train: Epoch[40/60] Total time: 0:00:23 (2.3676 s / it)
Averaged stats: Lr: 0.000068  Loss: 0.7077  Acc@1: 70.3125 (70.2838)  Acc@5: 89.0625 (91.1519)
Train: Epoch[41/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000063  Loss: 0.5415  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 3.4193  data: 0.6910  max mem: 7053
Train: Epoch[41/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000063  Loss: 1.0891  Acc@1: 68.7500 (69.4491)  Acc@5: 90.6250 (89.8164)  time: 2.3564  data: 0.0692  max mem: 7053
Train: Epoch[41/60] Total time: 0:00:23 (2.3661 s / it)
Averaged stats: Lr: 0.000063  Loss: 1.0891  Acc@1: 68.7500 (69.4491)  Acc@5: 90.6250 (89.8164)
Train: Epoch[42/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000057  Loss: 0.6420  Acc@1: 73.4375 (73.4375)  Acc@5: 89.0625 (89.0625)  time: 3.4860  data: 0.7198  max mem: 7053
Train: Epoch[42/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000057  Loss: 0.5290  Acc@1: 68.7500 (69.7830)  Acc@5: 92.1875 (90.4841)  time: 2.3779  data: 0.0721  max mem: 7053
Train: Epoch[42/60] Total time: 0:00:23 (2.3863 s / it)
Averaged stats: Lr: 0.000057  Loss: 0.5290  Acc@1: 68.7500 (69.7830)  Acc@5: 92.1875 (90.4841)
Train: Epoch[43/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000052  Loss: 0.7234  Acc@1: 67.1875 (67.1875)  Acc@5: 84.3750 (84.3750)  time: 3.4749  data: 0.8365  max mem: 7053
Train: Epoch[43/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000052  Loss: 0.6528  Acc@1: 68.7500 (70.1169)  Acc@5: 90.6250 (91.1519)  time: 2.3628  data: 0.0838  max mem: 7053
Train: Epoch[43/60] Total time: 0:00:23 (2.3724 s / it)
Averaged stats: Lr: 0.000052  Loss: 0.6528  Acc@1: 68.7500 (70.1169)  Acc@5: 90.6250 (91.1519)
Train: Epoch[44/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000046  Loss: 0.6317  Acc@1: 67.1875 (67.1875)  Acc@5: 87.5000 (87.5000)  time: 3.4130  data: 0.7672  max mem: 7053
Train: Epoch[44/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000046  Loss: 0.6472  Acc@1: 71.8750 (71.1185)  Acc@5: 90.6250 (91.3189)  time: 2.3563  data: 0.0768  max mem: 7053
Train: Epoch[44/60] Total time: 0:00:23 (2.3642 s / it)
Averaged stats: Lr: 0.000046  Loss: 0.6472  Acc@1: 71.8750 (71.1185)  Acc@5: 90.6250 (91.3189)
Train: Epoch[45/60]  [ 0/10]  eta: 0:00:33  Lr: 0.000041  Loss: 0.6379  Acc@1: 70.3125 (70.3125)  Acc@5: 92.1875 (92.1875)  time: 3.3752  data: 0.6817  max mem: 7053
Train: Epoch[45/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000041  Loss: 0.5975  Acc@1: 70.3125 (69.2821)  Acc@5: 90.6250 (91.3189)  time: 2.3517  data: 0.0683  max mem: 7053
Train: Epoch[45/60] Total time: 0:00:23 (2.3608 s / it)
Averaged stats: Lr: 0.000041  Loss: 0.5975  Acc@1: 70.3125 (69.2821)  Acc@5: 90.6250 (91.3189)
Train: Epoch[46/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000037  Loss: 0.6284  Acc@1: 68.7500 (68.7500)  Acc@5: 84.3750 (84.3750)  time: 3.4279  data: 0.7540  max mem: 7053
Train: Epoch[46/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000037  Loss: 0.7298  Acc@1: 65.6250 (67.6127)  Acc@5: 89.0625 (90.9850)  time: 2.3791  data: 0.0755  max mem: 7053
Train: Epoch[46/60] Total time: 0:00:23 (2.3876 s / it)
Averaged stats: Lr: 0.000037  Loss: 0.7298  Acc@1: 65.6250 (67.6127)  Acc@5: 89.0625 (90.9850)
Train: Epoch[47/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000032  Loss: 0.5575  Acc@1: 71.8750 (71.8750)  Acc@5: 92.1875 (92.1875)  time: 3.4580  data: 0.6622  max mem: 7053
Train: Epoch[47/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000032  Loss: 0.4473  Acc@1: 69.5652 (69.4491)  Acc@5: 90.6250 (89.8164)  time: 2.3597  data: 0.0663  max mem: 7053
Train: Epoch[47/60] Total time: 0:00:23 (2.3700 s / it)
Averaged stats: Lr: 0.000032  Loss: 0.4473  Acc@1: 69.5652 (69.4491)  Acc@5: 90.6250 (89.8164)
Train: Epoch[48/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000028  Loss: 0.6041  Acc@1: 70.3125 (70.3125)  Acc@5: 92.1875 (92.1875)  time: 3.4419  data: 0.7299  max mem: 7053
Train: Epoch[48/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000028  Loss: 0.3855  Acc@1: 70.3125 (71.6194)  Acc@5: 92.1875 (91.8197)  time: 2.3645  data: 0.0731  max mem: 7053
Train: Epoch[48/60] Total time: 0:00:23 (2.3724 s / it)
Averaged stats: Lr: 0.000028  Loss: 0.3855  Acc@1: 70.3125 (71.6194)  Acc@5: 92.1875 (91.8197)
Train: Epoch[49/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000024  Loss: 0.5066  Acc@1: 75.0000 (75.0000)  Acc@5: 95.3125 (95.3125)  time: 3.4211  data: 0.7088  max mem: 7053
Train: Epoch[49/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000024  Loss: 0.4030  Acc@1: 73.4375 (73.2888)  Acc@5: 92.1875 (93.3222)  time: 2.3862  data: 0.0710  max mem: 7053
Train: Epoch[49/60] Total time: 0:00:23 (2.3959 s / it)
Averaged stats: Lr: 0.000024  Loss: 0.4030  Acc@1: 73.4375 (73.2888)  Acc@5: 92.1875 (93.3222)
Train: Epoch[50/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000020  Loss: 0.5154  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)  time: 3.4583  data: 0.7907  max mem: 7053
Train: Epoch[50/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000020  Loss: 0.3460  Acc@1: 71.8750 (69.9499)  Acc@5: 89.0625 (90.6511)  time: 2.3730  data: 0.0792  max mem: 7053
Train: Epoch[50/60] Total time: 0:00:23 (2.3811 s / it)
Averaged stats: Lr: 0.000020  Loss: 0.3460  Acc@1: 71.8750 (69.9499)  Acc@5: 89.0625 (90.6511)
Train: Epoch[51/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000017  Loss: 0.4629  Acc@1: 79.6875 (79.6875)  Acc@5: 92.1875 (92.1875)  time: 3.5060  data: 0.7422  max mem: 7053
Train: Epoch[51/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000017  Loss: 0.6761  Acc@1: 71.8750 (72.1202)  Acc@5: 89.0625 (90.8180)  time: 2.3777  data: 0.0744  max mem: 7053
Train: Epoch[51/60] Total time: 0:00:23 (2.3876 s / it)
Averaged stats: Lr: 0.000017  Loss: 0.6761  Acc@1: 71.8750 (72.1202)  Acc@5: 89.0625 (90.8180)
Train: Epoch[52/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000014  Loss: 0.6429  Acc@1: 59.3750 (59.3750)  Acc@5: 87.5000 (87.5000)  time: 3.4312  data: 0.6987  max mem: 7053
Train: Epoch[52/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000014  Loss: 0.5188  Acc@1: 69.5652 (71.1185)  Acc@5: 91.3044 (92.6544)  time: 2.3694  data: 0.0700  max mem: 7053
Train: Epoch[52/60] Total time: 0:00:23 (2.3774 s / it)
Averaged stats: Lr: 0.000014  Loss: 0.5188  Acc@1: 69.5652 (71.1185)  Acc@5: 91.3044 (92.6544)
Train: Epoch[53/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000011  Loss: 0.4922  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)  time: 3.4459  data: 0.7295  max mem: 7053
Train: Epoch[53/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000011  Loss: 0.4883  Acc@1: 73.4375 (73.1219)  Acc@5: 93.7500 (94.1569)  time: 2.3822  data: 0.0731  max mem: 7053
Train: Epoch[53/60] Total time: 0:00:23 (2.3923 s / it)
Averaged stats: Lr: 0.000011  Loss: 0.4883  Acc@1: 73.4375 (73.1219)  Acc@5: 93.7500 (94.1569)
Train: Epoch[54/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000008  Loss: 0.4831  Acc@1: 73.4375 (73.4375)  Acc@5: 96.8750 (96.8750)  time: 3.5014  data: 0.8148  max mem: 7053
Train: Epoch[54/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000008  Loss: 0.6768  Acc@1: 73.4375 (71.7863)  Acc@5: 89.0625 (91.9866)  time: 2.3801  data: 0.0816  max mem: 7053
Train: Epoch[54/60] Total time: 0:00:23 (2.3880 s / it)
Averaged stats: Lr: 0.000008  Loss: 0.6768  Acc@1: 73.4375 (71.7863)  Acc@5: 89.0625 (91.9866)
Train: Epoch[55/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000006  Loss: 0.5370  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)  time: 3.5330  data: 0.8262  max mem: 7053
Train: Epoch[55/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000006  Loss: 0.5415  Acc@1: 68.7500 (70.9516)  Acc@5: 92.1875 (91.8197)  time: 2.3826  data: 0.0828  max mem: 7053
Train: Epoch[55/60] Total time: 0:00:23 (2.3923 s / it)
Averaged stats: Lr: 0.000006  Loss: 0.5415  Acc@1: 68.7500 (70.9516)  Acc@5: 92.1875 (91.8197)
Train: Epoch[56/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000004  Loss: 0.3328  Acc@1: 79.6875 (79.6875)  Acc@5: 96.8750 (96.8750)  time: 3.5011  data: 0.7549  max mem: 7053
Train: Epoch[56/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000004  Loss: 0.4773  Acc@1: 73.4375 (74.7913)  Acc@5: 92.1875 (92.8214)  time: 2.3992  data: 0.0756  max mem: 7053
Train: Epoch[56/60] Total time: 0:00:24 (2.4077 s / it)
Averaged stats: Lr: 0.000004  Loss: 0.4773  Acc@1: 73.4375 (74.7913)  Acc@5: 92.1875 (92.8214)
Train: Epoch[57/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000003  Loss: 0.5312  Acc@1: 71.8750 (71.8750)  Acc@5: 92.1875 (92.1875)  time: 3.4662  data: 0.8340  max mem: 7053
Train: Epoch[57/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000003  Loss: 0.3190  Acc@1: 70.3125 (70.1169)  Acc@5: 92.1875 (90.3172)  time: 2.3756  data: 0.0835  max mem: 7053
Train: Epoch[57/60] Total time: 0:00:23 (2.3850 s / it)
Averaged stats: Lr: 0.000003  Loss: 0.3190  Acc@1: 70.3125 (70.1169)  Acc@5: 92.1875 (90.3172)
Train: Epoch[58/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000002  Loss: 0.4788  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)  time: 3.4343  data: 0.6937  max mem: 7053
Train: Epoch[58/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000002  Loss: 0.5807  Acc@1: 71.8750 (73.4558)  Acc@5: 90.6250 (91.9866)  time: 2.3648  data: 0.0695  max mem: 7053
Train: Epoch[58/60] Total time: 0:00:23 (2.3728 s / it)
Averaged stats: Lr: 0.000002  Loss: 0.5807  Acc@1: 71.8750 (73.4558)  Acc@5: 90.6250 (91.9866)
Train: Epoch[59/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000001  Loss: 0.5487  Acc@1: 79.6875 (79.6875)  Acc@5: 93.7500 (93.7500)  time: 3.5028  data: 0.7808  max mem: 7053
Train: Epoch[59/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000001  Loss: 0.6047  Acc@1: 71.8750 (71.9533)  Acc@5: 90.6250 (90.6511)  time: 2.3774  data: 0.0782  max mem: 7053
Train: Epoch[59/60] Total time: 0:00:23 (2.3875 s / it)
Averaged stats: Lr: 0.000001  Loss: 0.6047  Acc@1: 71.8750 (71.9533)  Acc@5: 90.6250 (90.6511)
Train: Epoch[60/60]  [ 0/10]  eta: 0:00:34  Lr: 0.000000  Loss: 0.4564  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)  time: 3.4909  data: 0.8254  max mem: 7053
Train: Epoch[60/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000000  Loss: 0.7797  Acc@1: 69.5652 (70.7846)  Acc@5: 90.6250 (91.1519)  time: 2.3963  data: 0.0827  max mem: 7053
Train: Epoch[60/60] Total time: 0:00:24 (2.4050 s / it)
Averaged stats: Lr: 0.000000  Loss: 0.7797  Acc@1: 69.5652 (70.7846)  Acc@5: 90.6250 (91.1519)
Test: [Task 1]  [0/9]  eta: 0:00:16  Loss: 0.4483 (0.4483)  Acc@1: 93.7500 (93.7500)  Acc@5: 98.4375 (98.4375)  time: 1.8152  data: 0.8641  max mem: 7053
Test: [Task 1]  [8/9]  eta: 0:00:00  Loss: 0.2772 (0.3370)  Acc@1: 96.8750 (91.8447)  Acc@5: 100.0000 (98.8350)  time: 0.7682  data: 0.0962  max mem: 7053
Test: [Task 1] Total time: 0:00:07 (0.7790 s / it)
* Acc@1 91.845 Acc@5 98.835 loss 0.337
Batchwise eval time for task 1 = 0.7790166801876492
Test: [Task 2]  [0/9]  eta: 0:00:16  Loss: 0.6464 (0.6464)  Acc@1: 78.1250 (78.1250)  Acc@5: 100.0000 (100.0000)  time: 1.8122  data: 0.9216  max mem: 7053
Test: [Task 2]  [8/9]  eta: 0:00:00  Loss: 1.1285 (1.0626)  Acc@1: 57.8125 (65.7391)  Acc@5: 98.4375 (97.9130)  time: 0.8189  data: 0.1026  max mem: 7053
Test: [Task 2] Total time: 0:00:07 (0.8288 s / it)
* Acc@1 65.739 Acc@5 97.913 loss 1.063
Batchwise eval time for task 2 = 0.8288092348310683
Test: [Task 3]  [ 0/10]  eta: 0:00:17  Loss: 0.3894 (0.3894)  Acc@1: 95.3125 (95.3125)  Acc@5: 98.4375 (98.4375)  time: 1.7750  data: 0.9424  max mem: 7053
Test: [Task 3]  [ 9/10]  eta: 0:00:00  Loss: 0.4363 (0.6241)  Acc@1: 93.7500 (91.2752)  Acc@5: 98.4375 (98.4899)  time: 0.7668  data: 0.0944  max mem: 7053
Test: [Task 3] Total time: 0:00:07 (0.7750 s / it)
* Acc@1 91.275 Acc@5 98.490 loss 0.624
Batchwise eval time for task 3 = 0.7749864816665649
Test: [Task 4]  [ 0/10]  eta: 0:00:19  Loss: 1.2227 (1.2227)  Acc@1: 59.3750 (59.3750)  Acc@5: 95.3125 (95.3125)  time: 1.9256  data: 1.0162  max mem: 7053
Test: [Task 4]  [ 9/10]  eta: 0:00:00  Loss: 0.7095 (0.7815)  Acc@1: 87.5000 (82.0819)  Acc@5: 98.4375 (98.6348)  time: 0.7760  data: 0.1018  max mem: 7053
Test: [Task 4] Total time: 0:00:07 (0.7840 s / it)
* Acc@1 82.082 Acc@5 98.635 loss 0.782
Batchwise eval time for task 4 = 0.7839760541915893
Test: [Task 5]  [ 0/10]  eta: 0:00:18  Loss: 0.5113 (0.5113)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 1.8321  data: 0.9843  max mem: 7053
Test: [Task 5]  [ 9/10]  eta: 0:00:00  Loss: 0.4186 (0.5048)  Acc@1: 93.7500 (93.7500)  Acc@5: 98.4375 (98.3108)  time: 0.7711  data: 0.0986  max mem: 7053
Test: [Task 5] Total time: 0:00:07 (0.7797 s / it)
* Acc@1 93.750 Acc@5 98.311 loss 0.505
Batchwise eval time for task 5 = 0.779721736907959
Test: [Task 6]  [0/9]  eta: 0:00:17  Loss: 0.7425 (0.7425)  Acc@1: 84.3750 (84.3750)  Acc@5: 98.4375 (98.4375)  time: 1.9230  data: 1.1024  max mem: 7053
Test: [Task 6]  [8/9]  eta: 0:00:00  Loss: 0.8031 (0.8519)  Acc@1: 85.9375 (84.8057)  Acc@5: 96.8750 (97.5265)  time: 0.8236  data: 0.1227  max mem: 7053
Test: [Task 6] Total time: 0:00:07 (0.8322 s / it)
* Acc@1 84.806 Acc@5 97.527 loss 0.852
Batchwise eval time for task 6 = 0.8322377469804552
Test: [Task 7]  [ 0/10]  eta: 0:00:17  Loss: 1.2124 (1.2124)  Acc@1: 79.6875 (79.6875)  Acc@5: 98.4375 (98.4375)  time: 1.7887  data: 0.9494  max mem: 7053
Test: [Task 7]  [ 9/10]  eta: 0:00:00  Loss: 0.7960 (1.0209)  Acc@1: 79.6875 (79.7659)  Acc@5: 96.8750 (96.8227)  time: 0.7690  data: 0.0951  max mem: 7053
Test: [Task 7] Total time: 0:00:07 (0.7772 s / it)
* Acc@1 79.766 Acc@5 96.823 loss 1.021
Batchwise eval time for task 7 = 0.777233362197876
Test: [Task 8]  [ 0/10]  eta: 0:00:18  Loss: 1.4733 (1.4733)  Acc@1: 82.8125 (82.8125)  Acc@5: 96.8750 (96.8750)  time: 1.8294  data: 0.9311  max mem: 7053
Test: [Task 8]  [ 9/10]  eta: 0:00:00  Loss: 0.9321 (1.0583)  Acc@1: 82.8125 (76.2799)  Acc@5: 96.8750 (97.4403)  time: 0.7685  data: 0.0933  max mem: 7053
Test: [Task 8] Total time: 0:00:07 (0.7765 s / it)
* Acc@1 76.280 Acc@5 97.440 loss 1.058
Batchwise eval time for task 8 = 0.7765418529510498
[Average accuracy till task8]	Acc@1: 83.1166	Acc@5: 97.9966	Loss: 0.7801	Forgetting: 3.6066	Backward: -3.3872
Eval time for task 8 = 61.15590858459473
Using adam optimizer
Reinitialising optimizer
Similarity:  tensor(0.8846)  Task:  8
Old Num K:  12 New Num K:  13
Task number:  8
Train: Epoch[ 1/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000250  Loss: 3.1798  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  time: 3.5969  data: 0.7599  max mem: 7095
Train: Epoch[ 1/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000250  Loss: 3.3995  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  time: 2.4951  data: 0.0761  max mem: 7105
Train: Epoch[ 1/60] Total time: 0:00:25 (2.5030 s / it)
Averaged stats: Lr: 0.000250  Loss: 3.3995  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)
Train: Epoch[ 2/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000250  Loss: 3.1066  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  time: 3.6823  data: 0.8286  max mem: 7105
Train: Epoch[ 2/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000250  Loss: 2.6240  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  time: 2.5223  data: 0.0830  max mem: 7105
Train: Epoch[ 2/60] Total time: 0:00:25 (2.5331 s / it)
Averaged stats: Lr: 0.000250  Loss: 2.6240  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)
Train: Epoch[ 3/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000249  Loss: 2.7603  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  time: 3.6512  data: 0.7753  max mem: 7105
Train: Epoch[ 3/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000249  Loss: 2.3462  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.6667)  time: 2.5039  data: 0.0777  max mem: 7105
Train: Epoch[ 3/60] Total time: 0:00:25 (2.5122 s / it)
Averaged stats: Lr: 0.000249  Loss: 2.3462  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.6667)
Train: Epoch[ 4/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000248  Loss: 2.3108  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  time: 3.7698  data: 0.7420  max mem: 7105
Train: Epoch[ 4/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000248  Loss: 1.9040  Acc@1: 0.0000 (0.3333)  Acc@5: 3.1250 (3.0000)  time: 2.5120  data: 0.0743  max mem: 7105
Train: Epoch[ 4/60] Total time: 0:00:25 (2.5221 s / it)
Averaged stats: Lr: 0.000248  Loss: 1.9040  Acc@1: 0.0000 (0.3333)  Acc@5: 3.1250 (3.0000)
Train: Epoch[ 5/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000247  Loss: 1.9967  Acc@1: 0.0000 (0.0000)  Acc@5: 9.3750 (9.3750)  time: 3.6810  data: 0.8907  max mem: 7105
Train: Epoch[ 5/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000247  Loss: 1.8691  Acc@1: 1.5625 (2.3333)  Acc@5: 10.9375 (10.8333)  time: 2.4993  data: 0.0892  max mem: 7105
Train: Epoch[ 5/60] Total time: 0:00:25 (2.5075 s / it)
Averaged stats: Lr: 0.000247  Loss: 1.8691  Acc@1: 1.5625 (2.3333)  Acc@5: 10.9375 (10.8333)
Train: Epoch[ 6/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000246  Loss: 1.7704  Acc@1: 3.1250 (3.1250)  Acc@5: 20.3125 (20.3125)  time: 3.6199  data: 0.8001  max mem: 7105
Train: Epoch[ 6/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000246  Loss: 1.7026  Acc@1: 3.1250 (3.3333)  Acc@5: 18.7500 (18.1667)  time: 2.4928  data: 0.0801  max mem: 7105
Train: Epoch[ 6/60] Total time: 0:00:25 (2.5049 s / it)
Averaged stats: Lr: 0.000246  Loss: 1.7026  Acc@1: 3.1250 (3.3333)  Acc@5: 18.7500 (18.1667)
Train: Epoch[ 7/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000244  Loss: 1.6552  Acc@1: 6.2500 (6.2500)  Acc@5: 21.8750 (21.8750)  time: 3.5682  data: 0.7547  max mem: 7105
Train: Epoch[ 7/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000244  Loss: 1.6035  Acc@1: 4.6875 (5.1667)  Acc@5: 31.2500 (31.8333)  time: 2.5122  data: 0.0756  max mem: 7105
Train: Epoch[ 7/60] Total time: 0:00:25 (2.5210 s / it)
Averaged stats: Lr: 0.000244  Loss: 1.6035  Acc@1: 4.6875 (5.1667)  Acc@5: 31.2500 (31.8333)
Train: Epoch[ 8/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000242  Loss: 1.5926  Acc@1: 3.1250 (3.1250)  Acc@5: 34.3750 (34.3750)  time: 3.6114  data: 0.7686  max mem: 7105
Train: Epoch[ 8/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000242  Loss: 1.5341  Acc@1: 7.8125 (8.0000)  Acc@5: 42.1875 (42.5000)  time: 2.4924  data: 0.0770  max mem: 7105
Train: Epoch[ 8/60] Total time: 0:00:25 (2.5039 s / it)
Averaged stats: Lr: 0.000242  Loss: 1.5341  Acc@1: 7.8125 (8.0000)  Acc@5: 42.1875 (42.5000)
Train: Epoch[ 9/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000239  Loss: 1.4580  Acc@1: 10.9375 (10.9375)  Acc@5: 57.8125 (57.8125)  time: 3.6284  data: 0.8326  max mem: 7105
Train: Epoch[ 9/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000239  Loss: 1.2993  Acc@1: 9.3750 (10.8333)  Acc@5: 48.4375 (49.6667)  time: 2.4948  data: 0.0834  max mem: 7105
Train: Epoch[ 9/60] Total time: 0:00:25 (2.5029 s / it)
Averaged stats: Lr: 0.000239  Loss: 1.2993  Acc@1: 9.3750 (10.8333)  Acc@5: 48.4375 (49.6667)
Train: Epoch[10/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000236  Loss: 1.2846  Acc@1: 10.9375 (10.9375)  Acc@5: 56.2500 (56.2500)  time: 3.5126  data: 0.6709  max mem: 7105
Train: Epoch[10/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000236  Loss: 1.4677  Acc@1: 16.6667 (15.8333)  Acc@5: 58.3333 (60.0000)  time: 2.4745  data: 0.0672  max mem: 7105
Train: Epoch[10/60] Total time: 0:00:24 (2.4834 s / it)
Averaged stats: Lr: 0.000236  Loss: 1.4677  Acc@1: 16.6667 (15.8333)  Acc@5: 58.3333 (60.0000)
Train: Epoch[11/60]  [ 0/10]  eta: 0:00:40  Lr: 0.000233  Loss: 1.3174  Acc@1: 28.1250 (28.1250)  Acc@5: 65.6250 (65.6250)  time: 4.0832  data: 1.1404  max mem: 7105
Train: Epoch[11/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000233  Loss: 1.0920  Acc@1: 20.8333 (22.3333)  Acc@5: 60.9375 (61.8333)  time: 2.5325  data: 0.1142  max mem: 7105
Train: Epoch[11/60] Total time: 0:00:25 (2.5418 s / it)
Averaged stats: Lr: 0.000233  Loss: 1.0920  Acc@1: 20.8333 (22.3333)  Acc@5: 60.9375 (61.8333)
Train: Epoch[12/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000230  Loss: 1.2999  Acc@1: 20.3125 (20.3125)  Acc@5: 57.8125 (57.8125)  time: 3.7553  data: 0.8435  max mem: 7105
Train: Epoch[12/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000230  Loss: 1.1711  Acc@1: 23.4375 (27.1667)  Acc@5: 67.1875 (67.3333)  time: 2.5083  data: 0.0845  max mem: 7105
Train: Epoch[12/60] Total time: 0:00:25 (2.5174 s / it)
Averaged stats: Lr: 0.000230  Loss: 1.1711  Acc@1: 23.4375 (27.1667)  Acc@5: 67.1875 (67.3333)
Train: Epoch[13/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000226  Loss: 0.9462  Acc@1: 32.8125 (32.8125)  Acc@5: 75.0000 (75.0000)  time: 3.6828  data: 0.8311  max mem: 7105
Train: Epoch[13/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000226  Loss: 1.0852  Acc@1: 32.8125 (33.3333)  Acc@5: 71.8750 (72.1667)  time: 2.4993  data: 0.0832  max mem: 7105
Train: Epoch[13/60] Total time: 0:00:25 (2.5075 s / it)
Averaged stats: Lr: 0.000226  Loss: 1.0852  Acc@1: 32.8125 (33.3333)  Acc@5: 71.8750 (72.1667)
Train: Epoch[14/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000222  Loss: 1.0735  Acc@1: 29.6875 (29.6875)  Acc@5: 65.6250 (65.6250)  time: 3.5936  data: 0.7875  max mem: 7105
Train: Epoch[14/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000222  Loss: 1.2107  Acc@1: 40.6250 (38.5000)  Acc@5: 70.3125 (71.1667)  time: 2.5136  data: 0.0789  max mem: 7105
Train: Epoch[14/60] Total time: 0:00:25 (2.5248 s / it)
Averaged stats: Lr: 0.000222  Loss: 1.2107  Acc@1: 40.6250 (38.5000)  Acc@5: 70.3125 (71.1667)
Train: Epoch[15/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000218  Loss: 1.2754  Acc@1: 34.3750 (34.3750)  Acc@5: 62.5000 (62.5000)  time: 3.6010  data: 0.7949  max mem: 7105
Train: Epoch[15/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000218  Loss: 1.0575  Acc@1: 39.0625 (41.0000)  Acc@5: 71.8750 (73.8333)  time: 2.4930  data: 0.0796  max mem: 7105
Train: Epoch[15/60] Total time: 0:00:25 (2.5010 s / it)
Averaged stats: Lr: 0.000218  Loss: 1.0575  Acc@1: 39.0625 (41.0000)  Acc@5: 71.8750 (73.8333)
Train: Epoch[16/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000213  Loss: 0.8117  Acc@1: 54.6875 (54.6875)  Acc@5: 82.8125 (82.8125)  time: 3.5874  data: 0.7051  max mem: 7105
Train: Epoch[16/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000213  Loss: 1.2027  Acc@1: 45.3125 (45.3333)  Acc@5: 75.0000 (77.5000)  time: 2.4840  data: 0.0706  max mem: 7105
Train: Epoch[16/60] Total time: 0:00:24 (2.4938 s / it)
Averaged stats: Lr: 0.000213  Loss: 1.2027  Acc@1: 45.3125 (45.3333)  Acc@5: 75.0000 (77.5000)
Train: Epoch[17/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000209  Loss: 0.8479  Acc@1: 50.0000 (50.0000)  Acc@5: 84.3750 (84.3750)  time: 3.5464  data: 0.6991  max mem: 7105
Train: Epoch[17/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000209  Loss: 0.6802  Acc@1: 48.4375 (48.8333)  Acc@5: 76.5625 (78.3333)  time: 2.4781  data: 0.0700  max mem: 7105
Train: Epoch[17/60] Total time: 0:00:24 (2.4861 s / it)
Averaged stats: Lr: 0.000209  Loss: 0.6802  Acc@1: 48.4375 (48.8333)  Acc@5: 76.5625 (78.3333)
Train: Epoch[18/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000204  Loss: 0.8597  Acc@1: 57.8125 (57.8125)  Acc@5: 76.5625 (76.5625)  time: 3.8077  data: 0.7327  max mem: 7105
Train: Epoch[18/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000204  Loss: 0.8248  Acc@1: 50.0000 (49.5000)  Acc@5: 76.5625 (77.8333)  time: 2.5148  data: 0.0734  max mem: 7105
Train: Epoch[18/60] Total time: 0:00:25 (2.5236 s / it)
Averaged stats: Lr: 0.000204  Loss: 0.8248  Acc@1: 50.0000 (49.5000)  Acc@5: 76.5625 (77.8333)
Train: Epoch[19/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000198  Loss: 1.2969  Acc@1: 42.1875 (42.1875)  Acc@5: 62.5000 (62.5000)  time: 3.5869  data: 0.7337  max mem: 7105
Train: Epoch[19/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000198  Loss: 0.9565  Acc@1: 53.1250 (53.3333)  Acc@5: 79.6875 (79.0000)  time: 2.4950  data: 0.0735  max mem: 7105
Train: Epoch[19/60] Total time: 0:00:25 (2.5030 s / it)
Averaged stats: Lr: 0.000198  Loss: 0.9565  Acc@1: 53.1250 (53.3333)  Acc@5: 79.6875 (79.0000)
Train: Epoch[20/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000193  Loss: 0.8788  Acc@1: 59.3750 (59.3750)  Acc@5: 82.8125 (82.8125)  time: 3.6199  data: 0.7642  max mem: 7105
Train: Epoch[20/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000193  Loss: 0.8355  Acc@1: 53.1250 (55.3333)  Acc@5: 81.2500 (80.8333)  time: 2.4948  data: 0.0765  max mem: 7105
Train: Epoch[20/60] Total time: 0:00:25 (2.5064 s / it)
Averaged stats: Lr: 0.000193  Loss: 0.8355  Acc@1: 53.1250 (55.3333)  Acc@5: 81.2500 (80.8333)
Train: Epoch[21/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000188  Loss: 0.7926  Acc@1: 53.1250 (53.1250)  Acc@5: 82.8125 (82.8125)  time: 3.6096  data: 0.8691  max mem: 7105
Train: Epoch[21/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000188  Loss: 1.1319  Acc@1: 56.2500 (58.5000)  Acc@5: 79.6875 (82.3333)  time: 2.5121  data: 0.0870  max mem: 7105
Train: Epoch[21/60] Total time: 0:00:25 (2.5207 s / it)
Averaged stats: Lr: 0.000188  Loss: 1.1319  Acc@1: 56.2500 (58.5000)  Acc@5: 79.6875 (82.3333)
Train: Epoch[22/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000182  Loss: 0.7179  Acc@1: 67.1875 (67.1875)  Acc@5: 84.3750 (84.3750)  time: 3.6411  data: 0.7457  max mem: 7105
Train: Epoch[22/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000182  Loss: 0.7084  Acc@1: 62.5000 (63.5000)  Acc@5: 84.3750 (84.0000)  time: 2.4960  data: 0.0747  max mem: 7105
Train: Epoch[22/60] Total time: 0:00:25 (2.5062 s / it)
Averaged stats: Lr: 0.000182  Loss: 0.7084  Acc@1: 62.5000 (63.5000)  Acc@5: 84.3750 (84.0000)
Train: Epoch[23/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000176  Loss: 0.8586  Acc@1: 53.1250 (53.1250)  Acc@5: 81.2500 (81.2500)  time: 3.6187  data: 0.7177  max mem: 7105
Train: Epoch[23/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000176  Loss: 0.9106  Acc@1: 56.2500 (58.5000)  Acc@5: 81.2500 (80.8333)  time: 2.4952  data: 0.0719  max mem: 7105
Train: Epoch[23/60] Total time: 0:00:25 (2.5037 s / it)
Averaged stats: Lr: 0.000176  Loss: 0.9106  Acc@1: 56.2500 (58.5000)  Acc@5: 81.2500 (80.8333)
Train: Epoch[24/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000170  Loss: 0.7853  Acc@1: 60.9375 (60.9375)  Acc@5: 79.6875 (79.6875)  time: 3.5950  data: 0.7028  max mem: 7105
Train: Epoch[24/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000170  Loss: 0.9195  Acc@1: 60.9375 (61.5000)  Acc@5: 79.6875 (80.0000)  time: 2.5079  data: 0.0704  max mem: 7105
Train: Epoch[24/60] Total time: 0:00:25 (2.5177 s / it)
Averaged stats: Lr: 0.000170  Loss: 0.9195  Acc@1: 60.9375 (61.5000)  Acc@5: 79.6875 (80.0000)
Train: Epoch[25/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000164  Loss: 0.7841  Acc@1: 56.2500 (56.2500)  Acc@5: 81.2500 (81.2500)  time: 3.5139  data: 0.6885  max mem: 7105
Train: Epoch[25/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000164  Loss: 0.5595  Acc@1: 64.0625 (62.5000)  Acc@5: 81.2500 (81.1667)  time: 2.4813  data: 0.0690  max mem: 7105
Train: Epoch[25/60] Total time: 0:00:24 (2.4891 s / it)
Averaged stats: Lr: 0.000164  Loss: 0.5595  Acc@1: 64.0625 (62.5000)  Acc@5: 81.2500 (81.1667)
Train: Epoch[26/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000157  Loss: 0.7787  Acc@1: 64.0625 (64.0625)  Acc@5: 84.3750 (84.3750)  time: 3.5839  data: 0.6796  max mem: 7105
Train: Epoch[26/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000157  Loss: 0.4023  Acc@1: 62.5000 (64.0000)  Acc@5: 81.2500 (83.8333)  time: 2.4925  data: 0.0681  max mem: 7105
Train: Epoch[26/60] Total time: 0:00:25 (2.5021 s / it)
Averaged stats: Lr: 0.000157  Loss: 0.4023  Acc@1: 62.5000 (64.0000)  Acc@5: 81.2500 (83.8333)
Train: Epoch[27/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000151  Loss: 0.7409  Acc@1: 64.0625 (64.0625)  Acc@5: 82.8125 (82.8125)  time: 3.6951  data: 0.8684  max mem: 7105
Train: Epoch[27/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000151  Loss: 0.7663  Acc@1: 64.0625 (64.0000)  Acc@5: 81.2500 (82.5000)  time: 2.5066  data: 0.0870  max mem: 7105
Train: Epoch[27/60] Total time: 0:00:25 (2.5145 s / it)
Averaged stats: Lr: 0.000151  Loss: 0.7663  Acc@1: 64.0625 (64.0000)  Acc@5: 81.2500 (82.5000)
Train: Epoch[28/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000145  Loss: 0.6929  Acc@1: 68.7500 (68.7500)  Acc@5: 85.9375 (85.9375)  time: 3.6240  data: 0.8571  max mem: 7105
Train: Epoch[28/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000145  Loss: 0.6710  Acc@1: 65.6250 (66.6667)  Acc@5: 82.8125 (85.1667)  time: 2.5148  data: 0.0858  max mem: 7105
Train: Epoch[28/60] Total time: 0:00:25 (2.5255 s / it)
Averaged stats: Lr: 0.000145  Loss: 0.6710  Acc@1: 65.6250 (66.6667)  Acc@5: 82.8125 (85.1667)
Train: Epoch[29/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000138  Loss: 0.9636  Acc@1: 62.5000 (62.5000)  Acc@5: 78.1250 (78.1250)  time: 3.6489  data: 0.7924  max mem: 7105
Train: Epoch[29/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000138  Loss: 0.6298  Acc@1: 66.6667 (67.8333)  Acc@5: 85.9375 (85.3333)  time: 2.4970  data: 0.0794  max mem: 7105
Train: Epoch[29/60] Total time: 0:00:25 (2.5050 s / it)
Averaged stats: Lr: 0.000138  Loss: 0.6298  Acc@1: 66.6667 (67.8333)  Acc@5: 85.9375 (85.3333)
Train: Epoch[30/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000132  Loss: 0.7274  Acc@1: 67.1875 (67.1875)  Acc@5: 81.2500 (81.2500)  time: 3.5565  data: 0.7276  max mem: 7105
Train: Epoch[30/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000132  Loss: 0.8342  Acc@1: 67.1875 (67.1667)  Acc@5: 84.3750 (84.5000)  time: 2.4874  data: 0.0729  max mem: 7105
Train: Epoch[30/60] Total time: 0:00:24 (2.4963 s / it)
Averaged stats: Lr: 0.000132  Loss: 0.8342  Acc@1: 67.1875 (67.1667)  Acc@5: 84.3750 (84.5000)
Train: Epoch[31/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000125  Loss: 0.6838  Acc@1: 65.6250 (65.6250)  Acc@5: 82.8125 (82.8125)  time: 3.6044  data: 0.8213  max mem: 7105
Train: Epoch[31/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000125  Loss: 0.5182  Acc@1: 65.6250 (66.1667)  Acc@5: 82.8125 (84.0000)  time: 2.5122  data: 0.0823  max mem: 7105
Train: Epoch[31/60] Total time: 0:00:25 (2.5210 s / it)
Averaged stats: Lr: 0.000125  Loss: 0.5182  Acc@1: 65.6250 (66.1667)  Acc@5: 82.8125 (84.0000)
Train: Epoch[32/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000118  Loss: 0.7867  Acc@1: 62.5000 (62.5000)  Acc@5: 78.1250 (78.1250)  time: 3.5090  data: 0.7109  max mem: 7105
Train: Epoch[32/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000118  Loss: 0.7184  Acc@1: 68.7500 (67.8333)  Acc@5: 84.3750 (84.8333)  time: 2.4841  data: 0.0712  max mem: 7105
Train: Epoch[32/60] Total time: 0:00:24 (2.4937 s / it)
Averaged stats: Lr: 0.000118  Loss: 0.7184  Acc@1: 68.7500 (67.8333)  Acc@5: 84.3750 (84.8333)
Train: Epoch[33/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000112  Loss: 0.9690  Acc@1: 64.0625 (64.0625)  Acc@5: 76.5625 (76.5625)  time: 3.5754  data: 0.7451  max mem: 7105
Train: Epoch[33/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000112  Loss: 0.6014  Acc@1: 64.0625 (65.5000)  Acc@5: 82.8125 (84.3333)  time: 2.4894  data: 0.0747  max mem: 7105
Train: Epoch[33/60] Total time: 0:00:24 (2.4977 s / it)
Averaged stats: Lr: 0.000112  Loss: 0.6014  Acc@1: 64.0625 (65.5000)  Acc@5: 82.8125 (84.3333)
Train: Epoch[34/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000105  Loss: 0.8588  Acc@1: 62.5000 (62.5000)  Acc@5: 76.5625 (76.5625)  time: 3.6363  data: 0.8391  max mem: 7105
Train: Epoch[34/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000105  Loss: 0.8071  Acc@1: 62.5000 (64.6667)  Acc@5: 79.6875 (81.3333)  time: 2.5010  data: 0.0840  max mem: 7105
Train: Epoch[34/60] Total time: 0:00:25 (2.5105 s / it)
Averaged stats: Lr: 0.000105  Loss: 0.8071  Acc@1: 62.5000 (64.6667)  Acc@5: 79.6875 (81.3333)
Train: Epoch[35/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000099  Loss: 0.7879  Acc@1: 64.0625 (64.0625)  Acc@5: 81.2500 (81.2500)  time: 3.6227  data: 0.7108  max mem: 7105
Train: Epoch[35/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000099  Loss: 0.8396  Acc@1: 68.7500 (68.6667)  Acc@5: 84.3750 (86.1667)  time: 2.5148  data: 0.0712  max mem: 7105
Train: Epoch[35/60] Total time: 0:00:25 (2.5232 s / it)
Averaged stats: Lr: 0.000099  Loss: 0.8396  Acc@1: 68.7500 (68.6667)  Acc@5: 84.3750 (86.1667)
Train: Epoch[36/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000093  Loss: 0.6141  Acc@1: 73.4375 (73.4375)  Acc@5: 89.0625 (89.0625)  time: 3.5862  data: 0.7174  max mem: 7105
Train: Epoch[36/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000093  Loss: 0.5822  Acc@1: 68.7500 (68.8333)  Acc@5: 83.3333 (85.6667)  time: 2.4951  data: 0.0719  max mem: 7105
Train: Epoch[36/60] Total time: 0:00:25 (2.5050 s / it)
Averaged stats: Lr: 0.000093  Loss: 0.5822  Acc@1: 68.7500 (68.8333)  Acc@5: 83.3333 (85.6667)
Train: Epoch[37/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000086  Loss: 0.7649  Acc@1: 68.7500 (68.7500)  Acc@5: 79.6875 (79.6875)  time: 3.5628  data: 0.7897  max mem: 7105
Train: Epoch[37/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000086  Loss: 0.8125  Acc@1: 65.6250 (67.0000)  Acc@5: 83.3333 (84.8333)  time: 2.4876  data: 0.0791  max mem: 7105
Train: Epoch[37/60] Total time: 0:00:24 (2.4956 s / it)
Averaged stats: Lr: 0.000086  Loss: 0.8125  Acc@1: 65.6250 (67.0000)  Acc@5: 83.3333 (84.8333)
Train: Epoch[38/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000080  Loss: 0.5342  Acc@1: 73.4375 (73.4375)  Acc@5: 90.6250 (90.6250)  time: 3.5493  data: 0.7536  max mem: 7105
Train: Epoch[38/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000080  Loss: 0.5693  Acc@1: 71.8750 (70.0000)  Acc@5: 83.3333 (85.8333)  time: 2.5037  data: 0.0755  max mem: 7105
Train: Epoch[38/60] Total time: 0:00:25 (2.5148 s / it)
Averaged stats: Lr: 0.000080  Loss: 0.5693  Acc@1: 71.8750 (70.0000)  Acc@5: 83.3333 (85.8333)
Train: Epoch[39/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000074  Loss: 0.6327  Acc@1: 75.0000 (75.0000)  Acc@5: 84.3750 (84.3750)  time: 3.6308  data: 0.7419  max mem: 7105
Train: Epoch[39/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000074  Loss: 0.3404  Acc@1: 71.8750 (73.3333)  Acc@5: 87.5000 (87.6667)  time: 2.4927  data: 0.0743  max mem: 7105
Train: Epoch[39/60] Total time: 0:00:25 (2.5009 s / it)
Averaged stats: Lr: 0.000074  Loss: 0.3404  Acc@1: 71.8750 (73.3333)  Acc@5: 87.5000 (87.6667)
Train: Epoch[40/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000068  Loss: 0.5997  Acc@1: 64.0625 (64.0625)  Acc@5: 85.9375 (85.9375)  time: 3.5803  data: 0.7874  max mem: 7105
Train: Epoch[40/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000068  Loss: 0.4941  Acc@1: 71.8750 (72.0000)  Acc@5: 85.9375 (86.3333)  time: 2.4834  data: 0.0789  max mem: 7105
Train: Epoch[40/60] Total time: 0:00:24 (2.4927 s / it)
Averaged stats: Lr: 0.000068  Loss: 0.4941  Acc@1: 71.8750 (72.0000)  Acc@5: 85.9375 (86.3333)
Train: Epoch[41/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000063  Loss: 0.6098  Acc@1: 68.7500 (68.7500)  Acc@5: 81.2500 (81.2500)  time: 3.6255  data: 0.8007  max mem: 7105
Train: Epoch[41/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000063  Loss: 0.8027  Acc@1: 68.7500 (71.3333)  Acc@5: 85.9375 (86.5000)  time: 2.5169  data: 0.0802  max mem: 7105
Train: Epoch[41/60] Total time: 0:00:25 (2.5254 s / it)
Averaged stats: Lr: 0.000063  Loss: 0.8027  Acc@1: 68.7500 (71.3333)  Acc@5: 85.9375 (86.5000)
Train: Epoch[42/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000057  Loss: 0.5118  Acc@1: 82.8125 (82.8125)  Acc@5: 90.6250 (90.6250)  time: 3.6722  data: 0.8281  max mem: 7105
Train: Epoch[42/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000057  Loss: 0.6329  Acc@1: 71.8750 (72.3333)  Acc@5: 85.9375 (87.1667)  time: 2.4985  data: 0.0830  max mem: 7105
Train: Epoch[42/60] Total time: 0:00:25 (2.5085 s / it)
Averaged stats: Lr: 0.000057  Loss: 0.6329  Acc@1: 71.8750 (72.3333)  Acc@5: 85.9375 (87.1667)
Train: Epoch[43/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000052  Loss: 0.6165  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  time: 3.5575  data: 0.7501  max mem: 7105
Train: Epoch[43/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000052  Loss: 0.9119  Acc@1: 68.7500 (69.6667)  Acc@5: 85.9375 (86.0000)  time: 2.4925  data: 0.0751  max mem: 7105
Train: Epoch[43/60] Total time: 0:00:25 (2.5006 s / it)
Averaged stats: Lr: 0.000052  Loss: 0.9119  Acc@1: 68.7500 (69.6667)  Acc@5: 85.9375 (86.0000)
Train: Epoch[44/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000046  Loss: 0.7017  Acc@1: 73.4375 (73.4375)  Acc@5: 82.8125 (82.8125)  time: 3.6719  data: 0.8228  max mem: 7105
Train: Epoch[44/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000046  Loss: 0.3860  Acc@1: 70.3125 (69.3333)  Acc@5: 84.3750 (85.1667)  time: 2.5028  data: 0.0824  max mem: 7105
Train: Epoch[44/60] Total time: 0:00:25 (2.5133 s / it)
Averaged stats: Lr: 0.000046  Loss: 0.3860  Acc@1: 70.3125 (69.3333)  Acc@5: 84.3750 (85.1667)
Train: Epoch[45/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000041  Loss: 0.5825  Acc@1: 71.8750 (71.8750)  Acc@5: 85.9375 (85.9375)  time: 3.6539  data: 0.8115  max mem: 7105
Train: Epoch[45/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000041  Loss: 0.5298  Acc@1: 68.7500 (67.3333)  Acc@5: 84.3750 (84.6667)  time: 2.5093  data: 0.0813  max mem: 7105
Train: Epoch[45/60] Total time: 0:00:25 (2.5178 s / it)
Averaged stats: Lr: 0.000041  Loss: 0.5298  Acc@1: 68.7500 (67.3333)  Acc@5: 84.3750 (84.6667)
Train: Epoch[46/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000037  Loss: 0.5655  Acc@1: 75.0000 (75.0000)  Acc@5: 84.3750 (84.3750)  time: 3.7402  data: 0.7853  max mem: 7105
Train: Epoch[46/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000037  Loss: 0.2988  Acc@1: 70.3125 (70.3333)  Acc@5: 84.3750 (83.8333)  time: 2.5048  data: 0.0787  max mem: 7105
Train: Epoch[46/60] Total time: 0:00:25 (2.5140 s / it)
Averaged stats: Lr: 0.000037  Loss: 0.2988  Acc@1: 70.3125 (70.3333)  Acc@5: 84.3750 (83.8333)
Train: Epoch[47/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000032  Loss: 0.4181  Acc@1: 71.8750 (71.8750)  Acc@5: 90.6250 (90.6250)  time: 3.6144  data: 0.7544  max mem: 7105
Train: Epoch[47/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000032  Loss: 0.7206  Acc@1: 70.3125 (70.0000)  Acc@5: 84.3750 (85.8333)  time: 2.4978  data: 0.0756  max mem: 7105
Train: Epoch[47/60] Total time: 0:00:25 (2.5073 s / it)
Averaged stats: Lr: 0.000032  Loss: 0.7206  Acc@1: 70.3125 (70.0000)  Acc@5: 84.3750 (85.8333)
Train: Epoch[48/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000028  Loss: 0.6694  Acc@1: 65.6250 (65.6250)  Acc@5: 81.2500 (81.2500)  time: 3.6351  data: 0.8337  max mem: 7105
Train: Epoch[48/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000028  Loss: 0.3460  Acc@1: 67.1875 (70.5000)  Acc@5: 85.9375 (84.8333)  time: 2.4986  data: 0.0835  max mem: 7105
Train: Epoch[48/60] Total time: 0:00:25 (2.5089 s / it)
Averaged stats: Lr: 0.000028  Loss: 0.3460  Acc@1: 67.1875 (70.5000)  Acc@5: 85.9375 (84.8333)
Train: Epoch[49/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000024  Loss: 0.6312  Acc@1: 68.7500 (68.7500)  Acc@5: 79.6875 (79.6875)  time: 3.6034  data: 0.7838  max mem: 7105
Train: Epoch[49/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000024  Loss: 0.5516  Acc@1: 75.0000 (75.1667)  Acc@5: 87.5000 (87.1667)  time: 2.5135  data: 0.0785  max mem: 7105
Train: Epoch[49/60] Total time: 0:00:25 (2.5222 s / it)
Averaged stats: Lr: 0.000024  Loss: 0.5516  Acc@1: 75.0000 (75.1667)  Acc@5: 87.5000 (87.1667)
Train: Epoch[50/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000020  Loss: 0.5236  Acc@1: 73.4375 (73.4375)  Acc@5: 87.5000 (87.5000)  time: 3.6139  data: 0.7562  max mem: 7105
Train: Epoch[50/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000020  Loss: 0.3754  Acc@1: 67.1875 (70.8333)  Acc@5: 82.8125 (85.5000)  time: 2.4945  data: 0.0758  max mem: 7105
Train: Epoch[50/60] Total time: 0:00:25 (2.5046 s / it)
Averaged stats: Lr: 0.000020  Loss: 0.3754  Acc@1: 67.1875 (70.8333)  Acc@5: 82.8125 (85.5000)
Train: Epoch[51/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000017  Loss: 0.5199  Acc@1: 71.8750 (71.8750)  Acc@5: 90.6250 (90.6250)  time: 3.5962  data: 0.7784  max mem: 7105
Train: Epoch[51/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000017  Loss: 0.2986  Acc@1: 71.8750 (71.8333)  Acc@5: 89.0625 (87.5000)  time: 2.4997  data: 0.0780  max mem: 7105
Train: Epoch[51/60] Total time: 0:00:25 (2.5082 s / it)
Averaged stats: Lr: 0.000017  Loss: 0.2986  Acc@1: 71.8750 (71.8333)  Acc@5: 89.0625 (87.5000)
Train: Epoch[52/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000014  Loss: 0.4268  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)  time: 3.5632  data: 0.7412  max mem: 7105
Train: Epoch[52/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000014  Loss: 0.3033  Acc@1: 73.4375 (72.1667)  Acc@5: 85.9375 (85.6667)  time: 2.5047  data: 0.0743  max mem: 7105
Train: Epoch[52/60] Total time: 0:00:25 (2.5151 s / it)
Averaged stats: Lr: 0.000014  Loss: 0.3033  Acc@1: 73.4375 (72.1667)  Acc@5: 85.9375 (85.6667)
Train: Epoch[53/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000011  Loss: 0.5816  Acc@1: 70.3125 (70.3125)  Acc@5: 85.9375 (85.9375)  time: 3.5602  data: 0.7542  max mem: 7105
Train: Epoch[53/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000011  Loss: 0.5197  Acc@1: 70.3125 (70.5000)  Acc@5: 87.5000 (88.0000)  time: 2.4758  data: 0.0755  max mem: 7105
Train: Epoch[53/60] Total time: 0:00:24 (2.4837 s / it)
Averaged stats: Lr: 0.000011  Loss: 0.5197  Acc@1: 70.3125 (70.5000)  Acc@5: 87.5000 (88.0000)
Train: Epoch[54/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000008  Loss: 0.4232  Acc@1: 70.3125 (70.3125)  Acc@5: 90.6250 (90.6250)  time: 3.5603  data: 0.7364  max mem: 7105
Train: Epoch[54/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000008  Loss: 0.6375  Acc@1: 71.8750 (73.3333)  Acc@5: 87.5000 (87.5000)  time: 2.4835  data: 0.0738  max mem: 7105
Train: Epoch[54/60] Total time: 0:00:24 (2.4923 s / it)
Averaged stats: Lr: 0.000008  Loss: 0.6375  Acc@1: 71.8750 (73.3333)  Acc@5: 87.5000 (87.5000)
Train: Epoch[55/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000006  Loss: 0.4579  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)  time: 3.6594  data: 0.8494  max mem: 7105
Train: Epoch[55/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000006  Loss: 0.4478  Acc@1: 71.8750 (71.8333)  Acc@5: 85.9375 (85.6667)  time: 2.4982  data: 0.0851  max mem: 7105
Train: Epoch[55/60] Total time: 0:00:25 (2.5067 s / it)
Averaged stats: Lr: 0.000006  Loss: 0.4478  Acc@1: 71.8750 (71.8333)  Acc@5: 85.9375 (85.6667)
Train: Epoch[56/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000004  Loss: 0.3953  Acc@1: 82.8125 (82.8125)  Acc@5: 87.5000 (87.5000)  time: 3.8134  data: 0.7444  max mem: 7105
Train: Epoch[56/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000004  Loss: 0.4405  Acc@1: 71.8750 (71.0000)  Acc@5: 87.5000 (87.5000)  time: 2.5149  data: 0.0746  max mem: 7105
Train: Epoch[56/60] Total time: 0:00:25 (2.5245 s / it)
Averaged stats: Lr: 0.000004  Loss: 0.4405  Acc@1: 71.8750 (71.0000)  Acc@5: 87.5000 (87.5000)
Train: Epoch[57/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000003  Loss: 0.7171  Acc@1: 65.6250 (65.6250)  Acc@5: 81.2500 (81.2500)  time: 3.5406  data: 0.7024  max mem: 7105
Train: Epoch[57/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000003  Loss: 0.5162  Acc@1: 71.8750 (71.6667)  Acc@5: 87.5000 (86.8333)  time: 2.4866  data: 0.0704  max mem: 7105
Train: Epoch[57/60] Total time: 0:00:24 (2.4952 s / it)
Averaged stats: Lr: 0.000003  Loss: 0.5162  Acc@1: 71.8750 (71.6667)  Acc@5: 87.5000 (86.8333)
Train: Epoch[58/60]  [ 0/10]  eta: 0:00:35  Lr: 0.000002  Loss: 0.4807  Acc@1: 73.4375 (73.4375)  Acc@5: 87.5000 (87.5000)  time: 3.5901  data: 0.7147  max mem: 7105
Train: Epoch[58/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000002  Loss: 0.4790  Acc@1: 71.8750 (71.5000)  Acc@5: 85.9375 (87.0000)  time: 2.4929  data: 0.0716  max mem: 7105
Train: Epoch[58/60] Total time: 0:00:25 (2.5026 s / it)
Averaged stats: Lr: 0.000002  Loss: 0.4790  Acc@1: 71.8750 (71.5000)  Acc@5: 85.9375 (87.0000)
Train: Epoch[59/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000001  Loss: 0.6121  Acc@1: 75.0000 (75.0000)  Acc@5: 82.8125 (82.8125)  time: 3.6399  data: 0.7370  max mem: 7105
Train: Epoch[59/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000001  Loss: 0.7267  Acc@1: 68.7500 (72.1667)  Acc@5: 85.9375 (86.0000)  time: 2.5198  data: 0.0738  max mem: 7105
Train: Epoch[59/60] Total time: 0:00:25 (2.5285 s / it)
Averaged stats: Lr: 0.000001  Loss: 0.7267  Acc@1: 68.7500 (72.1667)  Acc@5: 85.9375 (86.0000)
Train: Epoch[60/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000000  Loss: 0.5552  Acc@1: 75.0000 (75.0000)  Acc@5: 84.3750 (84.3750)  time: 3.6760  data: 0.7492  max mem: 7105
Train: Epoch[60/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000000  Loss: 0.4034  Acc@1: 71.8750 (71.3333)  Acc@5: 87.5000 (87.1667)  time: 2.5036  data: 0.0751  max mem: 7105
Train: Epoch[60/60] Total time: 0:00:25 (2.5133 s / it)
Averaged stats: Lr: 0.000000  Loss: 0.4034  Acc@1: 71.8750 (71.3333)  Acc@5: 87.5000 (87.1667)
Test: [Task 1]  [0/9]  eta: 0:00:16  Loss: 0.4950 (0.4950)  Acc@1: 92.1875 (92.1875)  Acc@5: 98.4375 (98.4375)  time: 1.7955  data: 0.8820  max mem: 7105
Test: [Task 1]  [8/9]  eta: 0:00:00  Loss: 0.2986 (0.3711)  Acc@1: 96.8750 (91.8447)  Acc@5: 100.0000 (99.0291)  time: 0.7865  data: 0.0982  max mem: 7105
Test: [Task 1] Total time: 0:00:07 (0.7953 s / it)
* Acc@1 91.845 Acc@5 99.029 loss 0.371
Batchwise eval time for task 1 = 0.795272085401747
Test: [Task 2]  [0/9]  eta: 0:00:16  Loss: 0.6680 (0.6680)  Acc@1: 82.8125 (82.8125)  Acc@5: 100.0000 (100.0000)  time: 1.8275  data: 0.9249  max mem: 7105
Test: [Task 2]  [8/9]  eta: 0:00:00  Loss: 1.1347 (1.1028)  Acc@1: 56.2500 (67.6522)  Acc@5: 98.4375 (98.2609)  time: 0.8398  data: 0.1029  max mem: 7105
Test: [Task 2] Total time: 0:00:07 (0.8487 s / it)
* Acc@1 67.652 Acc@5 98.261 loss 1.103
Batchwise eval time for task 2 = 0.8486833307478163
Test: [Task 3]  [ 0/10]  eta: 0:00:18  Loss: 0.4550 (0.4550)  Acc@1: 95.3125 (95.3125)  Acc@5: 98.4375 (98.4375)  time: 1.8562  data: 0.9887  max mem: 7105
Test: [Task 3]  [ 9/10]  eta: 0:00:00  Loss: 0.4942 (0.6663)  Acc@1: 95.3125 (90.7718)  Acc@5: 98.4375 (98.6577)  time: 0.7948  data: 0.0992  max mem: 7105
Test: [Task 3] Total time: 0:00:08 (0.8024 s / it)
* Acc@1 90.772 Acc@5 98.658 loss 0.666
Batchwise eval time for task 3 = 0.8024697303771973
Test: [Task 4]  [ 0/10]  eta: 0:00:17  Loss: 1.3222 (1.3222)  Acc@1: 56.2500 (56.2500)  Acc@5: 95.3125 (95.3125)  time: 1.7591  data: 0.8667  max mem: 7105
Test: [Task 4]  [ 9/10]  eta: 0:00:00  Loss: 0.8193 (0.8520)  Acc@1: 81.2500 (80.5461)  Acc@5: 98.4375 (98.6348)  time: 0.7809  data: 0.0868  max mem: 7105
Test: [Task 4] Total time: 0:00:07 (0.7896 s / it)
* Acc@1 80.546 Acc@5 98.635 loss 0.852
Batchwise eval time for task 4 = 0.7896391391754151
Test: [Task 5]  [ 0/10]  eta: 0:00:19  Loss: 0.5519 (0.5519)  Acc@1: 85.9375 (85.9375)  Acc@5: 100.0000 (100.0000)  time: 1.9379  data: 1.0091  max mem: 7105
Test: [Task 5]  [ 9/10]  eta: 0:00:00  Loss: 0.4781 (0.5647)  Acc@1: 93.7500 (93.0743)  Acc@5: 98.4375 (98.3108)  time: 0.8002  data: 0.1011  max mem: 7105
Test: [Task 5] Total time: 0:00:08 (0.8083 s / it)
* Acc@1 93.074 Acc@5 98.311 loss 0.565
Batchwise eval time for task 5 = 0.8083554983139039
Test: [Task 6]  [0/9]  eta: 0:00:16  Loss: 0.7688 (0.7688)  Acc@1: 90.6250 (90.6250)  Acc@5: 98.4375 (98.4375)  time: 1.8625  data: 0.9914  max mem: 7105
Test: [Task 6]  [8/9]  eta: 0:00:00  Loss: 0.8844 (0.9281)  Acc@1: 87.5000 (84.6290)  Acc@5: 96.8750 (97.5265)  time: 0.8391  data: 0.1103  max mem: 7105
Test: [Task 6] Total time: 0:00:07 (0.8477 s / it)
* Acc@1 84.629 Acc@5 97.527 loss 0.928
Batchwise eval time for task 6 = 0.8477343453301324
Test: [Task 7]  [ 0/10]  eta: 0:00:18  Loss: 1.2129 (1.2129)  Acc@1: 79.6875 (79.6875)  Acc@5: 96.8750 (96.8750)  time: 1.8037  data: 0.8976  max mem: 7105
Test: [Task 7]  [ 9/10]  eta: 0:00:00  Loss: 0.7968 (1.0891)  Acc@1: 79.6875 (79.4314)  Acc@5: 96.8750 (96.4883)  time: 0.7919  data: 0.0899  max mem: 7105
Test: [Task 7] Total time: 0:00:07 (0.7996 s / it)
* Acc@1 79.431 Acc@5 96.488 loss 1.089
Batchwise eval time for task 7 = 0.7996650457382202
Test: [Task 8]  [ 0/10]  eta: 0:00:18  Loss: 1.5796 (1.5796)  Acc@1: 81.2500 (81.2500)  Acc@5: 96.8750 (96.8750)  time: 1.8037  data: 0.8631  max mem: 7105
Test: [Task 8]  [ 9/10]  eta: 0:00:00  Loss: 1.0524 (1.1222)  Acc@1: 81.2500 (78.1570)  Acc@5: 96.8750 (97.6109)  time: 0.7847  data: 0.0865  max mem: 7105
Test: [Task 8] Total time: 0:00:07 (0.7935 s / it)
* Acc@1 78.157 Acc@5 97.611 loss 1.122
Batchwise eval time for task 8 = 0.7935204982757569
Test: [Task 9]  [ 0/10]  eta: 0:00:19  Loss: 1.7040 (1.7040)  Acc@1: 64.0625 (64.0625)  Acc@5: 90.6250 (90.6250)  time: 1.9137  data: 1.0392  max mem: 7105
Test: [Task 9]  [ 9/10]  eta: 0:00:00  Loss: 1.1623 (1.2517)  Acc@1: 85.9375 (81.4189)  Acc@5: 93.7500 (95.2703)  time: 0.7999  data: 0.1041  max mem: 7105
Test: [Task 9] Total time: 0:00:08 (0.8079 s / it)
* Acc@1 81.419 Acc@5 95.270 loss 1.252
Batchwise eval time for task 9 = 0.807930850982666
[Average accuracy till task9]	Acc@1: 82.9812	Acc@5: 97.7544	Loss: 0.8831	Forgetting: 3.3199	Backward: -2.8933
Eval time for task 9 = 70.74571228027344
Using adam optimizer
Reinitialising optimizer
Similarity:  tensor(0.9008)  Task:  9
Old Num K:  13 New Num K:  14
Task number:  9
Train: Epoch[ 1/60]  [ 0/10]  eta: 0:00:39  Lr: 0.000250  Loss: 3.1563  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  time: 3.9200  data: 0.7235  max mem: 7148
Train: Epoch[ 1/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000250  Loss: 3.3714  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.3344)  time: 2.6271  data: 0.0725  max mem: 7158
Train: Epoch[ 1/60] Total time: 0:00:26 (2.6380 s / it)
Averaged stats: Lr: 0.000250  Loss: 3.3714  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.3344)
Train: Epoch[ 2/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000250  Loss: 2.8602  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  time: 3.8077  data: 0.9217  max mem: 7158
Train: Epoch[ 2/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000250  Loss: 2.4370  Acc@1: 0.0000 (1.1706)  Acc@5: 7.8125 (6.5217)  time: 2.6340  data: 0.0923  max mem: 7158
Train: Epoch[ 2/60] Total time: 0:00:26 (2.6426 s / it)
Averaged stats: Lr: 0.000250  Loss: 2.4370  Acc@1: 0.0000 (1.1706)  Acc@5: 7.8125 (6.5217)
Train: Epoch[ 3/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000249  Loss: 2.1928  Acc@1: 1.5625 (1.5625)  Acc@5: 17.1875 (17.1875)  time: 3.7524  data: 0.7129  max mem: 7158
Train: Epoch[ 3/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000249  Loss: 1.8640  Acc@1: 3.1250 (5.1839)  Acc@5: 31.2500 (31.6054)  time: 2.6112  data: 0.0714  max mem: 7158
Train: Epoch[ 3/60] Total time: 0:00:26 (2.6190 s / it)
Averaged stats: Lr: 0.000249  Loss: 1.8640  Acc@1: 3.1250 (5.1839)  Acc@5: 31.2500 (31.6054)
Train: Epoch[ 4/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000248  Loss: 1.8226  Acc@1: 10.9375 (10.9375)  Acc@5: 51.5625 (51.5625)  time: 3.8200  data: 0.8437  max mem: 7158
Train: Epoch[ 4/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000248  Loss: 1.5583  Acc@1: 17.1875 (18.8963)  Acc@5: 56.2500 (57.8595)  time: 2.6228  data: 0.0845  max mem: 7158
Train: Epoch[ 4/60] Total time: 0:00:26 (2.6335 s / it)
Averaged stats: Lr: 0.000248  Loss: 1.5583  Acc@1: 17.1875 (18.8963)  Acc@5: 56.2500 (57.8595)
Train: Epoch[ 5/60]  [ 0/10]  eta: 0:00:39  Lr: 0.000247  Loss: 1.5918  Acc@1: 25.0000 (25.0000)  Acc@5: 64.0625 (64.0625)  time: 3.9892  data: 0.8645  max mem: 7158
Train: Epoch[ 5/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000247  Loss: 1.3619  Acc@1: 32.8125 (33.7793)  Acc@5: 76.5625 (73.7458)  time: 2.6339  data: 0.0866  max mem: 7158
Train: Epoch[ 5/60] Total time: 0:00:26 (2.6423 s / it)
Averaged stats: Lr: 0.000247  Loss: 1.3619  Acc@1: 32.8125 (33.7793)  Acc@5: 76.5625 (73.7458)
Train: Epoch[ 6/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000246  Loss: 1.2711  Acc@1: 40.6250 (40.6250)  Acc@5: 84.3750 (84.3750)  time: 3.7181  data: 0.7811  max mem: 7158
Train: Epoch[ 6/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000246  Loss: 1.0664  Acc@1: 46.8750 (47.4916)  Acc@5: 84.3750 (82.7759)  time: 2.6125  data: 0.0782  max mem: 7158
Train: Epoch[ 6/60] Total time: 0:00:26 (2.6208 s / it)
Averaged stats: Lr: 0.000246  Loss: 1.0664  Acc@1: 46.8750 (47.4916)  Acc@5: 84.3750 (82.7759)
Train: Epoch[ 7/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000244  Loss: 1.0721  Acc@1: 60.9375 (60.9375)  Acc@5: 87.5000 (87.5000)  time: 3.7129  data: 0.7789  max mem: 7158
Train: Epoch[ 7/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000244  Loss: 0.8549  Acc@1: 59.3750 (60.3679)  Acc@5: 87.5000 (86.7893)  time: 2.6052  data: 0.0780  max mem: 7158
Train: Epoch[ 7/60] Total time: 0:00:26 (2.6140 s / it)
Averaged stats: Lr: 0.000244  Loss: 0.8549  Acc@1: 59.3750 (60.3679)  Acc@5: 87.5000 (86.7893)
Train: Epoch[ 8/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000242  Loss: 1.1124  Acc@1: 53.1250 (53.1250)  Acc@5: 79.6875 (79.6875)  time: 3.7937  data: 0.7265  max mem: 7158
Train: Epoch[ 8/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000242  Loss: 0.8159  Acc@1: 65.6250 (65.5518)  Acc@5: 89.0625 (87.4582)  time: 2.6154  data: 0.0728  max mem: 7158
Train: Epoch[ 8/60] Total time: 0:00:26 (2.6235 s / it)
Averaged stats: Lr: 0.000242  Loss: 0.8159  Acc@1: 65.6250 (65.5518)  Acc@5: 89.0625 (87.4582)
Train: Epoch[ 9/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000239  Loss: 1.0456  Acc@1: 60.9375 (60.9375)  Acc@5: 79.6875 (79.6875)  time: 3.8013  data: 0.9231  max mem: 7158
Train: Epoch[ 9/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000239  Loss: 0.8229  Acc@1: 70.3125 (70.7358)  Acc@5: 89.0625 (88.1271)  time: 2.6227  data: 0.0924  max mem: 7158
Train: Epoch[ 9/60] Total time: 0:00:26 (2.6311 s / it)
Averaged stats: Lr: 0.000239  Loss: 0.8229  Acc@1: 70.3125 (70.7358)  Acc@5: 89.0625 (88.1271)
Train: Epoch[10/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000236  Loss: 0.9090  Acc@1: 70.3125 (70.3125)  Acc@5: 93.7500 (93.7500)  time: 3.7913  data: 0.7350  max mem: 7158
Train: Epoch[10/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000236  Loss: 0.8660  Acc@1: 70.3125 (70.5686)  Acc@5: 89.0625 (88.7960)  time: 2.6082  data: 0.0737  max mem: 7158
Train: Epoch[10/60] Total time: 0:00:26 (2.6186 s / it)
Averaged stats: Lr: 0.000236  Loss: 0.8660  Acc@1: 70.3125 (70.5686)  Acc@5: 89.0625 (88.7960)
Train: Epoch[11/60]  [ 0/10]  eta: 0:00:39  Lr: 0.000233  Loss: 0.8403  Acc@1: 67.1875 (67.1875)  Acc@5: 85.9375 (85.9375)  time: 3.9577  data: 0.7295  max mem: 7158
Train: Epoch[11/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000233  Loss: 0.5540  Acc@1: 73.4375 (74.7492)  Acc@5: 92.1875 (90.4682)  time: 2.6285  data: 0.0731  max mem: 7158
Train: Epoch[11/60] Total time: 0:00:26 (2.6370 s / it)
Averaged stats: Lr: 0.000233  Loss: 0.5540  Acc@1: 73.4375 (74.7492)  Acc@5: 92.1875 (90.4682)
Train: Epoch[12/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000230  Loss: 0.7759  Acc@1: 73.4375 (73.4375)  Acc@5: 90.6250 (90.6250)  time: 3.7287  data: 0.8898  max mem: 7158
Train: Epoch[12/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000230  Loss: 0.9003  Acc@1: 75.0000 (76.2542)  Acc@5: 89.0625 (89.7993)  time: 2.6145  data: 0.0891  max mem: 7158
Train: Epoch[12/60] Total time: 0:00:26 (2.6225 s / it)
Averaged stats: Lr: 0.000230  Loss: 0.9003  Acc@1: 75.0000 (76.2542)  Acc@5: 89.0625 (89.7993)
Train: Epoch[13/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000226  Loss: 0.6916  Acc@1: 79.6875 (79.6875)  Acc@5: 90.6250 (90.6250)  time: 3.7857  data: 0.8654  max mem: 7158
Train: Epoch[13/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000226  Loss: 1.0272  Acc@1: 78.1250 (77.2575)  Acc@5: 89.0625 (90.1338)  time: 2.6324  data: 0.0867  max mem: 7158
Train: Epoch[13/60] Total time: 0:00:26 (2.6434 s / it)
Averaged stats: Lr: 0.000226  Loss: 1.0272  Acc@1: 78.1250 (77.2575)  Acc@5: 89.0625 (90.1338)
Train: Epoch[14/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000222  Loss: 0.6930  Acc@1: 85.9375 (85.9375)  Acc@5: 92.1875 (92.1875)  time: 3.8325  data: 0.7847  max mem: 7158
Train: Epoch[14/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000222  Loss: 0.7013  Acc@1: 82.8125 (80.6020)  Acc@5: 92.1875 (91.6388)  time: 2.6351  data: 0.0786  max mem: 7158
Train: Epoch[14/60] Total time: 0:00:26 (2.6435 s / it)
Averaged stats: Lr: 0.000222  Loss: 0.7013  Acc@1: 82.8125 (80.6020)  Acc@5: 92.1875 (91.6388)
Train: Epoch[15/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000218  Loss: 0.7794  Acc@1: 79.6875 (79.6875)  Acc@5: 89.0625 (89.0625)  time: 3.8039  data: 0.7946  max mem: 7158
Train: Epoch[15/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000218  Loss: 0.8925  Acc@1: 79.6875 (81.2709)  Acc@5: 90.9091 (91.3043)  time: 2.6183  data: 0.0796  max mem: 7158
Train: Epoch[15/60] Total time: 0:00:26 (2.6266 s / it)
Averaged stats: Lr: 0.000218  Loss: 0.8925  Acc@1: 79.6875 (81.2709)  Acc@5: 90.9091 (91.3043)
Train: Epoch[16/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000213  Loss: 0.7527  Acc@1: 75.0000 (75.0000)  Acc@5: 85.9375 (85.9375)  time: 3.7780  data: 0.8876  max mem: 7158
Train: Epoch[16/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000213  Loss: 0.3397  Acc@1: 84.3750 (83.1104)  Acc@5: 90.6250 (91.8060)  time: 2.6395  data: 0.0889  max mem: 7158
Train: Epoch[16/60] Total time: 0:00:26 (2.6490 s / it)
Averaged stats: Lr: 0.000213  Loss: 0.3397  Acc@1: 84.3750 (83.1104)  Acc@5: 90.6250 (91.8060)
Train: Epoch[17/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000209  Loss: 0.5214  Acc@1: 89.0625 (89.0625)  Acc@5: 96.8750 (96.8750)  time: 3.8017  data: 0.7493  max mem: 7158
Train: Epoch[17/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000209  Loss: 0.4176  Acc@1: 82.8125 (82.7759)  Acc@5: 92.1875 (92.1405)  time: 2.6195  data: 0.0751  max mem: 7158
Train: Epoch[17/60] Total time: 0:00:26 (2.6278 s / it)
Averaged stats: Lr: 0.000209  Loss: 0.4176  Acc@1: 82.8125 (82.7759)  Acc@5: 92.1875 (92.1405)
Train: Epoch[18/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000204  Loss: 0.5227  Acc@1: 87.5000 (87.5000)  Acc@5: 96.8750 (96.8750)  time: 3.7145  data: 0.8059  max mem: 7158
Train: Epoch[18/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000204  Loss: 0.6387  Acc@1: 79.6875 (83.2776)  Acc@5: 93.7500 (93.8127)  time: 2.6350  data: 0.0807  max mem: 7158
Train: Epoch[18/60] Total time: 0:00:26 (2.6440 s / it)
Averaged stats: Lr: 0.000204  Loss: 0.6387  Acc@1: 79.6875 (83.2776)  Acc@5: 93.7500 (93.8127)
Train: Epoch[19/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000198  Loss: 0.6837  Acc@1: 84.3750 (84.3750)  Acc@5: 90.6250 (90.6250)  time: 3.7491  data: 0.7832  max mem: 7158
Train: Epoch[19/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000198  Loss: 0.6936  Acc@1: 82.8125 (83.4448)  Acc@5: 90.9091 (92.6421)  time: 2.6110  data: 0.0785  max mem: 7158
Train: Epoch[19/60] Total time: 0:00:26 (2.6224 s / it)
Averaged stats: Lr: 0.000198  Loss: 0.6936  Acc@1: 82.8125 (83.4448)  Acc@5: 90.9091 (92.6421)
Train: Epoch[20/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000193  Loss: 0.6236  Acc@1: 79.6875 (79.6875)  Acc@5: 92.1875 (92.1875)  time: 3.8658  data: 0.7690  max mem: 7158
Train: Epoch[20/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000193  Loss: 0.5740  Acc@1: 85.9375 (84.4482)  Acc@5: 95.3125 (93.4783)  time: 2.6443  data: 0.0770  max mem: 7158
Train: Epoch[20/60] Total time: 0:00:26 (2.6529 s / it)
Averaged stats: Lr: 0.000193  Loss: 0.5740  Acc@1: 85.9375 (84.4482)  Acc@5: 95.3125 (93.4783)
Train: Epoch[21/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000188  Loss: 0.5395  Acc@1: 84.3750 (84.3750)  Acc@5: 93.7500 (93.7500)  time: 3.7580  data: 0.7648  max mem: 7158
Train: Epoch[21/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000188  Loss: 0.5746  Acc@1: 82.8125 (83.7793)  Acc@5: 93.7500 (93.9799)  time: 2.6093  data: 0.0766  max mem: 7158
Train: Epoch[21/60] Total time: 0:00:26 (2.6175 s / it)
Averaged stats: Lr: 0.000188  Loss: 0.5746  Acc@1: 82.8125 (83.7793)  Acc@5: 93.7500 (93.9799)
Train: Epoch[22/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000182  Loss: 0.4301  Acc@1: 89.0625 (89.0625)  Acc@5: 100.0000 (100.0000)  time: 3.7434  data: 0.7742  max mem: 7158
Train: Epoch[22/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000182  Loss: 0.5009  Acc@1: 85.9375 (85.2843)  Acc@5: 93.7500 (93.6455)  time: 2.6295  data: 0.0775  max mem: 7158
Train: Epoch[22/60] Total time: 0:00:26 (2.6395 s / it)
Averaged stats: Lr: 0.000182  Loss: 0.5009  Acc@1: 85.9375 (85.2843)  Acc@5: 93.7500 (93.6455)
Train: Epoch[23/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000176  Loss: 0.5987  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)  time: 3.7576  data: 0.8099  max mem: 7158
Train: Epoch[23/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000176  Loss: 0.5506  Acc@1: 82.8125 (85.7860)  Acc@5: 93.7500 (94.1472)  time: 2.6125  data: 0.0811  max mem: 7158
Train: Epoch[23/60] Total time: 0:00:26 (2.6210 s / it)
Averaged stats: Lr: 0.000176  Loss: 0.5506  Acc@1: 82.8125 (85.7860)  Acc@5: 93.7500 (94.1472)
Train: Epoch[24/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000170  Loss: 0.4335  Acc@1: 85.9375 (85.9375)  Acc@5: 96.8750 (96.8750)  time: 3.7919  data: 0.8902  max mem: 7158
Train: Epoch[24/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000170  Loss: 0.4111  Acc@1: 85.9375 (85.2843)  Acc@5: 95.3125 (94.8161)  time: 2.6302  data: 0.0892  max mem: 7158
Train: Epoch[24/60] Total time: 0:00:26 (2.6387 s / it)
Averaged stats: Lr: 0.000170  Loss: 0.4111  Acc@1: 85.9375 (85.2843)  Acc@5: 95.3125 (94.8161)
Train: Epoch[25/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000164  Loss: 0.5197  Acc@1: 84.3750 (84.3750)  Acc@5: 95.3125 (95.3125)  time: 3.8078  data: 0.7709  max mem: 7158
Train: Epoch[25/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000164  Loss: 0.4722  Acc@1: 86.3636 (88.6288)  Acc@5: 96.8750 (96.6555)  time: 2.6206  data: 0.0772  max mem: 7158
Train: Epoch[25/60] Total time: 0:00:26 (2.6315 s / it)
Averaged stats: Lr: 0.000164  Loss: 0.4722  Acc@1: 86.3636 (88.6288)  Acc@5: 96.8750 (96.6555)
Train: Epoch[26/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000157  Loss: 0.5140  Acc@1: 87.5000 (87.5000)  Acc@5: 95.3125 (95.3125)  time: 3.7518  data: 0.7478  max mem: 7158
Train: Epoch[26/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000157  Loss: 0.4022  Acc@1: 85.9375 (86.1204)  Acc@5: 93.7500 (92.6421)  time: 2.6001  data: 0.0749  max mem: 7158
Train: Epoch[26/60] Total time: 0:00:26 (2.6081 s / it)
Averaged stats: Lr: 0.000157  Loss: 0.4022  Acc@1: 85.9375 (86.1204)  Acc@5: 93.7500 (92.6421)
Train: Epoch[27/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000151  Loss: 0.4801  Acc@1: 87.5000 (87.5000)  Acc@5: 95.3125 (95.3125)  time: 3.7008  data: 0.7119  max mem: 7158
Train: Epoch[27/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000151  Loss: 0.4129  Acc@1: 87.5000 (87.2910)  Acc@5: 93.7500 (94.1472)  time: 2.6276  data: 0.0713  max mem: 7158
Train: Epoch[27/60] Total time: 0:00:26 (2.6361 s / it)
Averaged stats: Lr: 0.000151  Loss: 0.4129  Acc@1: 87.5000 (87.2910)  Acc@5: 93.7500 (94.1472)
Train: Epoch[28/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000145  Loss: 0.4082  Acc@1: 92.1875 (92.1875)  Acc@5: 95.3125 (95.3125)  time: 3.7801  data: 0.8768  max mem: 7158
Train: Epoch[28/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000145  Loss: 0.5069  Acc@1: 84.3750 (86.7893)  Acc@5: 93.7500 (93.4783)  time: 2.6163  data: 0.0878  max mem: 7158
Train: Epoch[28/60] Total time: 0:00:26 (2.6269 s / it)
Averaged stats: Lr: 0.000145  Loss: 0.5069  Acc@1: 84.3750 (86.7893)  Acc@5: 93.7500 (93.4783)
Train: Epoch[29/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000138  Loss: 0.4249  Acc@1: 89.0625 (89.0625)  Acc@5: 93.7500 (93.7500)  time: 3.7618  data: 0.8466  max mem: 7158
Train: Epoch[29/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000138  Loss: 0.5440  Acc@1: 84.3750 (85.2843)  Acc@5: 92.1875 (92.8094)  time: 2.6149  data: 0.0848  max mem: 7158
Train: Epoch[29/60] Total time: 0:00:26 (2.6230 s / it)
Averaged stats: Lr: 0.000138  Loss: 0.5440  Acc@1: 84.3750 (85.2843)  Acc@5: 92.1875 (92.8094)
Train: Epoch[30/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000132  Loss: 0.3317  Acc@1: 89.0625 (89.0625)  Acc@5: 98.4375 (98.4375)  time: 3.6968  data: 0.8530  max mem: 7158
Train: Epoch[30/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000132  Loss: 0.4113  Acc@1: 87.5000 (87.4582)  Acc@5: 95.3125 (94.8161)  time: 2.6144  data: 0.0854  max mem: 7158
Train: Epoch[30/60] Total time: 0:00:26 (2.6225 s / it)
Averaged stats: Lr: 0.000132  Loss: 0.4113  Acc@1: 87.5000 (87.4582)  Acc@5: 95.3125 (94.8161)
Train: Epoch[31/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000125  Loss: 0.4866  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 3.8624  data: 0.8818  max mem: 7158
Train: Epoch[31/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000125  Loss: 0.4176  Acc@1: 85.9375 (87.6254)  Acc@5: 95.3125 (94.4816)  time: 2.6198  data: 0.0883  max mem: 7158
Train: Epoch[31/60] Total time: 0:00:26 (2.6310 s / it)
Averaged stats: Lr: 0.000125  Loss: 0.4176  Acc@1: 85.9375 (87.6254)  Acc@5: 95.3125 (94.4816)
Train: Epoch[32/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000118  Loss: 0.4277  Acc@1: 85.9375 (85.9375)  Acc@5: 93.7500 (93.7500)  time: 3.7645  data: 0.7830  max mem: 7158
Train: Epoch[32/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000118  Loss: 0.3816  Acc@1: 87.5000 (88.1271)  Acc@5: 95.3125 (94.8161)  time: 2.6064  data: 0.0784  max mem: 7158
Train: Epoch[32/60] Total time: 0:00:26 (2.6141 s / it)
Averaged stats: Lr: 0.000118  Loss: 0.3816  Acc@1: 87.5000 (88.1271)  Acc@5: 95.3125 (94.8161)
Train: Epoch[33/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000112  Loss: 0.4304  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 3.6871  data: 0.7041  max mem: 7158
Train: Epoch[33/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000112  Loss: 0.5818  Acc@1: 89.0625 (88.7960)  Acc@5: 93.7500 (95.3177)  time: 2.5868  data: 0.0706  max mem: 7158
Train: Epoch[33/60] Total time: 0:00:25 (2.5959 s / it)
Averaged stats: Lr: 0.000112  Loss: 0.5818  Acc@1: 89.0625 (88.7960)  Acc@5: 93.7500 (95.3177)
Train: Epoch[34/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000105  Loss: 0.4496  Acc@1: 87.5000 (87.5000)  Acc@5: 92.1875 (92.1875)  time: 3.6495  data: 0.7260  max mem: 7158
Train: Epoch[34/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000105  Loss: 0.6722  Acc@1: 87.5000 (87.7926)  Acc@5: 93.7500 (93.8127)  time: 2.6059  data: 0.0727  max mem: 7158
Train: Epoch[34/60] Total time: 0:00:26 (2.6143 s / it)
Averaged stats: Lr: 0.000105  Loss: 0.6722  Acc@1: 87.5000 (87.7926)  Acc@5: 93.7500 (93.8127)
Train: Epoch[35/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000099  Loss: 0.3569  Acc@1: 87.5000 (87.5000)  Acc@5: 95.3125 (95.3125)  time: 3.6631  data: 0.7078  max mem: 7158
Train: Epoch[35/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000099  Loss: 0.4926  Acc@1: 87.5000 (89.1304)  Acc@5: 95.3125 (95.6522)  time: 2.5944  data: 0.0709  max mem: 7158
Train: Epoch[35/60] Total time: 0:00:26 (2.6025 s / it)
Averaged stats: Lr: 0.000099  Loss: 0.4926  Acc@1: 87.5000 (89.1304)  Acc@5: 95.3125 (95.6522)
Train: Epoch[36/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000093  Loss: 0.5049  Acc@1: 81.2500 (81.2500)  Acc@5: 92.1875 (92.1875)  time: 3.7678  data: 0.7871  max mem: 7158
Train: Epoch[36/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000093  Loss: 0.2942  Acc@1: 89.0625 (87.7926)  Acc@5: 95.4546 (95.9866)  time: 2.6281  data: 0.0788  max mem: 7158
Train: Epoch[36/60] Total time: 0:00:26 (2.6392 s / it)
Averaged stats: Lr: 0.000093  Loss: 0.2942  Acc@1: 89.0625 (87.7926)  Acc@5: 95.4546 (95.9866)
Train: Epoch[37/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000086  Loss: 0.4752  Acc@1: 81.2500 (81.2500)  Acc@5: 96.8750 (96.8750)  time: 3.6472  data: 0.7686  max mem: 7158
Train: Epoch[37/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000086  Loss: 0.3644  Acc@1: 89.0625 (87.1237)  Acc@5: 93.7500 (94.6488)  time: 2.6203  data: 0.0770  max mem: 7158
Train: Epoch[37/60] Total time: 0:00:26 (2.6287 s / it)
Averaged stats: Lr: 0.000086  Loss: 0.3644  Acc@1: 89.0625 (87.1237)  Acc@5: 93.7500 (94.6488)
Train: Epoch[38/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000080  Loss: 0.3985  Acc@1: 90.6250 (90.6250)  Acc@5: 95.3125 (95.3125)  time: 3.8018  data: 0.8531  max mem: 7158
Train: Epoch[38/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000080  Loss: 0.2602  Acc@1: 87.5000 (87.6254)  Acc@5: 95.3125 (93.9799)  time: 2.6159  data: 0.0854  max mem: 7158
Train: Epoch[38/60] Total time: 0:00:26 (2.6238 s / it)
Averaged stats: Lr: 0.000080  Loss: 0.2602  Acc@1: 87.5000 (87.6254)  Acc@5: 95.3125 (93.9799)
Train: Epoch[39/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000074  Loss: 0.2973  Acc@1: 93.7500 (93.7500)  Acc@5: 96.8750 (96.8750)  time: 3.8109  data: 0.8907  max mem: 7158
Train: Epoch[39/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000074  Loss: 0.5742  Acc@1: 87.5000 (87.2910)  Acc@5: 93.7500 (93.9799)  time: 2.6346  data: 0.0892  max mem: 7158
Train: Epoch[39/60] Total time: 0:00:26 (2.6443 s / it)
Averaged stats: Lr: 0.000074  Loss: 0.5742  Acc@1: 87.5000 (87.2910)  Acc@5: 93.7500 (93.9799)
Train: Epoch[40/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000068  Loss: 0.5869  Acc@1: 81.2500 (81.2500)  Acc@5: 87.5000 (87.5000)  time: 3.7092  data: 0.7421  max mem: 7158
Train: Epoch[40/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000068  Loss: 0.4996  Acc@1: 86.3636 (86.7893)  Acc@5: 90.9091 (92.1405)  time: 2.6120  data: 0.0743  max mem: 7158
Train: Epoch[40/60] Total time: 0:00:26 (2.6204 s / it)
Averaged stats: Lr: 0.000068  Loss: 0.4996  Acc@1: 86.3636 (86.7893)  Acc@5: 90.9091 (92.1405)
Train: Epoch[41/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000063  Loss: 0.2917  Acc@1: 93.7500 (93.7500)  Acc@5: 96.8750 (96.8750)  time: 3.8193  data: 0.8939  max mem: 7158
Train: Epoch[41/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000063  Loss: 0.4120  Acc@1: 87.5000 (87.9599)  Acc@5: 95.3125 (95.3177)  time: 2.6349  data: 0.0895  max mem: 7158
Train: Epoch[41/60] Total time: 0:00:26 (2.6438 s / it)
Averaged stats: Lr: 0.000063  Loss: 0.4120  Acc@1: 87.5000 (87.9599)  Acc@5: 95.3125 (95.3177)
Train: Epoch[42/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000057  Loss: 0.4924  Acc@1: 84.3750 (84.3750)  Acc@5: 89.0625 (89.0625)  time: 3.6962  data: 0.7088  max mem: 7158
Train: Epoch[42/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000057  Loss: 0.5449  Acc@1: 85.9375 (86.9565)  Acc@5: 92.1875 (93.4783)  time: 2.6097  data: 0.0710  max mem: 7158
Train: Epoch[42/60] Total time: 0:00:26 (2.6191 s / it)
Averaged stats: Lr: 0.000057  Loss: 0.5449  Acc@1: 85.9375 (86.9565)  Acc@5: 92.1875 (93.4783)
Train: Epoch[43/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000052  Loss: 0.4503  Acc@1: 81.2500 (81.2500)  Acc@5: 92.1875 (92.1875)  time: 3.8089  data: 0.8106  max mem: 7158
Train: Epoch[43/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000052  Loss: 0.2531  Acc@1: 85.9375 (87.2910)  Acc@5: 93.7500 (93.8127)  time: 2.6408  data: 0.0812  max mem: 7158
Train: Epoch[43/60] Total time: 0:00:26 (2.6497 s / it)
Averaged stats: Lr: 0.000052  Loss: 0.2531  Acc@1: 85.9375 (87.2910)  Acc@5: 93.7500 (93.8127)
Train: Epoch[44/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000046  Loss: 0.2592  Acc@1: 95.3125 (95.3125)  Acc@5: 98.4375 (98.4375)  time: 3.8323  data: 0.9135  max mem: 7158
Train: Epoch[44/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000046  Loss: 0.4218  Acc@1: 86.3636 (88.1271)  Acc@5: 95.3125 (95.1505)  time: 2.6201  data: 0.0915  max mem: 7158
Train: Epoch[44/60] Total time: 0:00:26 (2.6281 s / it)
Averaged stats: Lr: 0.000046  Loss: 0.4218  Acc@1: 86.3636 (88.1271)  Acc@5: 95.3125 (95.1505)
Train: Epoch[45/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000041  Loss: 0.3789  Acc@1: 85.9375 (85.9375)  Acc@5: 98.4375 (98.4375)  time: 3.6950  data: 0.7852  max mem: 7158
Train: Epoch[45/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000041  Loss: 0.2636  Acc@1: 87.5000 (87.6254)  Acc@5: 96.8750 (95.4849)  time: 2.6318  data: 0.0786  max mem: 7158
Train: Epoch[45/60] Total time: 0:00:26 (2.6411 s / it)
Averaged stats: Lr: 0.000041  Loss: 0.2636  Acc@1: 87.5000 (87.6254)  Acc@5: 96.8750 (95.4849)
Train: Epoch[46/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000037  Loss: 0.3214  Acc@1: 90.6250 (90.6250)  Acc@5: 96.8750 (96.8750)  time: 3.7607  data: 0.8693  max mem: 7158
Train: Epoch[46/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000037  Loss: 0.2049  Acc@1: 89.0625 (89.2977)  Acc@5: 95.3125 (94.9833)  time: 2.6070  data: 0.0871  max mem: 7158
Train: Epoch[46/60] Total time: 0:00:26 (2.6151 s / it)
Averaged stats: Lr: 0.000037  Loss: 0.2049  Acc@1: 89.0625 (89.2977)  Acc@5: 95.3125 (94.9833)
Train: Epoch[47/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000032  Loss: 0.3372  Acc@1: 87.5000 (87.5000)  Acc@5: 96.8750 (96.8750)  time: 3.8293  data: 0.8423  max mem: 7158
Train: Epoch[47/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000032  Loss: 0.4658  Acc@1: 87.5000 (87.9599)  Acc@5: 95.3125 (94.9833)  time: 2.6132  data: 0.0844  max mem: 7158
Train: Epoch[47/60] Total time: 0:00:26 (2.6212 s / it)
Averaged stats: Lr: 0.000032  Loss: 0.4658  Acc@1: 87.5000 (87.9599)  Acc@5: 95.3125 (94.9833)
Train: Epoch[48/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000028  Loss: 0.4179  Acc@1: 82.8125 (82.8125)  Acc@5: 95.3125 (95.3125)  time: 3.7534  data: 0.9072  max mem: 7158
Train: Epoch[48/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000028  Loss: 0.4152  Acc@1: 85.9375 (87.6254)  Acc@5: 95.3125 (95.1505)  time: 2.6109  data: 0.0909  max mem: 7158
Train: Epoch[48/60] Total time: 0:00:26 (2.6224 s / it)
Averaged stats: Lr: 0.000028  Loss: 0.4152  Acc@1: 85.9375 (87.6254)  Acc@5: 95.3125 (95.1505)
Train: Epoch[49/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000024  Loss: 0.3509  Acc@1: 89.0625 (89.0625)  Acc@5: 95.3125 (95.3125)  time: 3.7286  data: 0.7136  max mem: 7158
Train: Epoch[49/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000024  Loss: 0.5443  Acc@1: 89.0625 (87.9599)  Acc@5: 93.7500 (93.9799)  time: 2.6211  data: 0.0715  max mem: 7158
Train: Epoch[49/60] Total time: 0:00:26 (2.6298 s / it)
Averaged stats: Lr: 0.000024  Loss: 0.5443  Acc@1: 89.0625 (87.9599)  Acc@5: 93.7500 (93.9799)
Train: Epoch[50/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000020  Loss: 0.3605  Acc@1: 82.8125 (82.8125)  Acc@5: 96.8750 (96.8750)  time: 3.8320  data: 0.8957  max mem: 7158
Train: Epoch[50/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000020  Loss: 0.2491  Acc@1: 87.5000 (87.1237)  Acc@5: 93.7500 (94.4816)  time: 2.6141  data: 0.0897  max mem: 7158
Train: Epoch[50/60] Total time: 0:00:26 (2.6222 s / it)
Averaged stats: Lr: 0.000020  Loss: 0.2491  Acc@1: 87.5000 (87.1237)  Acc@5: 93.7500 (94.4816)
Train: Epoch[51/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000017  Loss: 0.2392  Acc@1: 92.1875 (92.1875)  Acc@5: 98.4375 (98.4375)  time: 3.7903  data: 0.8429  max mem: 7158
Train: Epoch[51/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000017  Loss: 0.2736  Acc@1: 87.5000 (87.7926)  Acc@5: 95.3125 (93.8127)  time: 2.6074  data: 0.0844  max mem: 7158
Train: Epoch[51/60] Total time: 0:00:26 (2.6165 s / it)
Averaged stats: Lr: 0.000017  Loss: 0.2736  Acc@1: 87.5000 (87.7926)  Acc@5: 95.3125 (93.8127)
Train: Epoch[52/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000014  Loss: 0.2667  Acc@1: 92.1875 (92.1875)  Acc@5: 95.3125 (95.3125)  time: 3.7144  data: 0.8315  max mem: 7158
Train: Epoch[52/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000014  Loss: 0.3370  Acc@1: 89.0625 (88.4615)  Acc@5: 92.1875 (94.3144)  time: 2.6082  data: 0.0833  max mem: 7158
Train: Epoch[52/60] Total time: 0:00:26 (2.6165 s / it)
Averaged stats: Lr: 0.000014  Loss: 0.3370  Acc@1: 89.0625 (88.4615)  Acc@5: 92.1875 (94.3144)
Train: Epoch[53/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000011  Loss: 0.4076  Acc@1: 85.9375 (85.9375)  Acc@5: 90.6250 (90.6250)  time: 3.7169  data: 0.7980  max mem: 7158
Train: Epoch[53/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000011  Loss: 0.2012  Acc@1: 89.0625 (87.9599)  Acc@5: 95.3125 (94.9833)  time: 2.6057  data: 0.0799  max mem: 7158
Train: Epoch[53/60] Total time: 0:00:26 (2.6139 s / it)
Averaged stats: Lr: 0.000011  Loss: 0.2012  Acc@1: 89.0625 (87.9599)  Acc@5: 95.3125 (94.9833)
Train: Epoch[54/60]  [ 0/10]  eta: 0:00:38  Lr: 0.000008  Loss: 0.3150  Acc@1: 90.6250 (90.6250)  Acc@5: 92.1875 (92.1875)  time: 3.8286  data: 0.9297  max mem: 7158
Train: Epoch[54/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000008  Loss: 0.4702  Acc@1: 89.0625 (88.4615)  Acc@5: 93.7500 (95.1505)  time: 2.6135  data: 0.0931  max mem: 7158
Train: Epoch[54/60] Total time: 0:00:26 (2.6221 s / it)
Averaged stats: Lr: 0.000008  Loss: 0.4702  Acc@1: 89.0625 (88.4615)  Acc@5: 93.7500 (95.1505)
Train: Epoch[55/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000006  Loss: 0.4463  Acc@1: 84.3750 (84.3750)  Acc@5: 92.1875 (92.1875)  time: 3.7395  data: 0.7743  max mem: 7158
Train: Epoch[55/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000006  Loss: 0.2971  Acc@1: 87.5000 (87.9599)  Acc@5: 92.1875 (93.4783)  time: 2.6289  data: 0.0776  max mem: 7158
Train: Epoch[55/60] Total time: 0:00:26 (2.6372 s / it)
Averaged stats: Lr: 0.000006  Loss: 0.2971  Acc@1: 87.5000 (87.9599)  Acc@5: 92.1875 (93.4783)
Train: Epoch[56/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000004  Loss: 0.3810  Acc@1: 87.5000 (87.5000)  Acc@5: 90.6250 (90.6250)  time: 3.6784  data: 0.6919  max mem: 7158
Train: Epoch[56/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000004  Loss: 0.2145  Acc@1: 85.9375 (85.9532)  Acc@5: 93.7500 (93.8127)  time: 2.6054  data: 0.0693  max mem: 7158
Train: Epoch[56/60] Total time: 0:00:26 (2.6135 s / it)
Averaged stats: Lr: 0.000004  Loss: 0.2145  Acc@1: 85.9375 (85.9532)  Acc@5: 93.7500 (93.8127)
Train: Epoch[57/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000003  Loss: 0.4193  Acc@1: 84.3750 (84.3750)  Acc@5: 92.1875 (92.1875)  time: 3.7150  data: 0.8006  max mem: 7158
Train: Epoch[57/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000003  Loss: 0.2542  Acc@1: 87.5000 (88.2943)  Acc@5: 96.8750 (96.1538)  time: 2.6272  data: 0.0802  max mem: 7158
Train: Epoch[57/60] Total time: 0:00:26 (2.6374 s / it)
Averaged stats: Lr: 0.000003  Loss: 0.2542  Acc@1: 87.5000 (88.2943)  Acc@5: 96.8750 (96.1538)
Train: Epoch[58/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000002  Loss: 0.2690  Acc@1: 92.1875 (92.1875)  Acc@5: 93.7500 (93.7500)  time: 3.7725  data: 0.8009  max mem: 7158
Train: Epoch[58/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000002  Loss: 0.4143  Acc@1: 89.0625 (88.4615)  Acc@5: 95.3125 (94.8161)  time: 2.6272  data: 0.0802  max mem: 7158
Train: Epoch[58/60] Total time: 0:00:26 (2.6355 s / it)
Averaged stats: Lr: 0.000002  Loss: 0.4143  Acc@1: 89.0625 (88.4615)  Acc@5: 95.3125 (94.8161)
Train: Epoch[59/60]  [ 0/10]  eta: 0:00:36  Lr: 0.000001  Loss: 0.4519  Acc@1: 85.9375 (85.9375)  Acc@5: 92.1875 (92.1875)  time: 3.6589  data: 0.7106  max mem: 7158
Train: Epoch[59/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000001  Loss: 0.4723  Acc@1: 87.5000 (87.2910)  Acc@5: 95.3125 (95.1505)  time: 2.5965  data: 0.0712  max mem: 7158
Train: Epoch[59/60] Total time: 0:00:26 (2.6046 s / it)
Averaged stats: Lr: 0.000001  Loss: 0.4723  Acc@1: 87.5000 (87.2910)  Acc@5: 95.3125 (95.1505)
Train: Epoch[60/60]  [ 0/10]  eta: 0:00:37  Lr: 0.000000  Loss: 0.2625  Acc@1: 85.9375 (85.9375)  Acc@5: 98.4375 (98.4375)  time: 3.7410  data: 0.8155  max mem: 7158
Train: Epoch[60/60]  [ 9/10]  eta: 0:00:02  Lr: 0.000000  Loss: 0.3802  Acc@1: 87.5000 (88.4615)  Acc@5: 93.7500 (94.8161)  time: 2.6333  data: 0.0817  max mem: 7158
Train: Epoch[60/60] Total time: 0:00:26 (2.6439 s / it)
Averaged stats: Lr: 0.000000  Loss: 0.3802  Acc@1: 87.5000 (88.4615)  Acc@5: 93.7500 (94.8161)
Test: [Task 1]  [0/9]  eta: 0:00:16  Loss: 0.5144 (0.5144)  Acc@1: 92.1875 (92.1875)  Acc@5: 98.4375 (98.4375)  time: 1.8675  data: 0.8522  max mem: 7158
Test: [Task 1]  [8/9]  eta: 0:00:00  Loss: 0.3158 (0.3824)  Acc@1: 96.8750 (91.8447)  Acc@5: 100.0000 (98.6408)  time: 0.8169  data: 0.0949  max mem: 7158
Test: [Task 1] Total time: 0:00:07 (0.8260 s / it)
* Acc@1 91.845 Acc@5 98.641 loss 0.382
Batchwise eval time for task 1 = 0.8260756863488091
Test: [Task 2]  [0/9]  eta: 0:00:17  Loss: 0.6814 (0.6814)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 1.9098  data: 0.9687  max mem: 7158
Test: [Task 2]  [8/9]  eta: 0:00:00  Loss: 1.1671 (1.1125)  Acc@1: 60.9375 (68.3478)  Acc@5: 98.4375 (98.2609)  time: 0.8721  data: 0.1078  max mem: 7158
Test: [Task 2] Total time: 0:00:07 (0.8811 s / it)
* Acc@1 68.348 Acc@5 98.261 loss 1.113
Batchwise eval time for task 2 = 0.881137900882297
Test: [Task 3]  [ 0/10]  eta: 0:00:19  Loss: 0.4699 (0.4699)  Acc@1: 95.3125 (95.3125)  Acc@5: 98.4375 (98.4375)  time: 1.9713  data: 0.9383  max mem: 7158
Test: [Task 3]  [ 9/10]  eta: 0:00:00  Loss: 0.5094 (0.6815)  Acc@1: 95.3125 (91.1074)  Acc@5: 98.4375 (98.6577)  time: 0.8299  data: 0.0941  max mem: 7158
Test: [Task 3] Total time: 0:00:08 (0.8381 s / it)
* Acc@1 91.107 Acc@5 98.658 loss 0.682
Batchwise eval time for task 3 = 0.838128924369812
Test: [Task 4]  [ 0/10]  eta: 0:00:18  Loss: 1.3222 (1.3222)  Acc@1: 56.2500 (56.2500)  Acc@5: 95.3125 (95.3125)  time: 1.8830  data: 0.9688  max mem: 7158
Test: [Task 4]  [ 9/10]  eta: 0:00:00  Loss: 0.8354 (0.8631)  Acc@1: 81.2500 (80.7167)  Acc@5: 98.4375 (98.6348)  time: 0.8175  data: 0.0971  max mem: 7158
Test: [Task 4] Total time: 0:00:08 (0.8262 s / it)
* Acc@1 80.717 Acc@5 98.635 loss 0.863
Batchwise eval time for task 4 = 0.8261926889419555
Test: [Task 5]  [ 0/10]  eta: 0:00:19  Loss: 0.5723 (0.5723)  Acc@1: 85.9375 (85.9375)  Acc@5: 100.0000 (100.0000)  time: 1.9215  data: 0.9121  max mem: 7158
Test: [Task 5]  [ 9/10]  eta: 0:00:00  Loss: 0.4858 (0.5841)  Acc@1: 93.7500 (93.0743)  Acc@5: 98.4375 (97.9730)  time: 0.8244  data: 0.0914  max mem: 7158
Test: [Task 5] Total time: 0:00:08 (0.8324 s / it)
* Acc@1 93.074 Acc@5 97.973 loss 0.584
Batchwise eval time for task 5 = 0.8324040174484253
Test: [Task 6]  [0/9]  eta: 0:00:16  Loss: 0.7924 (0.7924)  Acc@1: 89.0625 (89.0625)  Acc@5: 98.4375 (98.4375)  time: 1.8013  data: 0.8861  max mem: 7158
Test: [Task 6]  [8/9]  eta: 0:00:00  Loss: 0.9305 (0.9578)  Acc@1: 87.5000 (84.9823)  Acc@5: 96.8750 (97.3498)  time: 0.8578  data: 0.0986  max mem: 7158
Test: [Task 6] Total time: 0:00:07 (0.8669 s / it)
* Acc@1 84.982 Acc@5 97.350 loss 0.958
Batchwise eval time for task 6 = 0.8669207625918918
Test: [Task 7]  [ 0/10]  eta: 0:00:19  Loss: 1.2555 (1.2555)  Acc@1: 82.8125 (82.8125)  Acc@5: 96.8750 (96.8750)  time: 1.9235  data: 0.9169  max mem: 7158
Test: [Task 7]  [ 9/10]  eta: 0:00:00  Loss: 0.8083 (1.1197)  Acc@1: 82.8125 (79.7659)  Acc@5: 96.8750 (96.1538)  time: 0.8266  data: 0.0921  max mem: 7158
Test: [Task 7] Total time: 0:00:08 (0.8344 s / it)
* Acc@1 79.766 Acc@5 96.154 loss 1.120
Batchwise eval time for task 7 = 0.8344692945480346
Test: [Task 8]  [ 0/10]  eta: 0:00:18  Loss: 1.6063 (1.6063)  Acc@1: 79.6875 (79.6875)  Acc@5: 96.8750 (96.8750)  time: 1.8474  data: 0.9158  max mem: 7158
Test: [Task 8]  [ 9/10]  eta: 0:00:00  Loss: 1.0771 (1.1490)  Acc@1: 79.6875 (77.8157)  Acc@5: 96.8750 (97.4403)  time: 0.8137  data: 0.0918  max mem: 7158
Test: [Task 8] Total time: 0:00:08 (0.8236 s / it)
* Acc@1 77.816 Acc@5 97.440 loss 1.149
Batchwise eval time for task 8 = 0.8236217021942138
Test: [Task 9]  [ 0/10]  eta: 0:00:19  Loss: 1.8840 (1.8840)  Acc@1: 54.6875 (54.6875)  Acc@5: 90.6250 (90.6250)  time: 1.9993  data: 1.0215  max mem: 7158
Test: [Task 9]  [ 9/10]  eta: 0:00:00  Loss: 1.3328 (1.4424)  Acc@1: 65.6250 (71.9595)  Acc@5: 93.7500 (94.9324)  time: 0.8326  data: 0.1023  max mem: 7158
Test: [Task 9] Total time: 0:00:08 (0.8405 s / it)
* Acc@1 71.959 Acc@5 94.932 loss 1.442
Batchwise eval time for task 9 = 0.8405351877212525
Test: [Task 10]  [ 0/10]  eta: 0:00:18  Loss: 0.4660 (0.4660)  Acc@1: 98.4375 (98.4375)  Acc@5: 100.0000 (100.0000)  time: 1.8786  data: 0.8918  max mem: 7158
Test: [Task 10]  [ 9/10]  eta: 0:00:00  Loss: 0.5627 (0.5483)  Acc@1: 95.3125 (94.0476)  Acc@5: 98.4375 (97.7891)  time: 0.8537  data: 0.0894  max mem: 7158
Test: [Task 10] Total time: 0:00:08 (0.8617 s / it)
* Acc@1 94.048 Acc@5 97.789 loss 0.548
Batchwise eval time for task 10 = 0.8617087125778198
[Average accuracy till task10]	Acc@1: 83.2931	Acc@5: 97.5833	Loss: 0.8841	Forgetting: 3.8300	Backward: -3.4508
Eval time for task 10 = 82.0782585144043
Total training time: 3:41:02